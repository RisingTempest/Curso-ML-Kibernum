{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8d92a93",
   "metadata": {},
   "source": [
    "# Evaluación Modular 7:\n",
    "# Sistema Inteligente de Scoring Crediticio con Redes Neuronales Profundas\n",
    "\n",
    "## Objetivo\n",
    "Diseñar, entrenar y evaluar un modelo de red neuronal profunda para predecir la probabilidad de impago de clientes bancarios, utilizando un conjunto de datos realista. El modelo debe ser explicable, eficiente y presentar resultados interpretables para su uso en contextos financieros.\n",
    "\n",
    "**Datasets utilizados:**  \n",
    "`German Credit Data`\n",
    "\n",
    "---\n",
    "\n",
    "### Estructura del Notebook:\n",
    "1. Metodología.\n",
    "2. Configuración del entorno.\n",
    "3. Definicion de funciones.\n",
    "4. Uso de funciones y resultados.\n",
    "5. Análisis de los resultados y reflexiones finales.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29eb186e",
   "metadata": {},
   "source": [
    "## 1. Metodología\n",
    "\n",
    "### Flujo de trabajo\n",
    "\n",
    "1. **Carga y análisis exploratorio de datos:**\n",
    "    - Se carga el dataset **German Credit Data** y se nombran las columnas según la descripción oficial.\n",
    "    - Se realiza un análisis inicial de las variables:\n",
    "        - Descripción estadística de variables numéricas y categóricas.\n",
    "        - Distribución de la variable objetivo (`credit_risk`) y balance de clases.\n",
    "        - Visualización de conteos para la variable target.\n",
    "\n",
    "2. **Preprocesamiento de datos y manejo de desbalanceo:**\n",
    "    - Mapeo de variables ordinales según los diccionarios oficiales.\n",
    "    - Codificación **One-Hot** para variables nominales.\n",
    "    - Escalado de variables numéricas con **StandardScaler**.\n",
    "    - División en conjuntos **train/test** estratificados.\n",
    "    - Cálculo de **pesos de clase** para balancear la función de pérdida durante el entrenamiento de los modelos.\n",
    "\n",
    "3. **Construcción de modelos de predicción:**\n",
    "    - Se construye un **Simple DNN** con capas densas, activación ReLU, regularización L2 y Dropout.\n",
    "    - Se construye un **ResNet para datos tabulares** con bloques residuales, activación ReLU y salida sigmoide.\n",
    "    - Compilación de los modelos con **binary cross-entropy** y optimizador Adam.\n",
    "\n",
    "4. **Entrenamiento de modelos:**\n",
    "    - Entrenamiento con **early stopping** y reducción adaptativa del learning rate.\n",
    "    - Uso de los **pesos de clase** para manejar el desbalanceo.\n",
    "    - Validación durante el entrenamiento en el conjunto de test.\n",
    "\n",
    "5. **Evaluación de desempeño:**\n",
    "    - Cálculo de métricas de clasificación:\n",
    "        - **Accuracy, Precision, Recall, F1-score y ROC-AUC**.\n",
    "    - Comparación de los modelos en una tabla resumida.\n",
    "\n",
    "6. **Explicabilidad con SHAP:**\n",
    "    - Uso de **SHAP KernelExplainer** para analizar la contribución de cada variable a las predicciones.\n",
    "    - Selección de un subconjunto de muestras de test para los cálculos de SHAP.\n",
    "    - Visualización de **summary plots** para cada modelo, mostrando la importancia relativa de variables numéricas y nominales (one-hot).\n",
    "\n",
    "7. **Interpretación y análisis financiero:**\n",
    "    - Evaluación de la importancia relativa de **falsos positivos y falsos negativos** según el contexto financiero.\n",
    "    - Discusión sobre qué variables influyen más en el riesgo de crédito.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3be209",
   "metadata": {},
   "source": [
    "# 2. Configuración del entorno\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d10181c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías\n",
    "import os, io, contextlib, random, tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers, callbacks\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import shap\n",
    "\n",
    "# Reproducibilidad y disminución de logs\n",
    "os.environ['PYTHONHASHSEED'] = '42'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tqdm.tqdm = lambda *args, **kwargs: iter([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ed7617",
   "metadata": {},
   "source": [
    "# 3. Definición de funciones\n",
    "\n",
    "> **Nota:** Para mejor comprensión de las funciones y su utilidad, esta sección se divide en bloques, en donde cada uno responde a una parte diferente de la metodología de trabajo. \n",
    "\n",
    "---\n",
    "\n",
    "**Bloque 1:** Carga, preprocesamiento de datos y aplicación de reducción de dimensionalidad de los datos.\n",
    "\n",
    "- **`cargar_y_analizar_datos()`** \n",
    "Carga y analiza el dataset German Credit mostrando estadísticas y distribución de clases.\n",
    "\n",
    "- **`preprocesar_datos()`** \n",
    "Preprocesa datos (ordinal, nominal, escalado, train/test) y calcula pesos de clase.\n",
    "\n",
    "---\n",
    "\n",
    "### **Decisiones de diseño**\n",
    "\n",
    "##### **Definición de nombres de columnas:**\n",
    "\n",
    "- El archivo `german.data` no incluye encabezados, por lo que al cargarlo con pandas sería imposible referirse a las variables por nombre. Definir los nombres de columnas manualmente garantiza que cada atributo tenga una etiqueta clara y permite manipular los datos de forma más legible y menos propensa a errores.\n",
    "\n",
    "##### **División en variables numéricas, ordinales y nominales:**\n",
    "\n",
    "- En preprocesamiento, no basta con separar solo en numéricas y categóricas, porque las categóricas pueden tener orden lógico (ordinales) o no tenerlo (nominales). Las ordinales tienen categorías con jerarquía o progresión (ejemplo: nivel de ahorro o antigüedad laboral). Aquí es válido mapearlas a números enteros respetando su orden. Por otro lado, las nominales son solo etiquetas sin orden (ejemplo: propósito del crédito), y deben procesarse con One-Hot Encoding para evitar imponer un orden artificial.\n",
    "\n",
    "- La clasificación de cada variable como ordinal o nominal se hizo usando la documentación oficial del dataset, donde se especifica el significado y el orden implícito de cada atributo.\n",
    "\n",
    "##### **Cambio de valores de target de 1 y 2 a 0 y 1**\n",
    "\n",
    "- La conversión de las etiquetas de credit_risk de 1=good y 2=bad a 0 y 1 es una práctica común en clasificación binaria. Muchos algoritmos y métricas esperan que la clase negativa sea 0 y la positiva sea 1, lo que evita errores en bibliotecas como scikit-learn y simplifica el manejo de métricas como accuracy, precision o ROC-AUC.\n",
    "\n",
    "##### **Balanceo de clases**\n",
    "\n",
    "- El dataset original tiene un desbalance de ~70% clase \"good\" y ~30% \"bad\". Esto puede sesgar el modelo para predecir mayoritariamente la clase mayoritaria.\n",
    "\n",
    "- Se optó por class weights en lugar de técnicas de sobremuestreo como SMOTE porque:\n",
    "    - Mantiene intacta la distribución real de datos.\n",
    "    - Evita generar datos sintéticos que podrían no representar fielmente casos de crédito real.\n",
    "    - Es más simple y rápido, y funciona bien con la mayoría de algoritmos basados en gradiente o redes neuronales.\n",
    "\n",
    "- Los class weights le dicen al modelo que penalice más los errores en la clase minoritaria, equilibrando el aprendizaje sin alterar los datos originales.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29985c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_y_analizar_datos(filepath='german.data'):\n",
    "    \"\"\"\n",
    "    Carga el dataset German Credit Data, analiza sus variables y distribuciones, \n",
    "    y muestra estadísticas básicas y gráficos de la clase objetivo.\n",
    "\n",
    "    Pasos:\n",
    "    1. Definir nombres de columnas y cargar el CSV.\n",
    "    2. Mostrar primeras filas, descripción general y tipo de datos.\n",
    "    3. Visualizar la distribución de la variable objetivo 'credit_risk'.\n",
    "\n",
    "    Args:\n",
    "        filepath (str): Ruta al archivo de datos. Por defecto 'german.data'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame completo con los datos cargados.\n",
    "    \"\"\"\n",
    "    column_names = [\n",
    "        \"checking_status\", \"duration\", \"credit_history\", \"purpose\",\n",
    "        \"credit_amount\", \"savings\", \"employment\", \"installment_rate\",\n",
    "        \"personal_status\", \"other_parties\", \"residence_since\", \"property\",\n",
    "        \"age\", \"other_installments\", \"housing\", \"existing_credits\",\n",
    "        \"job\", \"num_dependents\", \"telephone\", \"foreign_worker\", \"credit_risk\"\n",
    "    ]\n",
    "    df = pd.read_csv(filepath, sep=' ', names=column_names)\n",
    "\n",
    "    print(\"Primeras filas del dataset:\")\n",
    "    display(df.head())\n",
    "    print(\"\\nDescripción general (numéricas y categóricas):\")\n",
    "    display(df.describe(include='all'))\n",
    "    print(\"\\nInformación general:\")\n",
    "    display(df.info())\n",
    "\n",
    "    print(\"\\nDistribución de clases (credit_risk):\")\n",
    "    print(df['credit_risk'].value_counts())\n",
    "    sns.countplot(x='credit_risk', data=df)\n",
    "    plt.title(\"Distribución de clases: good vs bad\")\n",
    "    plt.show()\n",
    "\n",
    "    return df\n",
    "\n",
    "def preprocesar_datos(df):\n",
    "    \"\"\"\n",
    "    Preprocesa los datos del German Credit Data, incluyendo:\n",
    "    - Mapeo de variables ordinales.\n",
    "    - One-Hot Encoding de variables nominales.\n",
    "    - Escalado de variables numéricas.\n",
    "    - División estratificada en train/test.\n",
    "    - Cálculo de pesos de clase para balanceo.\n",
    "\n",
    "    Pasos:\n",
    "    1. Mapear variables ordinales a valores enteros.\n",
    "    2. Definir variables nominales para One-Hot Encoding.\n",
    "    3. Construir pipelines para transformación numérica y categórica.\n",
    "    4. Ajustar y transformar train/test.\n",
    "    5. Calcular pesos de clase.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame original con los datos cargados.\n",
    "\n",
    "    Returns:\n",
    "        X_train_prep (np.ndarray): Features de entrenamiento preprocesadas.\n",
    "        X_test_prep (np.ndarray): Features de test preprocesadas.\n",
    "        y_train (np.ndarray): Etiquetas de entrenamiento.\n",
    "        y_test (np.ndarray): Etiquetas de test.\n",
    "        preprocessor (ColumnTransformer): Pipeline de preprocesamiento ajustado.\n",
    "        class_weight_dict (dict): Diccionario con pesos de clase para entrenamiento.\n",
    "    \"\"\"\n",
    "    target = 'credit_risk'\n",
    "\n",
    "    ordinal_vars_maps = {\n",
    "        'checking_status': {'A11': 0, 'A12': 1, 'A13': 2, 'A14': 3},\n",
    "        'savings': {'A61': 0, 'A62': 1, 'A63': 2, 'A64': 3, 'A65': 4},\n",
    "        'employment': {'A71': 0, 'A72': 1, 'A73': 2, 'A74': 3, 'A75': 4},\n",
    "        'personal_status': {'A91': 0, 'A92': 1, 'A93': 2, 'A94': 3, 'A95': 4},\n",
    "        'property': {'A121': 0, 'A122': 1, 'A123': 2, 'A124': 3},\n",
    "        'other_installments': {'A141': 0, 'A142': 1, 'A143': 2},\n",
    "        'housing': {'A151': 0, 'A152': 1, 'A153': 2},\n",
    "        'job': {'A171': 0, 'A172': 1, 'A173': 2, 'A174': 3},\n",
    "        'telephone': {'A191': 0, 'A192': 1},\n",
    "        'foreign_worker': {'A201': 1, 'A202': 0}\n",
    "    }\n",
    "\n",
    "    for col in ordinal_vars_maps.keys():\n",
    "        df[col] = df[col].map(ordinal_vars_maps[col]).astype(int)\n",
    "\n",
    "    nominal_vars = ['credit_history', 'purpose', 'other_parties']\n",
    "    num_vars = [col for col in df.columns if col not in nominal_vars + [target]]\n",
    "\n",
    "    print(\"Variables numéricas (incluidas ordinales):\", num_vars)\n",
    "    print(\"Variables nominales para One-Hot:\", nominal_vars)\n",
    "\n",
    "    numeric_transformer = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    categorical_transformer = Pipeline([\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', numeric_transformer, num_vars),\n",
    "        ('cat', categorical_transformer, nominal_vars)\n",
    "    ])\n",
    "\n",
    "    X = df.drop(columns=[target])\n",
    "    y = df[target].map({1: 0, 2: 1})  # good=0, bad=1\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "    X_train_prep = preprocessor.fit_transform(X_train)\n",
    "    X_test_prep = preprocessor.transform(X_test)\n",
    "\n",
    "    class_weights = compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=np.unique(y_train),\n",
    "        y=y_train\n",
    "    )\n",
    "    class_weight_dict = dict(enumerate(class_weights))\n",
    "    print(\"Pesos de clase calculados:\", class_weight_dict)\n",
    "\n",
    "    return X_train_prep, X_test_prep, y_train.values, y_test.values, preprocessor, class_weight_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc78d27",
   "metadata": {},
   "source": [
    "**Bloque 2:** Creación, entrenamiento y evaluación de modelos.\n",
    "\n",
    "- **`construir_dnn_simple()`** \n",
    "Crea y compila una red neuronal densa simple para clasificación binaria, con capas ocultas densas, regularización L2 y capas de dropout para prevenir sobreajuste.\n",
    "\n",
    "- **`bloque_residual()`** \n",
    "Implementa un bloque residual totalmente conectado. Permite el flujo directo de información mediante conexiones de salto (skip connections), ayudando a entrenar redes más profundas y estables.\n",
    "\n",
    "- **`construir_resnet_tabular()`** \n",
    "Crea y compila una red neuronal tipo ResNet adaptada a datos tabulares, utilizando bloques residuales para mejorar la capacidad de generalización y mitigar el problema del desvanecimiento del gradiente.\n",
    "\n",
    "- **`entrenar_modelo()`** \n",
    "Entrena un modelo usando Early Stopping (para detener el entrenamiento cuando no hay mejora) y reducción adaptativa de la tasa de aprendizaje (ReduceLROnPlateau), ajustando el entrenamiento al desbalanceo de clases mediante class_weight.\n",
    "\n",
    "- **`evaluar_modelo()`** \n",
    "Evalúa el rendimiento del modelo sobre datos de prueba, calculando métricas clave de clasificación binaria como accuracy, precision, recall, f1-score y ROC AUC, además de devolver las probabilidades predichas.\n",
    "\n",
    "---\n",
    "\n",
    "### **Decisiones de diseño**\n",
    "\n",
    "##### **Diseño de la DNN simple:**\n",
    "\n",
    "- Se optó por una red neuronal densa (DNN) con dos capas ocultas de 128 y 64 neuronas respectivamente, usando activación ReLU y regularización L2 combinada con dropout. Este diseño es suficiente para capturar relaciones no lineales en datos tabulares sin caer en una complejidad excesiva que incremente el riesgo de sobreajuste. La regularización L2 penaliza pesos grandes, y el dropout fuerza a la red a no depender en exceso de neuronas específicas, mejorando la capacidad de generalización.\n",
    "\n",
    "##### **Propósito del bloque residual:**\n",
    "\n",
    "- El bloque residual implementa skip connections, permitiendo que la señal original se sume a la salida de las capas intermedias. Esto facilita el entrenamiento de redes más profundas al mitigar el problema del desvanecimiento del gradiente y permite que la red aprenda funciones de identidad cuando es necesario, lo que aumenta su estabilidad y capacidad de adaptación.\n",
    "\n",
    "##### **Uso de ResNet tabular:**\n",
    "\n",
    "- La variante ResNet adaptada a datos tabulares permite aprovechar la estabilidad y la eficiencia en el entrenamiento que ofrecen los bloques residuales, especialmente en modelos con más capas. Esta arquitectura moderna suele superar a DNN simples en tareas complejas, ya que evita la degradación del rendimiento al aumentar la profundidad de la red.\n",
    "\n",
    "##### **Justificación para Early Stopping y ReduceLROnPlateau:**\n",
    "\n",
    "- Early Stopping: Detiene el entrenamiento cuando el rendimiento en el conjunto de validación deja de mejorar, evitando así el sobreajuste y reduciendo el tiempo de entrenamiento innecesario.\n",
    "\n",
    "- ReduceLROnPlateau: Disminuye la tasa de aprendizaje cuando el progreso se estanca, permitiendo que el optimizador realice ajustes más finos y aumente la probabilidad de converger a un mínimo óptimo.\n",
    "\n",
    "##### **Justificación de las métricas utilizadas:**\n",
    "\n",
    "- Accuracy: Proporción total de predicciones correctas; útil como referencia general.\n",
    "- Precision: Proporción de predicciones positivas correctas; relevante cuando el costo de un falso positivo es alto.\n",
    "- Recall: Proporción de casos positivos correctamente detectados; esencial cuando es crítico no omitir positivos reales.\n",
    "- F1-score: Media armónica de precisión y recall; balancea ambas métricas y es clave en escenarios con clases desbalanceadas.\n",
    "- ROC AUC: Evalúa la capacidad de discriminación del modelo entre clases para todos los umbrales posibles, proporcionando una medida robusta de rendimiento global.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2271c847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construir_dnn_simple(forma_entrada):\n",
    "    \"\"\"\n",
    "    Construye y compila un modelo DNN (red neuronal densa) simple para clasificación binaria.\n",
    "    \n",
    "    Parámetros:\n",
    "        forma_entrada (tuple): Forma de los datos de entrada (n_features,).\n",
    "\n",
    "    Retorna:\n",
    "        tensorflow.keras.Model: Modelo compilado listo para entrenamiento.\n",
    "    \"\"\"\n",
    "    modelo = models.Sequential([\n",
    "        layers.Input(shape=forma_entrada),\n",
    "        layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "        layers.Dropout(0.4),\n",
    "        layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    modelo.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return modelo\n",
    "\n",
    "\n",
    "def bloque_residual(x, unidades):\n",
    "    \"\"\"\n",
    "    Implementa un bloque residual con dos capas densas y conexión de atajo.\n",
    "    \n",
    "    Parámetros:\n",
    "        x (tensor): Entrada al bloque.\n",
    "        unidades (int): Número de neuronas en las capas densas.\n",
    "\n",
    "    Retorna:\n",
    "        tensor: Salida del bloque residual.\n",
    "    \"\"\"\n",
    "    atajo = x\n",
    "    x = layers.Dense(unidades, activation='relu')(x)\n",
    "    x = layers.Dense(unidades)(x)\n",
    "    x = layers.Add()([x, atajo])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def construir_resnet_tabular(forma_entrada):\n",
    "    \"\"\"\n",
    "    Construye y compila un modelo tipo ResNet adaptado para datos tabulares.\n",
    "    \n",
    "    Parámetros:\n",
    "        forma_entrada (tuple): Forma de los datos de entrada (n_features,).\n",
    "\n",
    "    Retorna:\n",
    "        tensorflow.keras.Model: Modelo compilado listo para entrenamiento.\n",
    "    \"\"\"\n",
    "    entradas = layers.Input(shape=forma_entrada)\n",
    "    x = layers.Dense(64, activation='relu')(entradas)\n",
    "    x = bloque_residual(x, 64)\n",
    "    x = bloque_residual(x, 64)\n",
    "    x = layers.Dense(1, activation='sigmoid')(x)\n",
    "    modelo = models.Model(inputs=entradas, outputs=x)\n",
    "    modelo.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return modelo\n",
    "\n",
    "\n",
    "def entrenar_modelo(modelo, X_entrenamiento, y_entrenamiento, X_validacion, y_validacion, peso_clase):\n",
    "    \"\"\"\n",
    "    Entrena un modelo Keras con early stopping y reducción adaptativa de tasa de aprendizaje.\n",
    "    \n",
    "    Parámetros:\n",
    "        modelo (tensorflow.keras.Model): Modelo compilado a entrenar.\n",
    "        X_entrenamiento (array): Datos de entrenamiento.\n",
    "        y_entrenamiento (array): Etiquetas de entrenamiento.\n",
    "        X_validacion (array): Datos de validación.\n",
    "        y_validacion (array): Etiquetas de validación.\n",
    "        peso_clase (dict): Pesos para balancear clases.\n",
    "\n",
    "    Retorna:\n",
    "        tensorflow.keras.callbacks.History: Historial de entrenamiento.\n",
    "    \"\"\"\n",
    "    early_stop = callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
    "    reduce_lr = callbacks.ReduceLROnPlateau(patience=3, factor=0.5, min_lr=1e-6)\n",
    "    historial = modelo.fit(\n",
    "        X_entrenamiento, y_entrenamiento,\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_validacion, y_validacion),\n",
    "        class_weight=peso_clase,\n",
    "        callbacks=[early_stop, reduce_lr],\n",
    "        verbose=0\n",
    "    )\n",
    "    return historial\n",
    "\n",
    "def evaluar_modelo(modelo, X_prueba, y_prueba):\n",
    "    \"\"\"\n",
    "    Evalúa un modelo de clasificación binaria y calcula métricas de rendimiento.\n",
    "    \n",
    "    Parámetros:\n",
    "        modelo (tensorflow.keras.Model): Modelo entrenado.\n",
    "        X_prueba (array): Datos de prueba.\n",
    "        y_prueba (array): Etiquetas reales.\n",
    "\n",
    "    Retorna:\n",
    "        tuple: \n",
    "            - dict con métricas (accuracy, precision, recall, f1_score, roc_auc)\n",
    "            - array con probabilidades predichas.\n",
    "    \"\"\"\n",
    "    y_pred_prob = modelo.predict(X_prueba).flatten()\n",
    "    y_pred = (y_pred_prob >= 0.5).astype(int)\n",
    "    metricas = {\n",
    "        'accuracy': accuracy_score(y_prueba, y_pred),\n",
    "        'precision': precision_score(y_prueba, y_pred),\n",
    "        'recall': recall_score(y_prueba, y_pred),\n",
    "        'f1_score': f1_score(y_prueba, y_pred),\n",
    "        'roc_auc': roc_auc_score(y_prueba, y_pred_prob)\n",
    "    }\n",
    "    return metricas, y_pred_prob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58f8767",
   "metadata": {},
   "source": [
    "**Bloque 3:** Visualización de resultados e importancia de variables.\n",
    "\n",
    "- **`predecir_shap_silenciado()`** \n",
    "Función auxiliar que permite obtener predicciones del modelo sin mostrar salidas por consola, necesaria para evitar ruido durante el cálculo de valores SHAP.\n",
    "\n",
    "- **`graficar_shap()`** \n",
    "Genera gráficos de resumen SHAP para interpretar la importancia relativa de las características en distintos modelos. Facilita la comparación visual de interpretabilidad.\n",
    "\n",
    "- **`mostrar_tabla_comparativa()`** \n",
    "Presenta en formato tabular las métricas de rendimiento de un modelo DNN simple frente a un modelo ResNet tabular, permitiendo una comparación rápida.\n",
    "\n",
    "---\n",
    "\n",
    "### **Decisiones de diseño**\n",
    "\n",
    "##### **Justificación de `predecir_shap_silenciado()`:**\n",
    "\n",
    "- Durante el cálculo de valores SHAP, la función interna de predicción del modelo (model.predict) imprime múltiples logs en consola, especialmente cuando se trabaja con Keras/TensorFlow. Estos mensajes saturaban la salida y mezclaban información irrelevante con los gráficos SHAP, dificultando la interpretación visual. Por eso, se creó `predecir_shap_silenciado()`, que redirige la salida estándar a un buffer temporal, evitando que los logs interfieran con los resultados y manteniendo la consola limpia.\n",
    "\n",
    "##### **Uso de SHAP para mostrar la importancia de las variables:**\n",
    "\n",
    "- SHAP (SHapley Additive exPlanations) es una técnica basada en teoría de juegos que asigna una contribución a cada característica según su impacto en la predicción del modelo.\n",
    "\n",
    "- Se utiliza porque:\n",
    "    - Interpretabilidad global y local → Permite entender tanto el peso de cada variable en el modelo completo como en predicciones individuales.\n",
    "    - Consistencia matemática → Los valores SHAP garantizan que si una característica tiene mayor contribución, su valor asignado será siempre mayor que el de otra con menor influencia.\n",
    "    - Detección de relaciones no lineales → A diferencia de la simple importancia de características en árboles, SHAP captura interacciones complejas.\n",
    "    - Transparencia y confianza → Facilita explicar las decisiones del modelo a usuarios no técnicos, mejorando la trazabilidad en contextos críticos (salud, finanzas, etc.).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3efbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predecir_shap_silenciado(modelo, X):\n",
    "    \"\"\"\n",
    "    Realiza predicciones con un modelo silenciando la salida estándar \n",
    "    para evitar impresiones innecesarias durante el cálculo con SHAP.\n",
    "\n",
    "    Parámetros:\n",
    "        modelo: Modelo entrenado de Keras.\n",
    "        X (ndarray): Datos de entrada.\n",
    "\n",
    "    Retorna:\n",
    "        ndarray: Predicciones aplanadas del modelo.\n",
    "    \"\"\"\n",
    "    with contextlib.redirect_stdout(io.StringIO()):\n",
    "        predicciones = modelo.predict(X)\n",
    "    return predicciones.flatten()\n",
    "\n",
    "\n",
    "def graficar_shap(lista_modelos, X_muestra, nombres_caracteristicas, titulos):\n",
    "    \"\"\"\n",
    "    Genera gráficos de resumen SHAP para interpretar la importancia de \n",
    "    las características en varios modelos.\n",
    "\n",
    "    Parámetros:\n",
    "        lista_modelos (list): Lista de modelos entrenados.\n",
    "        X_muestra (ndarray): Subconjunto de datos para explicación.\n",
    "        nombres_caracteristicas (list): Nombres de las variables.\n",
    "        titulos (list): Títulos para cada gráfico.\n",
    "    \"\"\"\n",
    "    fondo = X_muestra[np.random.choice(X_muestra.shape[0], \n",
    "                                       min(50, X_muestra.shape[0]), \n",
    "                                       replace=False)]\n",
    "    for i, modelo in enumerate(lista_modelos):\n",
    "        print(f\"\\nGráfico SHAP para: {titulos[i]}\")\n",
    "        explicador = shap.KernelExplainer(lambda x: predecir_shap_silenciado(modelo, x), fondo)\n",
    "        valores_shap = explicador.shap_values(X_muestra, nsamples=100, progress=False)\n",
    "        shap.summary_plot(valores_shap, X_muestra, feature_names=nombres_caracteristicas, show=True)\n",
    "\n",
    "\n",
    "def mostrar_tabla_comparativa(metricas_simple, metricas_resnet):\n",
    "    \"\"\"\n",
    "    Muestra una tabla comparativa de métricas entre un modelo DNN simple y un ResNet tabular.\n",
    "\n",
    "    Parámetros:\n",
    "        metricas_simple (dict): Métricas del modelo DNN simple.\n",
    "        metricas_resnet (dict): Métricas del modelo ResNet tabular.\n",
    "    \"\"\"\n",
    "    df_metricas = pd.DataFrame([metricas_simple, metricas_resnet], \n",
    "                               index=['DNN Simple', 'ResNet Tabular'])\n",
    "    display(df_metricas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11307524",
   "metadata": {},
   "source": [
    "**Bloque 4:** Función de ejecución.\n",
    "\n",
    "- **`main()`** \n",
    "Función orquestadora que ejecuta todo el pipeline: carga y análisis de datos, preprocesamiento, construcción y entrenamiento de modelos, evaluación y comparación de métricas, análisis de explicabilidad con SHAP y recordatorio para análisis financiero.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ede4119",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Orquesta todo el flujo de trabajo del proyecto:\n",
    "    1. Carga y análisis inicial de los datos.\n",
    "    2. Preprocesamiento (división, escalado, codificación y pesos de clases).\n",
    "    3. Construcción de modelos (DNN simple y ResNet tabular).\n",
    "    4. Entrenamiento de modelos.\n",
    "    5. Evaluación y comparación de métricas.\n",
    "    6. Explicabilidad mediante SHAP.\n",
    "    7. Mensaje de recordatorio para análisis de impacto financiero.\n",
    "    \"\"\"\n",
    "    print(\"=== Cargando y analizando datos ===\")\n",
    "    datos = cargar_y_analizar_datos()\n",
    "\n",
    "    print(\"=== Preprocesando datos ===\")\n",
    "    X_entrenamiento, X_prueba, y_entrenamiento, y_prueba, preprocesador, pesos_clase = preprocesar_datos(datos)\n",
    "\n",
    "    forma_entrada = X_entrenamiento.shape[1]\n",
    "    print(f\"Dimensión de entrada para modelos: {forma_entrada}\")\n",
    "\n",
    "    print(\"=== Construyendo modelos ===\")\n",
    "    modelo_simple = construir_dnn_simple(forma_entrada)\n",
    "    modelo_resnet = construir_resnet_tabular(forma_entrada)\n",
    "\n",
    "    print(\"=== Entrenando modelo DNN simple ===\")\n",
    "    entrenar_modelo(modelo_simple, X_entrenamiento, y_entrenamiento, X_prueba, y_prueba, pesos_clase)\n",
    "\n",
    "    print(\"=== Entrenando modelo ResNet tabular ===\")\n",
    "    entrenar_modelo(modelo_resnet, X_entrenamiento, y_entrenamiento, X_prueba, y_prueba, pesos_clase)\n",
    "\n",
    "    print(\"=== Evaluando modelos ===\")\n",
    "    metricas_simple, y_prob_simple = evaluar_modelo(modelo_simple, X_prueba, y_prueba)\n",
    "    metricas_resnet, y_prob_resnet = evaluar_modelo(modelo_resnet, X_prueba, y_prueba)\n",
    "\n",
    "    mostrar_tabla_comparativa(metricas_simple, metricas_resnet)\n",
    "\n",
    "    print(\"=== Explicabilidad con SHAP ===\")\n",
    "    # Subconjunto para SHAP (ejemplo: primeras 100 muestras)\n",
    "    X_shap_muestra = X_prueba[:100]\n",
    "\n",
    "    # Nombres de características (numéricas + OneHot nominales)\n",
    "    nombres_caracteristicas = list(preprocesador.transformers_[0][2])  # numéricas\n",
    "    nombres_onehot = preprocesador.named_transformers_['cat']['onehot'].get_feature_names_out(\n",
    "        preprocesador.transformers_[1][2]\n",
    "    )\n",
    "    nombres_caracteristicas.extend(nombres_onehot)\n",
    "\n",
    "    graficar_shap(\n",
    "        [modelo_simple, modelo_resnet],\n",
    "        X_shap_muestra,\n",
    "        nombres_caracteristicas=nombres_caracteristicas,\n",
    "        titulos=['DNN Simple', 'ResNet Tabular']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efd13a3",
   "metadata": {},
   "source": [
    "# 4. Visualización de resultados\n",
    "\n",
    "Se muestran los resultados obtenidos a partir de la ejecución de la funcion **main()**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423c046a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f155a9",
   "metadata": {},
   "source": [
    "# 5. Análisis de los resultados y reflexiones finales\n",
    "\n",
    "---\n",
    "\n",
    "## Evaluación de las métricas obtenidas\n",
    "\n",
    "Las métricas de rendimiento, como la precisión y el recall, fueron bajas para ambos modelos, indicando que el dataset representa un desafío. El dataset german.data es conocido por ser pequeño (solo 1000 instancias), desbalanceado y de baja dimensionalidad.\n",
    "- Tamaño del Dataset: Con solo 1000 instancias, el modelo tiene un número limitado de ejemplos para aprender los patrones subyacentes. Esto aumenta la probabilidad de sobreajuste y dificulta la generalización a datos no vistos.\n",
    "- Desbalance de Clases: El desbalance de clases (700 casos de \"buen crédito\" frente a 300 de \"mal crédito\") complica el entrenamiento. Si bien se usaron pesos de clase para mitigar este problema, el modelo aún puede tener dificultades para aprender las características de la clase minoritaria (\"mal crédito\").\n",
    "- Naturaleza de los Datos: El dataset consta de 20 variables, muchas de ellas categóricas. La transformación one-hot encoding crea nuevas variables, pero los patrones no lineales y las interacciones entre ellas son difíciles de capturar para cualquier modelo, especialmente con un conjunto de datos pequeño.\n",
    "\n",
    "La DNN simple obtuvo un rendimiento ligeramente superior, especialmente en la métrica de recall, que es la más importante en este contexto.\n",
    "- Complejidad del Modelo: Una arquitectura más simple, como la DNN simple, puede ser más adecuada para un dataset pequeño y ruidoso. Una ResNet tabular, al ser una arquitectura más compleja con conexiones residuales, podría estar sobreajustándose a los datos de entrenamiento.\n",
    "- Sobreadaptación (Overfitting): La ResNet tabular es ideal para problemas más complejos y datasets más grandes donde las conexiones residuales pueden ayudar a mitigar el problema del gradiente evanescente y permitir que la red se profundice sin degradar el rendimiento. En un dataset pequeño, su complejidad podría haber capturado el ruido en lugar de las señales, lo que se traduce en una menor capacidad de generalización. La DNN simple tiene menos parámetros, lo que reduce el riesgo de sobreajuste y puede resultar en un modelo más robusto para este dataset en particular.\n",
    "\n",
    "---\n",
    "\n",
    "## Análisis de resultados en el contexto del impacto de errores tipo I y II\n",
    "\n",
    "En el ámbito financiero, los errores de clasificación tienen un impacto económico directo.\n",
    "- Error Tipo I (Falso Positivo): Ocurre cuando se deniega un crédito a un cliente que en realidad es de bajo riesgo. Esto se traduce en una pérdida de ingresos potenciales para el banco. En nuestras métricas, este error se relaciona con la precisión. Un valor bajo de precisión indica una alta tasa de Falsos Positivos.\n",
    "- Error Tipo II (Falso Negativo): Ocurre cuando se aprueba un crédito a un cliente que en realidad es de alto riesgo y terminará por no pagarlo. Esto se traduce en una pérdida de capital directa para el banco. Este error se relaciona con el recall. Un valor bajo de recall indica una alta tasa de Falsos Negativos.\n",
    "\n",
    "En este contexto, podemos evaluar los dos modelos probados en este trabajo:\n",
    "- DNN simple:\n",
    "  - Recall (0.70): La DNN simple es mejor detectando a los clientes que realmente son malos créditos (clase 1). Captura el 70% de los casos de \"mal crédito\". Esto significa que su tasa de Falsos Negativos (Errores Tipo II) es menor que la de la ResNet. Desde una perspectiva financiera, esto es muy valioso, ya que reduce la pérdida de capital al evitar otorgar préstamos a una mayor proporción de clientes que no pagarían.\n",
    "  - Precision (0.55): Sin embargo, al ser más \"sensible\", también clasifica incorrectamente a más clientes como malos créditos (Falsos Positivos). Esto se refleja en su precisión, lo que indica que pierde más ingresos potenciales al rechazar a clientes que sí podrían pagar.\n",
    "- ResNet Tabular:\n",
    "  - Recall (0.62): La ResNet tabular tiene un recall más bajo, lo que significa que su tasa de Falsos Negativos (Errores Tipo II) es más alta. Detecta menos de los malos créditos reales, lo que podría llevar a mayores pérdidas de capital por impago.\n",
    "  - Precision (0.54): Su precisión es ligeramente inferior, pero no de forma significativa. Esto sugiere un comportamiento similar en términos de Falsos Positivos.\n",
    "\n",
    "En el contexto financiero, donde los errores tipo II (otorgar un mal crédito) son generalmente mucho más costosos que los errores tipo I (denegar un buen crédito), el modelo Simple DNN sería la mejor opción. Su mayor recall (70% vs. 62%) indica que es más efectivo a la hora de identificar a los clientes de alto riesgo, lo que se traduce directamente en una menor exposición a pérdidas por impagos.\n",
    "\n",
    "Aunque la DNN simple tiene una precisión ligeramente menor, el costo de un impago suele ser tan elevado que la prioridad es minimizar el recall. Si bien se perderán algunos clientes potenciales (Falsos Positivos), se evitará una mayor cantidad de préstamos incobrables.\n",
    "\n",
    "## Análisis de la importancia de variables visualizadas con SHAP\n",
    "\n",
    "Los gráficos SHAP (SHapley Additive exPlanations) que proporcionaste visualizan la importancia e impacto de cada característica en la predicción de los dos modelos de redes neuronales (una DNN simple y una ResNet tabular) para el riesgo de crédito. Un punto en el gráfico representa una instancia individual del conjunto de datos.\n",
    "\n",
    "- El eje X muestra el valor SHAP, que es el impacto de la característica en el \"output\" (predicción) del modelo.\n",
    "  - Valores positivos impulsan la predicción a ser un mal crédito (el target y=1).\n",
    "  - Valores negativos impulsan la predicción a ser un buen crédito (el target y=0).\n",
    "- El eje Y lista las características del conjunto de datos, ordenadas por su importancia media.\n",
    "- El color de los puntos indica el valor real de la característica para esa instancia.\n",
    "  - El rojo (High) indica un valor alto de la característica.\n",
    "  - El azul (Low) indica un valor bajo de la característica.\n",
    "\n",
    "### Comparación de variables entre Modelos (DNN vs. ResNet)\n",
    "\n",
    "Ambos gráficos identifican las mismas características principales como las más influyentes, lo cual es un buen indicio de que ambos modelos están aprendiendo patrones similares en los datos. No obstante, hay sutiles diferencias que vale la pena notar.\n",
    "\n",
    "En ambos modelos, las características más importantes para predecir el riesgo de crédito son:\n",
    "- checking_status: Es la característica más influyente con diferencia.\n",
    "  - Valores altos (rojo) (indicando una cuenta corriente con poco o ningún saldo) tienen un impacto positivo en el valor SHAP, lo que significa que aumentan la probabilidad de ser un mal crédito.\n",
    "  - Valores bajos (azul) (indicando un buen saldo) tienen un impacto negativo, disminuyendo la probabilidad de ser un mal crédito. Este es un resultado intuitivo y esperado en el análisis de riesgo crediticio.\n",
    "- duration (duración del crédito):\n",
    "  - Valores altos (rojo) (créditos a largo plazo) tienen un impacto positivo y están asociados a un mayor riesgo.\n",
    "  - Valores bajos (azul) (créditos a corto plazo) tienen un impacto negativo, sugiriendo menor riesgo. Esto también es coherente con la práctica bancaria, donde plazos más largos implican mayor incertidumbre.\n",
    "- savings (ahorros):\n",
    "  - Valores altos (rojo) (ahorros considerables) tienen un impacto negativo en el valor SHAP, reduciendo el riesgo de ser un mal crédito.\n",
    "  - Valores bajos (azul) (pocos o ningún ahorro) tienen un impacto positivo, aumentando el riesgo.\n",
    "\n",
    "---\n",
    "\n",
    "## Reflexiones\n",
    "\n",
    "### Ética, Sesgos Posibles y Decisiones no Explicadas\n",
    "\n",
    "El modelo de riesgo crediticio, si no se gestiona con cuidado, puede perpetuar y amplificar sesgos existentes en los datos.\n",
    "\n",
    "- Sesgos en los datos: El conjunto de datos german.data ya podría contener sesgos históricos. Por ejemplo, si los bancos históricamente han denegado más créditos a ciertos grupos demográficos, el modelo podría aprender esta correlación y continuar denegándolos, aunque no haya una base real en la solvencia. Las variables como age, job, personal_status y residence_since son especialmente sensibles al sesgo. Por ejemplo, si el modelo usa age para inferir que los jóvenes son de mayor riesgo, podría estar tomando una decisión sesgada.\n",
    "\n",
    "- Decisiones no explicadas (Black Box): Las redes neuronales profundas, como las que usamos, son a menudo \"cajas negras\" (black box). Esto significa que no es fácil entender por qué el modelo tomó una decisión específica para un individuo. Sin herramientas de explicabilidad, un oficial de crédito no podría justificar la denegación de un préstamo más allá de decir: \"El modelo lo predijo así\". Esto es éticamente problemático y puede llevar a la discriminación sin intención. La ausencia de transparencia dificulta la auditoría y la detección de sesgos.\n",
    "\n",
    "- Riesgo de discriminación: Si el modelo utiliza indirectamente variables que están correlacionadas con atributos protegidos (como origen étnico o género), podría discriminar sin que las variables explícitas estén presentes. Por ejemplo, la variable foreign_worker o incluso el residence_since podrían tener correlaciones con variables protegidas. La falta de transparencia podría ocultar esta discriminación.\n",
    "\n",
    "### ¿Puede explicarse este modelo a un equipo de riesgo bancario?\n",
    "\n",
    "Sí, este modelo puede explicarse a un equipo de riesgo bancario, y de hecho, es esencial hacerlo como parte de la explicabilidad de los modelos. Para esto, no basta con mostrar solo la precisión o el recall del modelo; la clave está en el uso de herramientas como SHAP.\n",
    "\n",
    "- SHAP (SHapley Additive exPlanations): Los gráficos SHAP que generaste son la herramienta perfecta para esta tarea. Permiten transformar la \"caja negra\" del modelo en un sistema explicable.\n",
    "  - Identificación de los factores de riesgo: Un analista puede mostrar el gráfico y decir: \"La duración del préstamo, el estado de la cuenta corriente y el nivel de ahorros son los factores más importantes que el modelo considera para evaluar el riesgo\". Esto alinea las decisiones del modelo con el conocimiento y la intuición del equipo de riesgo.\n",
    "  - Explicación de casos individuales: SHAP también permite generar explicaciones para una predicción individual. Por ejemplo, si el modelo deniega un préstamo, se puede generar un gráfico para ese cliente específico que muestre qué características (un saldo bajo, una larga duración del préstamo) contribuyeron más a la decisión de alto riesgo.\n",
    "\n",
    "- Balanceo de errores: La discusión sobre el recall y la precision es también fundamental para el equipo de riesgo. Se puede explicar que el modelo de DNN se eligió por su alto recall para minimizar las pérdidas por impago (Falsos Negativos), lo cual es la prioridad financiera del banco. Se debe ser transparente y admitir que esto conlleva una tasa más alta de rechazos a clientes que sí pagarían (Falsos Positivos), y discutir si ese equilibrio es aceptable.\n",
    "- Validación de conocimientos: Al presentar los resultados, un equipo de riesgo puede validar si los hallazgos del modelo concuerdan con su experiencia. Por ejemplo, el hecho de que checking_status sea la característica más importante confirma la intuición de que el flujo de caja del cliente es el principal predictor de riesgo.\n",
    "\n",
    "En conclusión, la combinación de métricas de rendimiento (especialmente recall) y herramientas de explicabilidad como SHAP hace que estos modelos de IA sean no solo útiles, sino también explicables y auditables para un equipo de riesgo bancario. Esto es vital para generar confianza, cumplir con regulaciones y tomar decisiones financieras responsables.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
