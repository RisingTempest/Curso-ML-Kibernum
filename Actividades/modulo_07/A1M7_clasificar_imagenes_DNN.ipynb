{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27fb2adb",
   "metadata": {},
   "source": [
    "# Módulo 7 - Actividad 1:\n",
    "# Clasificador de imágenes manuscrites con redes neuronales profundas\n",
    "\n",
    "## Objetivo\n",
    "Implementar una red neuronal completamente conectada para clasificar imágenes del dataset Fashion MNIST. El estudiante deberá explorar diferentes combinaciones de capas, funciones de activación, funciones de pérdida y optimizadores, evaluar su rendimiento y reflexionar sobre los resultados.\n",
    "\n",
    "**Datasets utilizados:**  \n",
    "`Fashion MNIST`\n",
    "\n",
    "---\n",
    "\n",
    "### Estructura del Notebook:\n",
    "1. Metodología.\n",
    "2. Configuración del entorno.\n",
    "3. Definicion de funciones.\n",
    "4. Uso de funciones y resultados.\n",
    "5. Análisis de los resultados y reflexiones finales.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df325f9",
   "metadata": {},
   "source": [
    "## 1. Metodología\n",
    "\n",
    "### Flujo de trabajo\n",
    "\n",
    "1. **Carga, escalado y One-Hot Encoding:**\n",
    "    - Se carga el dataset **Fashion MNIST** y se escala y se realiza One-Hot Encoding.\n",
    "\n",
    "2. **Creación de modelo y aplicación del mismo con diferentes configuraciones:**\n",
    "    - Define una función para la creación de una red neuronal secuencial con 2 capas ocultas y softmax en la salida.\n",
    "    - Define una función para entrenar el modelo anterior.\n",
    "    - Entrena el modelo en base a diferentes configuraciones de funciones de pérdida y optimizadores:\n",
    "        - categorical_crossentropy + adam\n",
    "        - categorical_crossentropy + sgd\n",
    "        - mse + adam\n",
    "        - mse + sgd\n",
    "\n",
    "3. **Visualización e interpretación:**\n",
    "    - Tabla resumen con la función de perdida y optimizador usado, además de test accuracy y test loss.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d1608a",
   "metadata": {},
   "source": [
    "# 2. Configuración del entorno\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf63fb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726f8194",
   "metadata": {},
   "source": [
    "# 3. Definición de funciones\n",
    "\n",
    "> **Nota:** Para mejor comprensión de las funciones y su utilidad, esta sección se divide en bloques, en donde cada uno responde a una parte diferente de la metodología de trabajo. \n",
    "\n",
    "---\n",
    "\n",
    "**Bloque 1:** Carga y preprocesamiento de datos.\n",
    "\n",
    "- **`cargar_datos()`** \n",
    "Carga el dataset Fashion MNIST, lo normaliza y aplica one-hot encoding a las etiquetas.\n",
    "\n",
    "---\n",
    "\n",
    "##### `Decisiones de diseño`\n",
    "\n",
    "##### **Escalado y One-Hot Encoding:**\n",
    "\n",
    "- Las imágenes del dataset Fashion MNIST contienen valores de píxeles que van de 0 a 255. Escalar estos valores a un rango entre 0 y 1 (dividiendo por 255) ayuda a que el modelo entrene más rápido y de manera más estable, ya que redes neuronales suelen converger mejor cuando las entradas están normalizadas. Además, reduce problemas numéricos relacionados con valores muy grandes y ayuda a que las funciones de activación como ReLU o sigmoid funcionen dentro de rangos óptimos.\n",
    "\n",
    "- Las etiquetas originales son enteros que indican la clase (0 a 9). Convertirlas a formato one-hot (vectores binarios donde solo la posición de la clase correcta es 1 y el resto 0) es necesario para tareas de clasificación con redes neuronales, especialmente cuando se usa una función de pérdida como categorical_crossentropy. Este formato permite que el modelo aprenda a predecir la probabilidad de cada clase y facilita el cálculo del error durante el entrenamiento.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66815ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_datos():\n",
    "    \"\"\"\n",
    "    Carga y preprocesa el dataset Fashion MNIST.\n",
    "\n",
    "    - Normaliza los valores de los píxeles a un rango entre 0 y 1.\n",
    "    - Convierte las etiquetas a codificación one-hot.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (x_train, y_train_oh, x_test, y_test_oh)\n",
    "            - x_train (ndarray): Imágenes de entrenamiento normalizadas.\n",
    "            - y_train_oh (ndarray): Etiquetas de entrenamiento en formato one-hot.\n",
    "            - x_test (ndarray): Imágenes de prueba normalizadas.\n",
    "            - y_test_oh (ndarray): Etiquetas de prueba en formato one-hot.\n",
    "    \"\"\"\n",
    "    (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "    y_train_oh = to_categorical(y_train, 10)\n",
    "    y_test_oh = to_categorical(y_test, 10)\n",
    "    return x_train, y_train_oh, x_test, y_test_oh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31225e7",
   "metadata": {},
   "source": [
    "**Bloque 2:** Definición y entrenamiento de modelos.\n",
    "\n",
    "- **`build_model()`** \n",
    "Construye una red neuronal secuencial con dos capas ocultas y salida softmax para clasificación multiclase.\n",
    "\n",
    "- **`train_model()`** \n",
    "Compila y entrena el modelo usando los datos de entrenamiento y validación con los parámetros indicados.\n",
    "\n",
    "- **`entrenamientos()`** \n",
    "Ejecuta entrenamientos con distintas combinaciones de funciones de pérdida y optimizadores, registrando resultados.\n",
    "\n",
    "---\n",
    "\n",
    "##### `Decisiones de diseño`\n",
    "\n",
    "##### **Eleccion de multiples funciones sobre una sola que cree y entrene el modelo:**\n",
    "\n",
    "- Dividir el código en funciones pequeñas y específicas mejora la claridad, facilita el mantenimiento y permite reutilizar partes del código fácilmente. Al usar build_model dentro de train_model y esta dentro de entrenamientos, se mantiene una estructura modular que simplifica probar distintas configuraciones, hacer cambios puntuales y escalar el proyecto sin que el código se vuelva confuso o difícil de manejar.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040b5617",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(activation1='relu', activation2='tanh'):\n",
    "    \"\"\"\n",
    "    Construye una red neuronal secuencial con dos capas ocultas y softmax en la salida.\n",
    "\n",
    "    Args:\n",
    "        activation1 (str): Función de activación de la primera capa oculta. Default 'relu'.\n",
    "        activation2 (str): Función de activación de la segunda capa oculta. Default 'tanh'.\n",
    "\n",
    "    Returns:\n",
    "        keras.Model: Modelo compilado sin entrenar.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(28, 28)))\n",
    "    model.add(Dense(128, activation=activation1))\n",
    "    model.add(Dense(64, activation=activation2))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "def train_model(x_train, y_train_oh, loss, optimizer, epochs=10):\n",
    "    \"\"\"\n",
    "    Compila y entrena un modelo con una función de pérdida y optimizador dados.\n",
    "\n",
    "    Usa los datos globales `x_train` y `y_train_oh`.\n",
    "\n",
    "    Args:\n",
    "        x_train (ndarray): Datos de entrenamiento normalizados.\n",
    "        y_train_oh (ndarray): Etiquetas de entrenamiento en formato one-hot.\n",
    "        loss (str): Nombre de la función de pérdida ('categorical_crossentropy' o 'mse').\n",
    "        optimizer (str): Optimizador a usar ('adam', 'sgd', etc.).\n",
    "        epochs (int): Número de épocas para entrenar. Default 10.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (modelo entrenado, historial de entrenamiento)\n",
    "    \"\"\"\n",
    "    model = build_model()\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "    history = model.fit(\n",
    "        x_train, y_train_oh,\n",
    "        validation_split=0.2,\n",
    "        epochs=epochs,\n",
    "        batch_size=128,\n",
    "        verbose=0\n",
    "    )\n",
    "    return model, history\n",
    "\n",
    "def entrenamientos(x_train, y_train_oh, x_test, y_test_oh, epochs=10):\n",
    "    \"\"\"\n",
    "    Entrena el modelo con distintas combinaciones de funciones de pérdida y optimizadores.\n",
    "\n",
    "    Evalúa cada modelo en el conjunto de prueba.\n",
    "\n",
    "    Args:\n",
    "        x_train (ndarray): Datos de entrenamiento normalizados.\n",
    "        y_train_oh (ndarray): Etiquetas de entrenamiento en formato one-hot.\n",
    "        x_test (ndarray): Datos de prueba normalizados.\n",
    "        y_test_oh (ndarray): Etiquetas de prueba en formato one-hot.\n",
    "        epochs (int): Número de épocas para cada entrenamiento. Default 10.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (resultados, historial)\n",
    "            - resultados (list): Lista de dicts con métricas de evaluación.\n",
    "            - historias (list): Lista de tuplas (loss, opt, history).\n",
    "    \"\"\"\n",
    "    resultados = []\n",
    "    historial = []\n",
    "\n",
    "    combinaciones = [\n",
    "        ('categorical_crossentropy', 'adam'),\n",
    "        ('categorical_crossentropy', 'sgd'),\n",
    "        ('mse', 'adam'),\n",
    "        ('mse', 'sgd'),\n",
    "    ]\n",
    "\n",
    "    for loss, opt in combinaciones:\n",
    "        print(f\"--- Entrenando con loss={loss}, optimizer={opt} ---\")\n",
    "        model, history = train_model(x_test, y_test_oh, loss, opt, epochs=epochs)\n",
    "\n",
    "        test_loss, test_acc = model.evaluate(x_test, y_test_oh, verbose=0)\n",
    "        resultados.append({\n",
    "            'Loss Function': loss,\n",
    "            'Optimizer': opt,\n",
    "            'Test Accuracy': test_acc,\n",
    "            'Test Loss': test_loss\n",
    "        })\n",
    "\n",
    "        historial.append((loss, opt, history))\n",
    "\n",
    "    return resultados, historial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f702dc05",
   "metadata": {},
   "source": [
    "**Bloque 3:** Visualizaciones.\n",
    "\n",
    "- **`mostrar_resultados()`** \n",
    "Muestra una tabla comparativa con la precisión y pérdida del conjunto de prueba para cada experimento.\n",
    "\n",
    "- **`graficar_historias()`** \n",
    "Genera gráficos de las curvas de pérdida y precisión de entrenamiento y validación para cada combinación evaluada.\n",
    "\n",
    "---\n",
    "\n",
    "##### `Decisiones de diseño`\n",
    "\n",
    "##### **Justificación para graficar las curvas de pérdida y precisión:**\n",
    "\n",
    "- Visualizar las curvas de pérdida y precisión durante el entrenamiento permite entender cómo evoluciona el aprendizaje del modelo en cada época, identificar posibles problemas como sobreajuste o subajuste, y comparar el desempeño entre diferentes configuraciones. Estas gráficas facilitan interpretar la estabilidad y eficacia del entrenamiento, ayudando a tomar decisiones informadas para mejorar el modelo.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31d8591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostrar_resultados(resultados):\n",
    "    \"\"\"\n",
    "    Muestra una tabla con los resultados de los experimentos.\n",
    "\n",
    "    Args:\n",
    "        resultados (list): Lista de diccionarios con métricas de evaluación.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: Tabla de resultados mostrada y devuelta.\n",
    "    \"\"\"\n",
    "    df_resultados = pd.DataFrame(resultados)\n",
    "    print(\"\\n===== Comparación de resultados en test =====\")\n",
    "    df_resultados.to_string(index=False)\n",
    "    display(df_resultados)\n",
    "    return df_resultados\n",
    "\n",
    "def graficar_historias(historial):\n",
    "    \"\"\"\n",
    "    Grafica curvas de pérdida y precisión para cada combinación entrenada.\n",
    "\n",
    "    Args:\n",
    "        historias (list): Lista de tuplas (loss, opt, history) de cada experimento.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(14, 10))\n",
    "\n",
    "    for i, (loss, opt, history) in enumerate(historial):\n",
    "        plt.subplot(2, 2, i + 1)\n",
    "        plt.plot(history.history['loss'], label='Train Loss')\n",
    "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "        plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "        plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "        plt.title(f'{opt.capitalize()} con {loss.capitalize()}')\n",
    "        #plt.title(f'{loss} + {opt}')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Metric')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67415a58",
   "metadata": {},
   "source": [
    "**Bloque 4:** Función de ejecución.\n",
    "\n",
    "- **`main()`** \n",
    "Ejecuta el pipeline completo de carga, entrenamiento y visualización de resultados.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e4aa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Punto de entrada del programa:\n",
    "    - Carga y prepara los datos.\n",
    "    - Ejecuta los entrenamientos con combinaciones de pérdida/optimizador.\n",
    "    - Muestra resultados en tabla y gráficos.\n",
    "    \"\"\"\n",
    "    # Carga de datos\n",
    "    x_train, y_train_oh, x_test, y_test_oh = cargar_datos()\n",
    "\n",
    "    # Entrenamiento de modelos con diferentes configuraciones\n",
    "    resultados, historial = entrenamientos(x_train, y_train_oh, x_test, y_test_oh,epochs=10)\n",
    "\n",
    "    # Visualización de los resultados comparativos en tablas y gráficas\n",
    "    mostrar_resultados(resultados)\n",
    "    graficar_historias(historial)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13518912",
   "metadata": {},
   "source": [
    "# 4. Visualización de resultados\n",
    "\n",
    "Se muestran los resultados obtenidos a partir de la ejecución de la funcion **main()**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526ad22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f1e87e",
   "metadata": {},
   "source": [
    "# 5. Análisis de los resultados y reflexiones finales\n",
    "\n",
    "---\n",
    "\n",
    "## Análisis comparativo de una red neuronal con diferentes configuraciones\n",
    "\n",
    "> Nota: el análisis se realizo en base a una ejecución en concreto, por lo que los valores podrían cambiar entre ejecuciones, sin embargo, la base no cambia, solo varían un poco los valores pero siguen siendo igual de representativos para la evaluación.\n",
    "\n",
    "#### 1. ¿Qué combinación funcionó mejor y por qué?\n",
    "\n",
    "- La combinación que obtuvo mejor desempeño fue categorical_crossentropy con el optimizador adam, alcanzando un accuracy en test cercano al 88.6%. Este resultado se explica porque la función de pérdida categorical_crossentropy es la más adecuada para problemas de clasificación multiclase, al penalizar de manera efectiva las predicciones incorrectas y guiar mejor el aprendizaje. Por otro lado, el optimizador adam ajusta dinámicamente la tasa de aprendizaje para cada parámetro, acelerando la convergencia y mejorando la estabilidad durante el entrenamiento. Las curvas de pérdida y precisión muestran una mejora consistente y un buen balance entre entrenamiento y validación, indicando que el modelo generaliza bien sin sobreajustar.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. ¿Qué efectos tuviste al cambiar funciones de activación o pérdida?\n",
    "\n",
    "- En cuanto a las funciones de pérdida, se observa que aunque el mse logró un accuracy alto con adam (~88.2%), su valor numérico de pérdida fue inusualmente bajo, lo que puede ser engañoso y no refleja adecuadamente la calidad del modelo para clasificación. Además, cuando se usó sgd con mse, el modelo no aprendió correctamente, con un accuracy muy bajo (17.3%), indicando que esta combinación no es adecuada para esta tarea. En contraste, la función categorical_crossentropy mostró una convergencia más rápida y mejores resultados con ambos optimizadores, especialmente con adam.\n",
    "\n",
    "- Respecto a las funciones de activación, se mantuvieron constantes: ReLU en la primera capa y Tanh en la segunda. Esta combinación equilibra la eficiencia del aprendizaje inicial (gracias a ReLU) con la capacidad de modelar relaciones no lineales más suaves (gracias a Tanh). Dado que no se variaron estas activaciones entre experimentos, el cambio en rendimiento se atribuye principalmente a la función de pérdida y el optimizador.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. ¿Qué harías diferente si tuvieras más datos o más tiempo de entrenamiento?\n",
    "\n",
    "- Con más datos disponibles, se podría considerar aumentar la complejidad del modelo, añadiendo más capas o neuronas, junto con técnicas de regularización como Dropout o Batch Normalization para evitar sobreajuste. Esto aprovecharía mejor la riqueza de los datos adicionales para mejorar la generalización.\n",
    "\n",
    "- Si se dispusiera de más tiempo para entrenar, sería recomendable extender el número de épocas (por ejemplo, a 20 o 30) y utilizar técnicas como EarlyStopping para evitar el sobreentrenamiento. También valdría la pena experimentar con el tamaño del batch para optimizar el proceso de entrenamiento y aplicar esquemas de ajuste dinámico de la tasa de aprendizaje (learning rate schedules), especialmente cuando se usa SGD.\n",
    "\n",
    "- Finalmente, para optimizar hiperparámetros, herramientas automáticas como Optuna o Grid Search podrían explorar distintas configuraciones, incluyendo la cantidad de neuronas, funciones de activación alternativas (LeakyReLU, ELU), y parámetros del optimizador (learning rate, momentum), buscando el mejor equilibrio entre precisión y eficiencia.\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusión\n",
    "\n",
    "La combinación categorical_crossentropy + adam resultó ser la más efectiva, proporcionando el mejor balance entre precisión y estabilidad en el entrenamiento. Aunque mse mostró resultados competitivos con adam, no es la función de pérdida recomendada para clasificación multiclase, y su desempeño fue pobre con SGD. Para futuros trabajos, se sugiere aumentar la capacidad del modelo y el tiempo de entrenamiento, aplicando técnicas de regularización y ajuste fino de hiperparámetros para maximizar el rendimiento y la robustez del modelo.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
