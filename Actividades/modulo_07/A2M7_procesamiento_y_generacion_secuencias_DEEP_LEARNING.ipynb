{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfdec1b0",
   "metadata": {},
   "source": [
    "# Módulo 7 - Actividad 2:\n",
    "# Del análisis al arte: procesamiento y generación de secuencias con Deep Learning\n",
    "\n",
    "## Objetivo\n",
    "Comprender el comportamiento de ambos modelos (secuencial y generativo), evaluar sus resultados y reflexionar sobre su aplicación en contextos distintos.\n",
    "\n",
    "**Datasets utilizados:**  \n",
    "`IMDb`\n",
    "`MNIST`\n",
    "\n",
    "---\n",
    "\n",
    "### Estructura del Notebook:\n",
    "1. Metodología.\n",
    "2. Configuración del entorno.\n",
    "3. Definicion de funciones.\n",
    "4. Uso de funciones y resultados.\n",
    "5. Análisis de los resultados y reflexiones finales.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18937015",
   "metadata": {},
   "source": [
    "## 1. Metodología\n",
    "\n",
    "### Flujo de trabajo\n",
    "\n",
    "> Para mejorar el entendimiento del código, en vez de agrupar todas las visualizaciones en una celda aparte, esta vez de decidió dejar cada visualización en el modelo que corresponden, debido a que, si bien ambas son redes neuronales, cumplen roles totalmente diferentes como lo son RNN y GAN.\n",
    "\n",
    "1. **Carga y preprocesamiento de datos:**\n",
    "    - Se cargan los dataset **IMDb** y **MNIST**, igualando las longitudes para el primer set y normalizando los datos para el segundo.\n",
    "\n",
    "2. **Creación, entrenamiento y visualización de modelo RNN usando LSTM:**\n",
    "    - Se crea un modelo LSTM, se entrena y se evalúa:\n",
    "        - Se utilizó como optimizer \"adam\", como función de pérdida \"binary_crossentropy\" y como métrica \"accuracy\".\n",
    "    - Tabla resumen de los datos de accuracy y loss para cada epoch en el modelo LSTM aplicado al dataset IMDb y tabla de accuracy y loss para el conjunto de prueba.\n",
    "    - Gráficos comparativos de accuracy y loss para los datos de entrenamiento y validación.\n",
    "    - Matriz de confusión de los datos de IMDb con el modelo LSTM.\n",
    "\n",
    "3. **Creación y entrenamiento de modelo GAN:**\n",
    "    - Se crea un modelo GAN con un generador y un discriminador, y luego se entrena y evalúa.\n",
    "    - Datos de loss para el generador y el discriminador y accuracy cada 100 epoch en el modelo GAN con los datos de MNIST.\n",
    "    - Gráfico de la evolución de accuracy y loss de GAP en función de cada epoch.\n",
    "    - Grilla de imagenes guardadas generadas con GAP de los datos de IMDb cada 500 epoch.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e78ecbf",
   "metadata": {},
   "source": [
    "# 2. Configuración del entorno\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f974a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb, mnist\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, LeakyReLU, Input\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import os\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Establecer seeds\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "# Crear carpeta de salida para imágenes generadas\n",
    "os.makedirs(\"gan_images\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60480905",
   "metadata": {},
   "source": [
    "# 3. Definición de funciones\n",
    "\n",
    "> **Nota:** Para mejor comprensión de las funciones y su utilidad, esta sección se divide en bloques, en donde cada uno responde a una parte diferente de la metodología de trabajo. \n",
    "\n",
    "---\n",
    "\n",
    "**Bloque 1:** Carga y preprocesamiento de datos.\n",
    "\n",
    "- **`cargar_y_preprocesar_datasets()`** \n",
    "Carga y preprocesa los datasets IMDb (con padding) y MNIST (normalización y reshape).\n",
    "\n",
    "---\n",
    "\n",
    "##### `Decisiones de diseño`\n",
    "\n",
    "##### **IMDb – Clasificación de sentimientos con LSTM:**\n",
    "\n",
    "- Razón del padding (pad_sequences):\n",
    "    - Las reseñas de IMDb vienen como listas de enteros (tokens) de distinta longitud.\n",
    "    - Las redes LSTM requieren que todas las secuencias tengan la misma longitud, por lo que usamos pad_sequences con maxlen=200 para truncar o rellenar con ceros.\n",
    "\n",
    "- Elegir maxlen=200 asegura que:\n",
    "    - Se conserve la mayor parte de la información importante.\n",
    "    - Se mantenga una longitud manejable para el modelo (menos cómputo, menos overfitting).\n",
    "\n",
    "##### **MNIST – Generación de dígitos con GAN:**\n",
    "\n",
    "- Normalización (/ 255.0):\n",
    "    - Los píxeles de las imágenes van de 0 a 255. Dividir por 255 los lleva al rango [0, 1], lo cual:\n",
    "    - Mejora la estabilidad numérica del entrenamiento.\n",
    "    - Es compatible con la salida del generador (que usa sigmoid).\n",
    "\n",
    "- Aplanamiento (reshape(-1, 784)):\n",
    "    - La GAN usa capas Dense, que requieren vectores planos. Por eso se transforma cada imagen de 28×28 a 784 dimensiones.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca65ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_y_preprocesar_datasets():\n",
    "    \"\"\"\n",
    "    Carga y preprocesa los datasets IMDb (para LSTM) y MNIST (para GAN).\n",
    "\n",
    "    - Para IMDb: aplica padding a las secuencias de texto para que tengan una longitud fija.\n",
    "    - Para MNIST: normaliza las imágenes y las aplana a vectores de 784 dimensiones.\n",
    "\n",
    "    Returns:\n",
    "        tuple: \n",
    "            - (x_train_imdb, y_train_imdb, x_test_imdb, y_test_imdb): Datos preprocesados del dataset IMDb.\n",
    "            - x_train_mnist (ndarray): Imágenes normalizadas y aplanadas del dataset MNIST (solo datos de entrenamiento).\n",
    "    \"\"\"\n",
    "    # IMDb: carga y padding\n",
    "    num_words = 10000\n",
    "    maxlen = 200\n",
    "    (x_train_imdb, y_train_imdb), (x_test_imdb, y_test_imdb) = imdb.load_data(num_words=num_words)\n",
    "    x_train_imdb = pad_sequences(x_train_imdb, maxlen=maxlen)\n",
    "    x_test_imdb = pad_sequences(x_test_imdb, maxlen=maxlen)\n",
    "\n",
    "    # MNIST: carga y normalización\n",
    "    (x_train_mnist, _), (_, _) = mnist.load_data()\n",
    "    x_train_mnist = x_train_mnist.reshape(-1, 784).astype('float32') / 255.0\n",
    "\n",
    "    return (x_train_imdb, y_train_imdb, x_test_imdb, y_test_imdb), x_train_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ad457d",
   "metadata": {},
   "source": [
    "**Bloque 2:** Aplicación de RNN.\n",
    "\n",
    "- **`construir_modelo_lstm()`** \n",
    "Construye y compila un modelo LSTM para clasificación binaria con embedding.\n",
    "\n",
    "- **`entrenar_y_evaluar_lstm()`** \n",
    "Entrena el modelo LSTM y evalúa su desempeño en el conjunto test.\n",
    "\n",
    "- **`visualizar_resultados_lstm()`** \n",
    "Muestra tablas, gráficas y matriz de confusión del entrenamiento y evaluación LSTM.\n",
    "\n",
    "---\n",
    "\n",
    "##### `Decisiones de diseño`\n",
    "\n",
    "##### **Justificación del modelo LSTM:**\n",
    "\n",
    "- Capa Embedding\n",
    "    - Se utiliza una capa Embedding para transformar las secuencias de enteros (que representan palabras) en vectores densos de 128 dimensiones. Esta transformación permite que el modelo aprenda representaciones vectoriales útiles del lenguaje, donde palabras con significado similar pueden ocupar posiciones cercanas en el espacio. A diferencia de una codificación one-hot (que sería muy dispersa y de alta dimensionalidad), el embedding es eficiente y se ajusta durante el entrenamiento para captar patrones semánticos y sintácticos del texto.\n",
    "\n",
    "- Capa LSTM\n",
    "    - La capa LSTM (Long Short-Term Memory) permite al modelo procesar secuencias considerando el orden de las palabras y las dependencias a largo plazo dentro del texto. A diferencia de las redes densas, las LSTM están diseñadas específicamente para datos secuenciales, y su arquitectura con \"puertas\" internas permite decidir qué información conservar, olvidar o transmitir a lo largo de la secuencia. Esto es fundamental en tareas como análisis de sentimientos, donde el contexto y la posición de las palabras (por ejemplo, \"no me gustó\") son clave para una clasificación correcta.\n",
    "\n",
    "- Capa Dense(1, activation='sigmoid')\n",
    "    - La última capa del modelo es densa, con una sola neurona y activación sigmoid, ya que se trata de una tarea de clasificación binaria: cada reseña debe ser clasificada como positiva o negativa. La función sigmoid devuelve un valor entre 0 y 1, lo que puede interpretarse como la probabilidad de que la reseña sea positiva. Este valor probabilístico facilita tanto la interpretación como la aplicación de umbrales para la clasificación final.\n",
    "\n",
    "- Función de pérdida binary_crossentropy\n",
    "    - Se emplea la función de pérdida binary_crossentropy porque es la más adecuada para clasificación binaria. Esta función mide la divergencia entre las etiquetas verdaderas (0 o 1) y las probabilidades predichas por el modelo, penalizando más fuertemente las predicciones incorrectas que se alejan mucho del valor real. Su uso permite entrenar el modelo de forma que aprenda a asignar probabilidades más precisas a cada clase.\n",
    "\n",
    "- Optimizador adam\n",
    "    - El optimizador seleccionado es Adam, ampliamente utilizado por su eficiencia, velocidad de convergencia y estabilidad. Adam combina los beneficios del descenso por gradiente estocástico con técnicas de momentums adaptativos, ajustando la tasa de aprendizaje de cada parámetro de forma individual. Esta adaptabilidad permite que el entrenamiento sea más robusto incluso con pocos ajustes manuales.\n",
    "\n",
    "- Métrica accuracy\n",
    "    - La métrica de evaluación utilizada es la accuracy (precisión), que indica el porcentaje de predicciones correctas. Esta métrica es especialmente útil en problemas de clasificación balanceada, como este caso, ya que ofrece una medida directa e intuitiva del desempeño general del modelo en términos de aciertos sobre el total de ejemplos.\n",
    "\n",
    "---\n",
    "\n",
    "##### **Justificación de las visualizaciones:**\n",
    "\n",
    "- Las gráficas de pérdida y precisión durante el entrenamiento permiten visualizar el comportamiento del modelo en las distintas épocas, diferenciando entre desempeño en entrenamiento y validación. Esto ayuda a detectar fenómenos como sobreajuste (cuando el modelo aprende muy bien el entrenamiento pero falla en validación) o infraajuste (cuando no aprende lo suficiente en ninguno de los conjuntos). Por otro lado, la matriz de confusión ofrece una visión más detallada del desempeño del modelo, mostrando cuántas veces acertó o se equivocó en cada clase, y permitiendo identificar sesgos o errores sistemáticos.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b5486a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construir_modelo_lstm(input_length, vocab_size=10000):\n",
    "    \"\"\"\n",
    "    Construye y compila una red neuronal LSTM para clasificación binaria de texto.\n",
    "\n",
    "    Args:\n",
    "        input_length (int): Longitud fija de las secuencias de entrada (tras padding).\n",
    "        vocab_size (int, optional): Número de palabras únicas del vocabulario. Default es 10,000.\n",
    "\n",
    "    Returns:\n",
    "        keras.Model: Modelo Keras compilado listo para entrenamiento.\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=vocab_size, output_dim=128, input_length=input_length),\n",
    "        LSTM(64, dropout=0.2, recurrent_dropout=0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def entrenar_y_evaluar_lstm(x_train, y_train, x_test, y_test, batch_size=64, epochs=3):\n",
    "    \"\"\"\n",
    "    Entrena el modelo LSTM usando los datos de IMDb, evalúa su desempeño en el conjunto de prueba \n",
    "    y retorna los objetos necesarios para análisis posterior.\n",
    "\n",
    "    Args:\n",
    "        x_train (ndarray): Secuencias de entrenamiento (preprocesadas).\n",
    "        y_train (ndarray): Etiquetas binarias de entrenamiento.\n",
    "        x_test (ndarray): Secuencias de prueba.\n",
    "        y_test (ndarray): Etiquetas binarias de prueba.\n",
    "        batch_size (int, optional): Tamaño de lote durante entrenamiento. Default es 64.\n",
    "        epochs (int, optional): Número de épocas de entrenamiento. Default es 3.\n",
    "\n",
    "    Returns:\n",
    "        tuple: \n",
    "            - history (History): Histórico de métricas del entrenamiento.\n",
    "            - test_loss (float): Pérdida en el conjunto de prueba.\n",
    "            - test_acc (float): Precisión en el conjunto de prueba.\n",
    "            - y_test (ndarray): Etiquetas reales del test set.\n",
    "            - y_pred (ndarray): Predicciones binarias generadas por el modelo.\n",
    "    \"\"\"\n",
    "    model = construir_modelo_lstm(input_length=x_train.shape[1])\n",
    "\n",
    "    history = model.fit(\n",
    "        x_train, y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=0.2,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Evaluación final en test set\n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "    # Predicciones\n",
    "    y_pred_probs = model.predict(x_test, verbose=0)\n",
    "    y_pred = (y_pred_probs > 0.5).astype('int')\n",
    "\n",
    "    # Retornar todo lo necesario para visualizar\n",
    "    return history, test_loss, test_acc, y_test, y_pred\n",
    "\n",
    "def visualizar_resultados_lstm(history, test_loss, test_acc, y_test, y_pred):\n",
    "    \"\"\"\n",
    "    Muestra visualizaciones y métricas clave del modelo LSTM, incluyendo:\n",
    "    - Tabla resumen de entrenamiento\n",
    "    - Evaluación final en test\n",
    "    - Gráficas de pérdida y precisión\n",
    "    - Matriz de confusión\n",
    "\n",
    "    Args:\n",
    "        history (History): Objeto de entrenamiento de Keras.\n",
    "        test_loss (float): Pérdida final en el conjunto de prueba.\n",
    "        test_acc (float): Precisión final en el conjunto de prueba.\n",
    "        y_test (ndarray): Etiquetas verdaderas.\n",
    "        y_pred (ndarray): Predicciones binarias del modelo.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "    from IPython.display import display\n",
    "\n",
    "    # === Tabla resumen de métricas por época ===\n",
    "    metrics_table = pd.DataFrame({\n",
    "        'Época': range(1, len(history.history['loss']) + 1),\n",
    "        'Loss (train)': history.history['loss'],\n",
    "        'Accuracy (train)': history.history['accuracy'],\n",
    "        'Val Loss': history.history['val_loss'],\n",
    "        'Val Accuracy': history.history['val_accuracy']\n",
    "    })\n",
    "    display(metrics_table.round(4))\n",
    "\n",
    "    # === Display en test set ===\n",
    "    eval_summary = pd.DataFrame({\n",
    "        'Conjunto': ['Test'],\n",
    "        'Loss': [test_loss],\n",
    "        'Accuracy': [test_acc]\n",
    "    })\n",
    "    display(eval_summary.round(4))\n",
    "\n",
    "    # === Gráficas de métricas ===\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # Pérdida\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "    plt.title('Pérdida durante el entrenamiento')\n",
    "    plt.xlabel('Épocas')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Precisión\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Train Acc')\n",
    "    plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
    "    plt.title('Precisión durante el entrenamiento')\n",
    "    plt.xlabel('Épocas')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # === Matriz de confusión ===\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Neg\", \"Pos\"])\n",
    "    disp.plot(cmap='Blues')\n",
    "    plt.title(\"Matriz de Confusión - Test IMDb\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a4db6f",
   "metadata": {},
   "source": [
    "**Bloque 3:** Aplicación de GAN.\n",
    "\n",
    "- **`build_generator()`** \n",
    "Crea el modelo generador simple de la GAN que transforma ruido en imágenes 28x28.\n",
    "\n",
    "- **`build_discriminator()`** \n",
    "Crea el modelo discriminador simple de la GAN que clasifica imágenes reales vs falsas.\n",
    "\n",
    "- **`generate_image()`** \n",
    "Genera y guarda una imagen sintetizada por el generador en una carpeta.\n",
    "\n",
    "- **`train_gan()`** \n",
    "Entrena la GAN completa y grafica la evolución de pérdidas y precisión.\n",
    "\n",
    "- **`mostrar_imagenes_generadas()`** \n",
    "Muestra en una grilla las imágenes generadas guardadas durante el entrenamiento.\n",
    "\n",
    "---\n",
    "\n",
    "##### `Decisiones de diseño`\n",
    "\n",
    "##### **Justificación – Entrenamiento y Evaluación de GAN:**\n",
    "\n",
    "- Uso de LeakyReLU en el generador y discriminador\n",
    "    - Se utiliza la función de activación LeakyReLU en lugar de la ReLU tradicional porque permite un pequeño gradiente incluso cuando la entrada es negativa, lo que evita el problema del “apagado de neuronas” (dead neurons) que puede ocurrir con ReLU. En GANs, donde el entrenamiento es altamente inestable y el generador parte generando ruido, es crucial mantener el flujo de gradiente incluso en regiones donde las activaciones podrían ser pequeñas o negativas. Esto estabiliza el aprendizaje tanto en el generador como en el discriminador desde las primeras iteraciones.\n",
    "\n",
    "- ¿Cómo se genera una imagen?\n",
    "    - El generador toma como entrada un vector de ruido aleatorio de 100 dimensiones, extraído de una distribución normal. Este vector no tiene estructura aparente, pero al pasar por el generador, se transforma en una imagen aplanada de 784 valores (correspondiente a 28x28 píxeles) con valores entre 0 y 1 gracias a la activación sigmoid. Esta imagen generada intenta imitar el estilo de los dígitos reales del conjunto MNIST. Al ser reconstruida y visualizada como una matriz 28x28, podemos apreciar qué tan convincentemente el generador ha aprendido la distribución visual de los números manuscritos.\n",
    "\n",
    "- Importancia de G Loss, D Loss y Accuracy\n",
    "    - G Loss (pérdida del generador): mide qué tan bien logra el generador engañar al discriminador. Cuanto más baja sea esta pérdida, más eficaz es el generador para producir imágenes que el discriminador no puede distinguir de las reales.\n",
    "    - D Loss (pérdida del discriminador): evalúa la capacidad del discriminador para diferenciar imágenes reales de falsas. Una pérdida equilibrada indica que el discriminador está aprendiendo, pero no volviéndose dominante.\n",
    "    - Accuracy (precisión): representa qué porcentaje de imágenes reales y falsas el discriminador clasifica correctamente. A diferencia de la pérdida, que puede ser más difícil de interpretar intuitivamente, la precisión entrega un número directo sobre su capacidad de clasificación. No se calcula una “accuracy” para el generador porque este no tiene etiquetas reales que clasificar —su objetivo es engañar, no clasificar—.\n",
    "\n",
    "- Gráficas de las métricas G Loss, D Loss y Accuracy\n",
    "    - Graficar estas dos métricas permite visualizar la dinámica del juego entre el generador y el discriminador. Un generador que mejora debería mostrar una pérdida (g_loss) decreciente o estable, mientras que un discriminador que se mantiene en 100% de precisión por mucho tiempo puede estar ganando la partida demasiado fácilmente, lo cual indica que el generador no está aprendiendo correctamente. En cambio, una evolución alternada o equilibrada refleja una mejor competencia entre ambos modelos, lo cual es deseable en una GAN. Estos gráficos permiten también detectar si alguno de los modelos colapsa (por ejemplo, si el generador deja de aprender).\n",
    "\n",
    "- Representación de las imagenes generadas\n",
    "    - Las imágenes generadas permiten evaluar visualmente si el generador está aprendiendo una distribución significativa. Como el objetivo final de la GAN es producir imágenes plausibles, observar su evolución cada cierto número de épocas permite detectar en qué momento los dígitos comienzan a tener forma coherente. Además, esto responde directamente a una de las preguntas de la tarea: ¿cuándo las imágenes comenzaron a parecerse a dígitos reales?. La grilla final con ejemplos de diferentes épocas resume de manera tangible el progreso de la GAN a lo largo del entrenamiento.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece769d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    \"\"\"\n",
    "    Construye el generador de la GAN.\n",
    "\n",
    "    La red toma un vector de ruido de 100 dimensiones como entrada y produce una imagen de salida \n",
    "    de 784 píxeles (28×28 aplanada), usando capas densas y activaciones no lineales.\n",
    "\n",
    "    Returns:\n",
    "        keras.Model: Modelo generador no compilado.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=100))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(Dense(784, activation='sigmoid'))  # salida 28x28 flatten\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_discriminator():\n",
    "    \"\"\"\n",
    "    Construye el discriminador de la GAN.\n",
    "\n",
    "    La red toma una imagen aplanada de 784 píxeles como entrada y produce una probabilidad \n",
    "    de si la imagen es real o generada, usando capas densas y activación sigmoid.\n",
    "\n",
    "    Returns:\n",
    "        keras.Model: Modelo discriminador compilable.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=784))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # 0 = fake, 1 = real\n",
    "    return model\n",
    "\n",
    "\n",
    "def generate_image(generator, epoch, output_dir=\"gan_images\"):\n",
    "    \"\"\"\n",
    "    Genera una imagen a partir del generador y la guarda en disco como PNG.\n",
    "\n",
    "    Args:\n",
    "        generator (keras.Model): El modelo generador entrenado.\n",
    "        epoch (int): Número de época actual (para nombrar el archivo).\n",
    "        output_dir (str): Carpeta donde guardar la imagen. Default es \"gan_images\".\n",
    "    \"\"\"\n",
    "    noise = np.random.normal(0, 1, (1, 100))\n",
    "    generated_img = generator.predict(noise, verbose=0).reshape(28, 28)\n",
    "\n",
    "    plt.imshow(generated_img, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Generado en epoch {epoch}')\n",
    "    plt.savefig(f\"{output_dir}/digit_epoch_{epoch}.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def train_gan(x_train, epochs=3000, batch_size=128, save_interval=500):\n",
    "    \"\"\"\n",
    "    Entrena una GAN básica para generar dígitos manuscritos.\n",
    "\n",
    "    Se entrena el discriminador para distinguir imágenes reales de generadas, y el generador\n",
    "    para engañar al discriminador. Se guarda una imagen generada cada cierto intervalo y\n",
    "    se grafica la evolución de la pérdida del generador y la precisión del discriminador.\n",
    "\n",
    "    Args:\n",
    "        x_train (ndarray): Imágenes reales (aplanadas y normalizadas).\n",
    "        epochs (int): Número de iteraciones de entrenamiento. Default es 3000.\n",
    "        batch_size (int): Tamaño de lote total (mitad real, mitad generado).\n",
    "        save_interval (int): Intervalo de épocas para guardar imágenes generadas.\n",
    "    \"\"\"\n",
    "    g_losses = []\n",
    "    d_accuracies = []\n",
    "\n",
    "    half_batch = batch_size // 2\n",
    "\n",
    "    generator = build_generator()\n",
    "    discriminator = build_discriminator()\n",
    "\n",
    "    # Compilar discriminador\n",
    "    discriminator.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Construir GAN completa\n",
    "    discriminator.trainable = False\n",
    "    gan_input = Input(shape=(100,))\n",
    "    gan_output = discriminator(generator(gan_input))\n",
    "    gan = Model(gan_input, gan_output)\n",
    "    gan.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # === Entrenamiento del discriminador ===\n",
    "        idx = np.random.randint(0, x_train.shape[0], half_batch)\n",
    "        real_imgs = x_train[idx]\n",
    "\n",
    "        noise = np.random.normal(0, 1, (half_batch, 100))\n",
    "        fake_imgs = generator.predict(noise, verbose=0)\n",
    "\n",
    "        d_loss_real = discriminator.train_on_batch(real_imgs, np.ones((half_batch, 1)))\n",
    "        d_loss_fake = discriminator.train_on_batch(fake_imgs, np.zeros((half_batch, 1)))\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "        # === Entrenamiento del generador (vía GAN) ===\n",
    "        noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "        g_loss = gan.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "\n",
    "        # === Mostrar progreso ===\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch} — D loss: {d_loss[0]:.4f}, acc: {d_loss[1]*100:.2f}% — G loss: {g_loss:.4f}\")\n",
    "\n",
    "        # === Guardar imagen generada ===\n",
    "        if epoch % save_interval == 0:\n",
    "            generate_image(generator, epoch)\n",
    "\n",
    "        g_losses.append(g_loss)\n",
    "        d_accuracies.append(d_loss[1])  # d_loss = [loss, acc]\n",
    "\n",
    "    # === Gráfico de evolución G Loss y D Accuracy ===\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(g_losses, label='Generador - Pérdida', linewidth=2)\n",
    "    plt.plot(d_accuracies, label='Discriminador - Accuracy', linewidth=2)\n",
    "    plt.xlabel('Épocas')\n",
    "    plt.title('Evolución del entrenamiento GAN')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def mostrar_imagenes_generadas(carpeta='gan_images', intervalo=500, max_epoch=5000):\n",
    "    \"\"\"\n",
    "    Muestra en una grilla las imágenes generadas por la GAN en diferentes épocas.\n",
    "\n",
    "    Args:\n",
    "        carpeta (str): Ruta a la carpeta donde están las imágenes PNG.\n",
    "        intervalo (int): Frecuencia con la que se guardaron imágenes (ej: cada 500 epochs).\n",
    "        max_epoch (int): Última época considerada.\n",
    "    \"\"\"\n",
    "    epochs = list(range(intervalo, max_epoch + 1, intervalo))\n",
    "    total = len(epochs)\n",
    "    cols = 5\n",
    "    rows = (total + cols - 1) // cols\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 2, rows * 2))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, epoch in enumerate(epochs):\n",
    "        ruta = os.path.join(carpeta, f'digit_epoch_{epoch}.png')\n",
    "        if os.path.exists(ruta):\n",
    "            img = mpimg.imread(ruta)\n",
    "            axes[i].imshow(img, cmap='gray')\n",
    "            axes[i].axis('off')\n",
    "            axes[i].set_title(f\"Epoch {epoch}\")\n",
    "        else:\n",
    "            axes[i].axis('off')\n",
    "            axes[i].set_title(f\"Epoch {epoch}\\n(no encontrada)\")\n",
    "\n",
    "    # Quitar ejes vacíos\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "\n",
    "    plt.suptitle(\"Evolución de imágenes generadas por la GAN\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.9)  # deja espacio al título\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a531176",
   "metadata": {},
   "source": [
    "**Bloque 4:** Función de ejecución main.\n",
    "\n",
    "- **`main()`** \n",
    "Ejecuta todo el flujo: carga datos, entrena LSTM y GAN, y visualiza resultados.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9097c335",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Función principal que ejecuta el flujo completo de la tarea.\n",
    "\n",
    "    1. Carga y preprocesa los datasets IMDb (para clasificación de sentimientos) y MNIST (para generación de dígitos).\n",
    "    2. Entrena una red LSTM con el dataset IMDb y visualiza sus resultados, incluyendo métricas, gráficas y matriz de confusión.\n",
    "    3. Entrena una red GAN simple con MNIST durante 3000 épocas, guarda imágenes generadas en intervalos regulares,\n",
    "       y grafica la evolución de la pérdida del generador y la precisión del discriminador.\n",
    "    4. Muestra en una grilla las imágenes generadas por la GAN a lo largo del entrenamiento para observar el progreso visual.\n",
    "\n",
    "    Esta función organiza todo el flujo del proyecto, facilitando la ejecución estructurada y replicable.\n",
    "    \"\"\"\n",
    "    # === 1. Cargar datasets ===\n",
    "    (imdb_train_x, imdb_train_y, imdb_test_x, imdb_test_y), mnist_train_x = cargar_y_preprocesar_datasets()\n",
    "\n",
    "    # === 2. Parte A: LSTM con IMDb ===\n",
    "    history, test_loss, test_acc, y_test, y_pred = entrenar_y_evaluar_lstm(\n",
    "        imdb_train_x, imdb_train_y, imdb_test_x, imdb_test_y\n",
    "    )\n",
    "    visualizar_resultados_lstm(history, test_loss, test_acc, y_test, y_pred)\n",
    "\n",
    "    # === 3. Parte B: GAN con MNIST ===\n",
    "    train_gan(mnist_train_x, epochs=5000, batch_size=128, save_interval=500)\n",
    "    mostrar_imagenes_generadas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f7ae35",
   "metadata": {},
   "source": [
    "# 4. Visualización de resultados\n",
    "\n",
    "Se muestran los resultados obtenidos a partir de la ejecución de la funcion **main()**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4c964d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adf9477",
   "metadata": {},
   "source": [
    "# 5. Análisis de los resultados y reflexiones finales\n",
    "\n",
    "---\n",
    "\n",
    "## Reflexión con base en los resultados obtenidos con RNN\n",
    "\n",
    "- Los resultados muestran que la red LSTM logra una buena precisión en entrenamiento y validación (alrededor del 85-87% en validación y test), lo que indica que efectivamente está aprendiendo a clasificar el sentimiento de las reseñas. Sin embargo, se observa que la pérdida de validación no disminuye consistentemente y el accuracy no mejora después de cierto punto, sugiriendo que la red tiene ciertas dificultades para generalizar más allá de los patrones más evidentes.\n",
    "\n",
    "- Esto puede relacionarse con la dificultad que tiene la red para “recordar” secuencias completas o información a largo plazo en las reseñas. Como las reseñas son textos relativamente largos, la LSTM podría estar olvidando detalles importantes que aparecen al principio o en secciones intermedias del texto, afectando su capacidad de clasificación fina.\n",
    "\n",
    "- La matriz de confusión apoya esta idea: hay un número considerable de falsos negativos y falsos positivos, lo que indica que la red a veces confunde la polaridad del sentimiento, probablemente porque no captura el contexto completo o matices en la secuencia.\n",
    "\n",
    "- En resumen, aunque la LSTM aprende patrones relevantes, la complejidad y longitud de las secuencias representan un reto para su memoria, limitando su capacidad para “recordar” toda la información necesaria para una clasificación perfecta.\n",
    "\n",
    "---\n",
    "\n",
    "## Reflexión con base en los resultados obtenidos con GAN\n",
    "\n",
    "- Durante el entrenamiento de la GAN, observamos que la precisión del discriminador se mantiene muy alta, cercana a 1 (100%), prácticamente durante todo el proceso. Esto indica que el discriminador logra distinguir con gran éxito entre imágenes reales y falsas generadas, lo que es esperable al principio cuando el generador todavía produce imágenes poco realistas.\n",
    "\n",
    "- Sin embargo, la pérdida del discriminador varía bastante a lo largo del entrenamiento. Esto puede ser interpretado como que, aunque el discriminador es muy bueno clasificando, su confianza o certeza (reflejada en la pérdida) fluctúa conforme el generador mejora y genera imágenes más convincentes. En momentos donde la pérdida baja, el discriminador se siente seguro; cuando sube, está enfrentando imágenes más difíciles de clasificar.\n",
    "\n",
    "- En cuanto al generador, la pérdida tiende a incrementarse de forma general, lo que se puede interpretar como un proceso de mejora en su capacidad para engañar al discriminador. Una pérdida alta del generador significa que está produciendo imágenes que el discriminador encuentra cada vez más difíciles de diferenciar de las reales.\n",
    "\n",
    "- En las imágenes generadas, vemos que recién alrededor de la época 4000 aparecen formas que se parecen a dígitos reales, aunque con cierta variabilidad entre ejecuciones.\n",
    "\n",
    "- En resumen, la alta precisión del discriminador junto con la variabilidad de su pérdida y el aumento de la pérdida del generador reflejan la dinámica típica del entrenamiento GAN, donde ambos modelos están en una especie de “competencia” que hace que la calidad de las imágenes mejoren gradualmente hasta volverse reconocibles.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
