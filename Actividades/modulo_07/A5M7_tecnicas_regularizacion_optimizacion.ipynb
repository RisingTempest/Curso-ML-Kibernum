{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ff0a282",
   "metadata": {},
   "source": [
    "# Módulo 7 - Actividad 5:\n",
    "# Entrenamiento de un modelo con técnicas de regularización y optimización\n",
    "\n",
    "## Objetivo\n",
    "Diseñar, entrenar y evaluar una red neuronal convolucional utilizando al menos dos técnicas de regularización y dos de optimización, ajustadas al contexto de un dataset realista.\n",
    "\n",
    "**Datasets utilizados:**  \n",
    "`CIFAR-10`\n",
    "\n",
    "---\n",
    "\n",
    "### Estructura del Notebook:\n",
    "1. Metodología.\n",
    "2. Configuración del entorno.\n",
    "3. Definicion de funciones.\n",
    "4. Uso de funciones y resultados.\n",
    "5. Análisis de los resultados y reflexiones finales.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1e4d5f",
   "metadata": {},
   "source": [
    "## 1. Metodología\n",
    "\n",
    "### Flujo de trabajo\n",
    "\n",
    "> Se diseñó un pipeline modular para entrenar un modelo CNN desde cero sobre el dataset CIFAR-10. El flujo abarca la carga y preprocesamiento de datos, construcción y compilación del modelo, entrenamiento con callbacks para optimización, evaluación y visualización de métricas.\n",
    "\n",
    "1. **Carga y preprocesamiento de datos:**  \n",
    "   - Se cargó el dataset CIFAR-10, compuesto por imágenes RGB de 32x32 píxeles en 10 clases.  \n",
    "   - Se normalizaron las imágenes para escalar los valores de píxeles a un rango [0, 1].  \n",
    "   - Las etiquetas se convirtieron a formato one-hot para facilitar la clasificación multiclase.  \n",
    "\n",
    "2. **Construcción del modelo:**  \n",
    "   - Se definió una arquitectura CNN con dos capas convolucionales seguidas de capas de pooling para reducción espacial.  \n",
    "   - Se aplicó regularización L2 en las capas convolucionales para evitar el sobreajuste.  \n",
    "   - Se añadió una capa densa con activación ReLU seguida de dropout (0.5) para mejorar la robustez del modelo.  \n",
    "   - La capa final es una capa densa con activación softmax para clasificación en 10 categorías.  \n",
    "\n",
    "3. **Compilación del modelo:**  \n",
    "   - El modelo se compiló usando el optimizador Adam con una tasa de aprendizaje inicial de 0.001.  \n",
    "   - Se usó la función de pérdida categorical_crossentropy, adecuada para problemas multiclase con etiquetas one-hot.  \n",
    "\n",
    "4. **Configuración de callbacks:**  \n",
    "   - Se incluyó EarlyStopping para detener el entrenamiento cuando la pérdida de validación dejara de mejorar tras 5 épocas consecutivas, evitando el sobreentrenamiento.  \n",
    "   - ReduceLROnPlateau ajustó la tasa de aprendizaje disminuyéndola automáticamente al estancarse la métrica de validación, mejorando la convergencia.  \n",
    "   - Un callback personalizado registró la evolución del learning rate para su visualización posterior.  \n",
    "\n",
    "5. **Entrenamiento:**  \n",
    "   - Se entrenó el modelo durante un máximo de 50 épocas con un batch size de 64, usando un 20% de los datos para validación.  \n",
    "   - Los callbacks monitorearon el entrenamiento para optimizar el proceso y evitar el sobreajuste.  \n",
    "\n",
    "6. **Evaluación y visualización:**  \n",
    "   - Se evaluó la precisión y pérdida en el conjunto de prueba para medir la generalización del modelo.  \n",
    "   - Se graficaron las curvas de precisión, pérdida y tasa de aprendizaje para analizar el comportamiento del entrenamiento y ajuste del learning rate.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b821fb",
   "metadata": {},
   "source": [
    "# 2. Configuración del entorno\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65da65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, LambdaCallback\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd814e51",
   "metadata": {},
   "source": [
    "# 3. Definición de funciones\n",
    "\n",
    "> **Nota:** Para mejor comprensión de las funciones y su utilidad, esta sección se divide en bloques, en donde cada uno responde a una parte diferente de la metodología de trabajo. \n",
    "\n",
    "---\n",
    "\n",
    "**Bloque 1:** Carga y preprocesamiento de datos.\n",
    "\n",
    "- **`cargar_y_preprocesar_datos()`** \n",
    "Carga el dataset CIFAR-10, normaliza las imágenes y convierte las etiquetas a formato one-hot.\n",
    "\n",
    "---\n",
    "\n",
    "##### Decisiones de diseño:\n",
    "\n",
    "#### Elección del dataset CIFAR-10\n",
    "\n",
    "- El dataset CIFAR-10 fue elegido por ser un conjunto de imágenes en color ampliamente utilizado para tareas de clasificación en visión por computadora. Su tamaño moderado y diversidad de 10 clases lo hacen adecuado para entrenar y evaluar modelos de redes neuronales convolucionales, permitiendo experimentar con técnicas de regularización y optimización sin requerir recursos computacionales excesivos. Esto lo convierte en una opción ideal para proyectos educativos y pruebas rápidas de arquitecturas, asegurando un buen equilibrio entre complejidad y practicidad.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1aace91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_y_preprocesar_datos():\n",
    "    \"\"\"\n",
    "    Carga el dataset CIFAR-10 y realiza el preprocesamiento necesario para el entrenamiento.\n",
    "\n",
    "    Específicamente:\n",
    "    - Descarga y separa los datos en conjuntos de entrenamiento y prueba.\n",
    "    - Normaliza los valores de píxeles a un rango [0, 1] para mejorar la convergencia.\n",
    "    - Convierte las etiquetas a formato one-hot encoding para clasificación multiclase.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Cuatro arrays numpy:\n",
    "            - x_train: Imágenes de entrenamiento normalizadas (float32).\n",
    "            - y_train: Etiquetas de entrenamiento codificadas one-hot.\n",
    "            - x_test: Imágenes de prueba normalizadas (float32).\n",
    "            - y_test: Etiquetas de prueba codificadas one-hot.\n",
    "    \"\"\"\n",
    "    (x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "    x_train = x_train.astype('float32') / 255.0\n",
    "    x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "    y_train = keras.utils.to_categorical(y_train, 10)\n",
    "    y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc29a160",
   "metadata": {},
   "source": [
    "**Bloque 2:** Creación, compilación y entrenamiento del modelo.\n",
    "\n",
    "- **`construir_modelo()`** \n",
    "Define y arma la arquitectura CNN con capas convolucionales, regularización L2 y dropout.\n",
    "\n",
    "- **`compilar_modelo()`** \n",
    "Compila el modelo con el optimizador Adam y la función de pérdida para clasificación multiclase.\n",
    "\n",
    "- **`obtener_callbacks()`** \n",
    "Crea los callbacks para early stopping, reducción de learning rate y registro de la tasa de aprendizaje.\n",
    "\n",
    "---\n",
    "\n",
    "##### Decisiones de diseño:\n",
    "\n",
    "#### Arquitectura del modelo detallada\n",
    "\n",
    "- La arquitectura propuesta combina dos capas convolucionales con activación ReLU y regularización L2 para extraer características relevantes mientras se controla el sobreajuste mediante la penalización de pesos grandes. Las capas MaxPooling reducen la dimensionalidad espacial de las representaciones, facilitando el aprendizaje y disminuyendo la complejidad computacional. La capa Flatten transforma las características extraídas en un vector para ser procesado por las capas densas. La capa densa intermedia con activación ReLU permite al modelo aprender combinaciones no lineales de las características, mientras que la capa Dropout introduce aleatoriedad en la desconexión de neuronas durante el entrenamiento para mejorar la robustez y evitar el sobreajuste. Finalmente, la capa de salida con activación softmax genera una distribución de probabilidades para la clasificación multiclase, ajustándose al problema específico del dataset.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0772fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construir_modelo(tamaño_entrada=(32, 32, 3), num_clases=10):\n",
    "    \"\"\"\n",
    "    Construye un modelo de red neuronal convolucional (CNN) para clasificación de imágenes.\n",
    "\n",
    "    Arquitectura:\n",
    "    - Dos capas convolucionales con activación ReLU y regularización L2.\n",
    "    - Capas MaxPooling para reducción espacial.\n",
    "    - Capa Flatten para vectorizar las características.\n",
    "    - Capa densa intermedia con activación ReLU.\n",
    "    - Capa Dropout para evitar sobreajuste.\n",
    "    - Capa de salida densa con activación softmax para clasificación multiclase.\n",
    "\n",
    "    Args:\n",
    "        tamaño_entrada (tuple): Dimensiones de las imágenes de entrada (alto, ancho, canales).\n",
    "        num_clases (int): Cantidad de clases para la clasificación.\n",
    "\n",
    "    Returns:\n",
    "        keras.Model: Modelo CNN no compilado listo para entrenamiento.\n",
    "    \"\"\"\n",
    "    modelo = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', padding='same',\n",
    "               kernel_regularizer=keras.regularizers.l2(0.001), input_shape=tamaño_entrada),\n",
    "        MaxPooling2D((2, 2)),\n",
    "\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same',\n",
    "               kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "        MaxPooling2D((2, 2)),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_clases, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    return modelo\n",
    "\n",
    "\n",
    "def compilar_modelo(modelo, tasa_aprendizaje=0.001):\n",
    "    \"\"\"\n",
    "    Compila el modelo con el optimizador Adam y función de pérdida para clasificación multiclase.\n",
    "\n",
    "    Parámetros configurables:\n",
    "    - Tasa de aprendizaje inicial para el optimizador Adam.\n",
    "\n",
    "    Args:\n",
    "        modelo (keras.Model): Modelo no compilado.\n",
    "        tasa_aprendizaje (float): Learning rate para el optimizador Adam.\n",
    "\n",
    "    Returns:\n",
    "        keras.Model: Modelo compilado listo para entrenamiento.\n",
    "    \"\"\"\n",
    "    optimizador = keras.optimizers.Adam(learning_rate=tasa_aprendizaje)\n",
    "    modelo.compile(\n",
    "        optimizer=optimizador,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return modelo\n",
    "\n",
    "\n",
    "def obtener_callbacks(modelo):\n",
    "    \"\"\"\n",
    "    Crea una lista de callbacks para mejorar el entrenamiento y seguimiento.\n",
    "\n",
    "    Callbacks incluidos:\n",
    "    - EarlyStopping: Detiene el entrenamiento si la pérdida de validación no mejora tras cierta paciencia.\n",
    "    - ReduceLROnPlateau: Reduce la tasa de aprendizaje si la métrica monitorizada se estanca.\n",
    "    - LambdaCallback: Registra el learning rate al final de cada época para visualizar su evolución.\n",
    "\n",
    "    Args:\n",
    "        modelo (keras.Model): Modelo compilado cuyo optimizador se monitoriza para el learning rate.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            - lista_callbacks (list): Lista con los callbacks definidos.\n",
    "            - lista_lr (list): Lista vacía que se llenará con los valores del learning rate durante el entrenamiento.\n",
    "    \"\"\"\n",
    "    lista_lr = []\n",
    "\n",
    "    seguimiento_lr = LambdaCallback(on_epoch_end=lambda epoca, logs: lista_lr.append(\n",
    "        float(keras.backend.get_value(modelo.optimizer.lr))\n",
    "    ))\n",
    "\n",
    "    parada_temprana = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    reduccion_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=1e-6\n",
    "    )\n",
    "\n",
    "    return [parada_temprana, reduccion_lr, seguimiento_lr], lista_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73eede1",
   "metadata": {},
   "source": [
    "**Bloque 3:** Visualización de resultados.\n",
    "\n",
    "- **`graficar_entrenamiento()`** \n",
    "Genera gráficos de precisión, pérdida y evolución del learning rate durante el entrenamiento.\n",
    "\n",
    "---\n",
    "\n",
    "##### Decisiones de diseño:\n",
    "\n",
    "#### Elección de parámetros para graficar\n",
    "\n",
    "- Se eligieron para graficar la precisión y pérdida tanto en entrenamiento como en validación con el fin de monitorear el desempeño del modelo y detectar posibles señales de sobreajuste o subajuste durante el proceso de entrenamiento. La precisión muestra qué tan bien el modelo clasifica correctamente las muestras, mientras que la pérdida refleja qué tan lejos están las predicciones de los valores reales, ofreciendo una medida más sensible a la calidad del ajuste. Además, se incluyó la evolución del learning rate por época para visualizar cómo los callbacks de ajuste automático de tasa de aprendizaje impactan en la convergencia del modelo, facilitando la interpretación de cambios en el rendimiento asociados a modificaciones en este hiperparámetro crítico.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f70f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graficar_entrenamiento(historial, lista_lr):\n",
    "    \"\"\"\n",
    "    Grafica las curvas de precisión, pérdida y tasa de aprendizaje durante el entrenamiento.\n",
    "\n",
    "    Parámetros graficados:\n",
    "    - Precisión en entrenamiento y validación.\n",
    "    - Pérdida en entrenamiento y validación.\n",
    "    - Evolución del learning rate por época.\n",
    "\n",
    "    Args:\n",
    "        historial (History): Objeto retornado por model.fit() con historial del entrenamiento.\n",
    "        lista_lr (list): Valores del learning rate registrados por época.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(14, 4))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(historial.history['accuracy'], label='Entrenamiento')\n",
    "    plt.plot(historial.history['val_accuracy'], label='Validación')\n",
    "    plt.title(\"Precisión\")\n",
    "    plt.xlabel(\"Épocas\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(historial.history['loss'], label='Entrenamiento')\n",
    "    plt.plot(historial.history['val_loss'], label='Validación')\n",
    "    plt.title(\"Pérdida\")\n",
    "    plt.xlabel(\"Épocas\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(lista_lr, marker='o')\n",
    "    plt.title(\"Learning Rate\")\n",
    "    plt.xlabel(\"Épocas\")\n",
    "    plt.ylabel(\"LR\")\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcdd346",
   "metadata": {},
   "source": [
    "**Bloque 4:** Función de ejecución.\n",
    "\n",
    "- **`main()`** \n",
    "Ejecuta el flujo completo: carga datos, crea y entrena el modelo, evalúa y visualiza resultados.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2607fd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Función principal que ejecuta el flujo completo de:\n",
    "    - Carga y preprocesamiento de datos.\n",
    "    - Construcción y compilación del modelo.\n",
    "    - Configuración de callbacks.\n",
    "    - Entrenamiento del modelo.\n",
    "    - Evaluación sobre el conjunto de prueba.\n",
    "    - Visualización de métricas y tasa de aprendizaje.\n",
    "    \"\"\"\n",
    "    x_train, y_train, x_test, y_test = cargar_y_preprocesar_datos()\n",
    "\n",
    "    modelo = construir_modelo()\n",
    "    modelo = compilar_modelo(modelo)\n",
    "\n",
    "    callbacks, lista_lr = obtener_callbacks(modelo)\n",
    "\n",
    "    historial = modelo.fit(\n",
    "        x_train, y_train,\n",
    "        validation_split=0.2,\n",
    "        epochs=50,\n",
    "        batch_size=64,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    perdida_test, accuracy_test = modelo.evaluate(x_test, y_test, verbose=0)\n",
    "    print(f\"Accuracy en test: {accuracy_test:.4f}\")\n",
    "\n",
    "    graficar_entrenamiento(historial, lista_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636403c1",
   "metadata": {},
   "source": [
    "# 4. Visualización de resultados\n",
    "\n",
    "Se muestran los resultados obtenidos a partir de la ejecución de la funcion **main()**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a8cab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05efac12",
   "metadata": {},
   "source": [
    "# 5. Análisis de los resultados y reflexiones finales\n",
    "\n",
    "---\n",
    "\n",
    ">Nota: Los resultados estan basados en valores especificos obtenidos en una ejecución aleatoria, por lo que dichos valores de accuracy por ejemplo, podrián variar en otras ejecuciones. De igual forma, los resultados estan hechos con el fin de representar el significado del uso de los métodos de regularización y optimización en redes neuronales.\n",
    "\n",
    "---\n",
    "\n",
    "## Análisis de resultados\n",
    "\n",
    "- El entrenamiento comienza con una accuracy del 39 % y una val_accuracy del 52 %, lo que indica que el modelo empieza a aprender desde el inicio, considerando que en CIFAR-10 el azar puro daría alrededor de un 10 %. A lo largo de las primeras 23 épocas, la accuracy de entrenamiento aumenta del 39 % al 80 %, mientras que la de validación pasa del 52 % al 73 %. Sin embargo, entre las épocas 13 y 16 la val_accuracy se mantiene alrededor del 71 % mientras la accuracy de entrenamiento sigue mejorando, lo que señala el inicio de un sobreajuste. En la época 17, el callback ReduceLROnPlateau reduce el learning rate a 0.0005, lo que permite desbloquear la mejora y alcanzar un 73.2 % de val_accuracy. Al finalizar, el modelo logra un 80.5 % de accuracy en entrenamiento, 73.2 % en validación y 72.36 % en el conjunto de prueba, resultado consistente con la validación y sin indicios de fuga de datos.\n",
    "\n",
    "- El modelo presenta una generalización aceptable, con una diferencia de aproximadamente 7–8 puntos porcentuales entre la accuracy de entrenamiento y la de validación en la última época, lo cual es normal para una CNN pequeña en CIFAR-10. El uso del Learning Rate Scheduler resultó efectivo, ya que las reducciones de la tasa de aprendizaje en las épocas 17 y 22 evitaron el estancamiento en la mejora de la validación. Además, la regularización mediante L2 y Dropout contribuyó a contener el sobreajuste, aunque la arquitectura, por su simplicidad, tiene ciertas limitaciones para capturar patrones más complejos del dataset.\n",
    "\n",
    "- Considerando que se trata de una CNN pequeña con solo dos capas convolucionales, un accuracy de prueba del 72 % es consistente y competitivo para CIFAR-10 sin técnicas avanzadas de aumento de datos\n",
    "\n",
    "---\n",
    "\n",
    "### ¿Qué técnica tuvo mayor impacto?\n",
    "\n",
    "Las técnicas que tuvieron mayor impacto en la mejora del rendimiento y la generalización del modelo fueron:\n",
    "\n",
    "- **Regularización L2** en las capas convolucionales, que ayuda a reducir el sobreajuste penalizando pesos grandes y estabilizando el entrenamiento.  \n",
    "- **Dropout** en la capa densa final, que promueve una representación más robusta al impedir la dependencia excesiva en neuronas específicas.  \n",
    "- **Callbacks de EarlyStopping y ReduceLROnPlateau**, que detienen el entrenamiento cuando la pérdida de validación deja de mejorar y ajustan automáticamente la tasa de aprendizaje, respectivamente.  \n",
    "Estas técnicas combinadas permitieron que el modelo aprendiera adecuadamente sin caer en sobreajuste ni quedar atrapado en mínimos locales.\n",
    "\n",
    "### ¿Cómo se evitó el sobreajuste?\n",
    "\n",
    "El sobreajuste se evitó mediante varias estrategias implementadas en el modelo:\n",
    "\n",
    "- **Regularización L2 (weight decay)** para penalizar pesos grandes y favorecer modelos más simples.  \n",
    "- **Dropout** para desconectar aleatoriamente neuronas durante el entrenamiento, evitando la dependencia excesiva de conexiones específicas.  \n",
    "- **EarlyStopping**, que interrumpe el entrenamiento cuando la métrica de validación deja de mejorar, evitando un entrenamiento excesivo.  \n",
    "- **Separación de un conjunto de validación** para monitorear el rendimiento del modelo en datos no vistos durante el entrenamiento.\n",
    "\n",
    "Estas medidas evitaron que el modelo memorizara el conjunto de entrenamiento y favorecieron una mejor generalización a datos nuevos.\n",
    "\n",
    "### ¿Qué se haría diferente si el dataset fuese más grande?\n",
    "\n",
    "Si el dataset fuera considerablemente más grande, se considerarían las siguientes modificaciones para aprovechar mejor los datos y recursos:\n",
    "\n",
    "- Implementar **Data Augmentation** para aumentar artificialmente la diversidad de las imágenes y mejorar la capacidad de generalización del modelo.  \n",
    "- Ajustar la intensidad de la **regularización L2** y la tasa de **dropout**, ya que con más datos el riesgo de sobreajuste disminuye, permitiendo modelos más complejos.  \n",
    "- Incrementar la profundidad y complejidad del modelo, añadiendo más capas convolucionales y filtros para capturar patrones más complejos.  \n",
    "- Utilizar optimizadores o programadores de tasa de aprendizaje más sofisticados, como **Lookahead** o **Cosine Annealing**, para mejorar la convergencia en entrenamientos prolongados.  \n",
    "- Aplicar técnicas de **entrenamiento distribuido** o usar hardware especializado como GPUs o TPUs para acelerar el proceso.  \n",
    "- Incorporar **Batch Normalization** para estabilizar y acelerar el entrenamiento en arquitecturas más profundas.  \n",
    "- Implementar **checkpointing** para guardar periódicamente el estado del modelo y evitar pérdidas de progreso en entrenamientos largos.\n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "## Pruebas adicionales con Batch Normalization y Data Augmentation\n",
    "\n",
    "- Se realizaron experimentos incorporando técnicas adicionales como **Batch Normalization** y **Data Augmentation**, así como aumentando la complejidad del modelo con el fin de potenciar su rendimiento. Estas mejoras demostraron ser efectivas para aumentar la precisión y reducir la pérdida, pero también provocaron un incremento significativo en el tiempo de entrenamiento, llegando a superar los 22 minutos en hardware convencional.\n",
    "\n",
    "- Dado que el contexto de la tarea cuenta con limitaciones de tiempo y recursos computacionales, se decidió optar por un modelo más sencillo que mantuviera un buen balance entre desempeño y eficiencia. No obstante, estas técnicas avanzadas quedan como posibles mejoras para futuras implementaciones o para entornos con mayor capacidad de cómputo.\n",
    "\n",
    "- Es importante destacar los resultados alcanzados durante esta prueba mejorada, que incluyen:\n",
    "    - Época final: 47/50  \n",
    "    - Pérdida (loss) en entrenamiento: 0.5162  \n",
    "    - Precisión (accuracy) en entrenamiento: 84.81%  \n",
    "    - Pérdida en validación: 0.5707  \n",
    "    - Precisión en validación: 83.78%  \n",
    "    - Learning rate ajustado: 3.1250e-05  \n",
    "    - Precisión final en test: 84.17%  \n",
    "\n",
    "- Estos experimentos con Batch Normalization y Data Augmentation son precisamente dos de las estrategias que se plantearon en la sección ¿Qué haría diferente si el dataset fuese más grande?. Aunque el dataset original no aumentó en tamaño, el Data Augmentation permitió simular un conjunto más diverso, y la Batch Normalization se probó como técnica de estabilización en arquitecturas más profundas. Los resultados —un aumento de la precisión en validación del 73.2 % al 83.78 %— demuestran que estas ideas no son solo teóricas, sino que ya han mostrado un impacto positivo. Con un dataset realmente mayor y más capacidad de cómputo, es probable que estas técnicas ofrezcan aún mejores mejoras de generalización.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
