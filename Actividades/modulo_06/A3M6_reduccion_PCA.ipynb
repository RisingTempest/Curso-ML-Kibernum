{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af5ad654",
   "metadata": {},
   "source": [
    "# Actividad 3:\n",
    "# Descubriendo estructuras ocultas: Reducción de dimensionalidad con PCA\n",
    "\n",
    "## Objetivo\n",
    "Aplicar PCA en un conjunto de datos multivariado, interpretar los resultados, visualizar la proyección en 2D, y reflexionar sobre el impacto de la reducción de dimensionalidad en el análisis exploratorio de datos y la preparación de modelos predictivos.\n",
    "\n",
    "**Datasets utilizados:**  \n",
    "`Wine`\n",
    "\n",
    "---\n",
    "\n",
    "### Estructura del Notebook:\n",
    "1. Metodología.\n",
    "2. Configuración del entorno.\n",
    "3. Definicion de funciones.\n",
    "4. Uso de funciones y resultados.\n",
    "5. Análisis de los resultados y reflexiones finales.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bcbbd4",
   "metadata": {},
   "source": [
    "## 1. Metodología\n",
    "\n",
    "### Flujo de trabajo\n",
    "\n",
    "1. **Carga, preprocesamiento de datos y aplicación de PCA exploratorio:**\n",
    "    - Se carga el dataset **Wine** y se escala.\n",
    "    - Se aplica PCA para obtener la varianza acumulada y ver como varía con cada componente.\n",
    "\n",
    "2. **Aplicación de KNN:**\n",
    "    - Se preparan los datos, haciendo train_test_split a partir de X e y original y escalando sobre los splits.\n",
    "    - Uso de optuna para encontrar los mejores hiperparámetros para el modelo KNeighborsClassifier, se usa para evaluar con y sin PCA.\n",
    "    - Entrenamiento del modelo con los mejores hiperparámetros con y sin PCA.\n",
    "\n",
    "3. **Visualización e interpretación:**\n",
    "    - Tabla de evolución de la varianza acumulada por componente.\n",
    "    - Gráfico de varianza acumulada por componente y gráfico de PCA con 2 componentes.\n",
    "    - Comparación de métricas de modelos KNeighborsClassifier con y sin PCA.\n",
    "    - Matriz de confusión de los modelos con y sin PCA.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96c0183",
   "metadata": {},
   "source": [
    "# 2. Configuración del entorno\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc64cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaciones de librerías de terceros\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import optuna\n",
    "\n",
    "# Importaciones de scikit-learn\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Configuraciones de estilo\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# Desactiva el logging de Optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)  # Solo muestra warnings y errores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7620e0a6",
   "metadata": {},
   "source": [
    "# 3. Definición de funciones\n",
    "\n",
    "> **Nota:** Para mejor comprensión de las funciones y su utilidad, esta sección se divide en bloques, en donde cada uno responde a una parte diferente de la metodología de trabajo. \n",
    "\n",
    "---\n",
    "\n",
    "**Bloque 1:** Carga, preprocesamiento de datos y aplicación de PCA exploratorio.\n",
    "\n",
    "- **`carga_y_preprocesamiento()`** \n",
    "Carga el dataset Wine, realiza escalado y prepara los datos para el análisis.\n",
    "\n",
    "- **`aplicar_pca()`** \n",
    "Aplica PCA para obtener componentes principales y la varianza explicada acumulada.\n",
    "---\n",
    "\n",
    "`Justificación del uso de None en n_componentes`\n",
    "\n",
    "Para entender cuánta información contiene cada componente principal, primero calculamos todas las componentes posibles del dataset (en este caso, 13 características originales). Esto permite obtener la varianza explicada y acumulada completa, facilitando la selección informada de un número reducido de componentes que retengan la mayor parte de la información (normalmente, un umbral del 90% o más). Esta etapa es fundamental para justificar posteriormente cuántos componentes usar en el modelo.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05abd65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def carga_y_preprocesamiento():\n",
    "    \"\"\"\n",
    "    Carga y preprocesa el dataset Wine de scikit-learn.\n",
    "\n",
    "    - Carga los datos y la variable objetivo.\n",
    "    - Muestra la forma y distribución de clases.\n",
    "    - Verifica la ausencia de valores nulos.\n",
    "    - Escala las características usando StandardScaler.\n",
    "\n",
    "    Returns:\n",
    "        X_scaled_df (pd.DataFrame): Datos escalados con nombres de columnas.\n",
    "        X (pd.DataFrame): Datos originales sin escalar.\n",
    "        y (pd.Series): Variable objetivo (clases).\n",
    "    \"\"\"\n",
    "    # Cargar el dataset Wine de scikit-learn\n",
    "    wine = load_wine()\n",
    "    X = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
    "    y = pd.Series(wine.target, name=\"target\") # La variable objetivo en Wine se llama 'target'\n",
    "\n",
    "    # Vista general e información del dataset\n",
    "    print(\"Forma del dataset (X):\", X.shape)\n",
    "    print(\"Forma del dataset (y):\", y.shape)\n",
    "    X.info()\n",
    "\n",
    "    # Distribución de clases de la variable objetivo\n",
    "    distribucion_de_clases_target = y.value_counts()\n",
    "    print(\"\\nDistribución de clases de la variable objetivo:\")\n",
    "    print(distribucion_de_clases_target)\n",
    "\n",
    "    # Revisar si no hay nulos antes de escalar\n",
    "    if X.isnull().sum().any():\n",
    "        print(\"Advertencia: Hay valores nulos en los datos después del preprocesamiento.\")\n",
    "    else:\n",
    "        print(\"\\nNo hay valores nulos en los datos después del preprocesamiento.\")\n",
    "\n",
    "    # Escalar cuando tenemos todo limpio\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Opcional: convertir X_scaled de nuevo a DataFrame para mantener los nombres de las columnas\n",
    "    X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "    return X_scaled_df, X, y\n",
    "\n",
    "\n",
    "def aplicar_pca(X_scaled):\n",
    "    \"\"\"\n",
    "    Aplica Análisis de Componentes Principales (PCA) al dataset escalado.\n",
    "\n",
    "    - Calcula todas las componentes para obtener varianza explicada y acumulada.\n",
    "    - Facilita análisis exploratorio para selección del número óptimo de componentes.\n",
    "\n",
    "    Args:\n",
    "        X_scaled (np.ndarray o pd.DataFrame): Datos escalados.\n",
    "\n",
    "    Returns:\n",
    "        X_pca (np.ndarray): Datos transformados por PCA.\n",
    "        varianza_explicada (np.ndarray): Varianza explicada por cada componente.\n",
    "        varianza_acumulada (np.ndarray): Varianza explicada acumulada.\n",
    "    \"\"\"\n",
    "    # Reducir a 2 componentes para visualización\n",
    "    pca = PCA(n_components=None)  # para calcular todas y ver la varianza acumulada\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "    # Varianza explicada\n",
    "    varianza_explicada = pca.explained_variance_ratio_\n",
    "    varianza_acumulada = np.cumsum(varianza_explicada)\n",
    "\n",
    "    return X_pca, varianza_explicada, varianza_acumulada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f090019",
   "metadata": {},
   "source": [
    "**Bloque 2:** Aplicación de KNN con y sin PCA.\n",
    "\n",
    "- **`preparar_datos_modelo()`** \n",
    "Divide y preprocesa los datos para entrenamiento y prueba, opcionalmente aplicando PCA.\n",
    "\n",
    "- **`buscar_hiperparametros_optimos()`** \n",
    "Optimiza los hiperparámetros del modelo KNN usando Optuna y validación cruzada estratificada.\n",
    "\n",
    "- **`entrenar_y_evaluar_modelo()`** \n",
    "Entrena el modelo KNN con parámetros dados y evalúa su rendimiento con métricas clave.\n",
    "\n",
    "---\n",
    "\n",
    "`Justificación de escalar nuevamente los datos`\n",
    "\n",
    "Los datos se escalan primero sobre el dataset completo para un análisis exploratorio global y aplicación inicial de PCA. Luego, tras dividir los datos en entrenamiento y prueba, se realiza un escalado independiente sobre el conjunto de entrenamiento y se aplica la misma transformación al conjunto de prueba. Esto es clave para evitar filtrado de información del test set en el entrenamiento (data leakage), y para simular condiciones reales en donde el modelo no debe conocer datos futuros.\n",
    "\n",
    "---\n",
    "\n",
    "`Justificación de uso de 8 componentes en PCA`\n",
    "\n",
    "Se seleccionaron 8 componentes principales en el análisis PCA porque estos explican aproximadamente el 92.02% de la varianza acumulada de los datos originales. Este umbral representa un equilibrio adecuado entre reducción de dimensionalidad y retención de información:\n",
    "\n",
    "- Captura la mayoría de la estructura de los datos, evitando pérdida significativa de información relevante.\n",
    "- Reduce el ruido y la redundancia, ya que se eliminan componentes que aportan muy poca varianza.\n",
    "- Mejora la eficiencia computacional sin comprometer gravemente el rendimiento predictivo del modelo.\n",
    "- Este umbral del 92% es comúnmente aceptado como suficientemente alto para preservar las relaciones fundamentales en los datos, evitando el sobreajuste que puede darse con demasiadas variables.\n",
    "- Por tanto, 8 componentes representan un punto óptimo para mantener la calidad del modelo y facilitar su interpretación.\n",
    "\n",
    "---\n",
    "\n",
    "`Justificación del uso de KNN con y sin PCA`\n",
    "\n",
    "El algoritmo K-Nearest Neighbors (KNN) es sensible a la dimensionalidad y a la escala de los datos, lo cual lo convierte en una excelente opción para evaluar el impacto de técnicas de reducción dimensional como PCA (Análisis de Componentes Principales).\n",
    "\n",
    "KNN sin PCA:\n",
    "- Evaluar el modelo directamente sobre los datos originales permite observar su desempeño con toda la información disponible. Esto actúa como línea base (\"baseline\") para comparar contra cualquier técnica de reducción o transformación.\n",
    "\n",
    "KNN con PCA:\n",
    "- Al reducir la dimensionalidad con PCA:\n",
    "- Se elimina ruido o redundancia en los datos, lo que puede ayudar a mejorar la generalización.\n",
    "- Se reduce el costo computacional al trabajar con menos dimensiones.\n",
    "- Se busca mejorar el rendimiento o mantenerlo con menor complejidad.\n",
    "- Es útil cuando los datos tienen muchas variables correlacionadas (como es el caso del dataset Wine).\n",
    "\n",
    "Comparar ambos escenarios permite:\n",
    "- Evaluar si la reducción de dimensiones sacrifica o mejora el rendimiento.\n",
    "- Observar el trade-off entre precisión y eficiencia.\n",
    "- Identificar si el modelo depende de características específicas que podrían perderse al aplicar PCA.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d669bd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparar_datos_modelo(X, y, usar_pca=False, n_componentes_pca=8, test_size=0.3, random_state=42):\n",
    "    \"\"\"\n",
    "    Prepara los datos para el entrenamiento del modelo.\n",
    "\n",
    "    - Divide el dataset en entrenamiento y prueba con estratificación para conservar distribución de clases.\n",
    "    - Escala los datos usando StandardScaler ajustado solo sobre entrenamiento.\n",
    "    - Aplica PCA si se especifica con el número de componentes deseado.\n",
    "\n",
    "    Args:\n",
    "        X (pd.DataFrame o np.ndarray): Datos originales.\n",
    "        y (pd.Series o np.ndarray): Variable objetivo.\n",
    "        usar_pca (bool): Indica si se aplica PCA.\n",
    "        n_componentes_pca (int): Número de componentes para PCA, calculado con la varianza acumulada.\n",
    "        test_size (float): Proporción de test set.\n",
    "        random_state (int): Semilla para reproducibilidad.\n",
    "\n",
    "    Returns:\n",
    "        Tuple: Datos divididos y preprocesados para entrenamiento y prueba.\n",
    "        Si usar_pca es True: (X_train_pca, X_test_pca, y_train, y_test)\n",
    "        Si usar_pca es False: (X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "    \"\"\"\n",
    "    # Split con estratificación\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "\n",
    "    # Escalado\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    if usar_pca:\n",
    "        pca = PCA(n_components=n_componentes_pca)\n",
    "        X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "        X_test_pca = pca.transform(X_test_scaled)\n",
    "        return X_train_pca, X_test_pca, y_train, y_test\n",
    "    else:\n",
    "        return X_train_scaled, X_test_scaled, y_train, y_test\n",
    "\n",
    "def buscar_hiperparametros_optimos(X_train, y_train, n_trials=30):\n",
    "    \"\"\"\n",
    "    Optimiza hiperparámetros de KNN usando Optuna con validación cruzada estratificada.\n",
    "\n",
    "    - Busca número óptimo de vecinos, tipo de peso y métrica de distancia.\n",
    "    - Utiliza StratifiedKFold para preservar distribución de clases en folds.\n",
    "    - Maximiza accuracy promedio en validación cruzada.\n",
    "\n",
    "    Args:\n",
    "        X_train (np.ndarray): Datos de entrenamiento.\n",
    "        y_train (np.ndarray): Etiquetas de entrenamiento.\n",
    "        n_trials (int): Número de pruebas de hiperparámetros.\n",
    "\n",
    "    Returns:\n",
    "        dict: Mejores hiperparámetros encontrados por Optuna.\n",
    "    \"\"\"\n",
    "    def objective(trial):\n",
    "        n_neighbors = trial.suggest_int(\"n_neighbors\", 1, 30)\n",
    "        weights = trial.suggest_categorical(\"weights\", [\"uniform\", \"distance\"])\n",
    "        metric = trial.suggest_categorical(\"metric\", [\"euclidean\", \"manhattan\", \"chebyshev\"])\n",
    "\n",
    "        knn = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights, metric=metric)\n",
    "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "        score = cross_val_score(knn, X_train, y_train, cv=skf, scoring=\"accuracy\").mean()\n",
    "        return score\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "    return study.best_params\n",
    "\n",
    "\n",
    "def entrenar_y_evaluar_modelo(X_train, X_test, y_train, y_test, params):\n",
    "    \"\"\"\n",
    "    Entrena el modelo KNN con hiperparámetros dados y evalúa su desempeño.\n",
    "\n",
    "    - Ajusta el modelo con datos de entrenamiento.\n",
    "    - Predice sobre datos de prueba.\n",
    "    - Calcula métricas de clasificación multiclasica (accuracy, precision, recall, f1).\n",
    "    - Calcula la matriz de confusión.\n",
    "\n",
    "    Args:\n",
    "        X_train (np.ndarray): Datos de entrenamiento.\n",
    "        X_test (np.ndarray): Datos de prueba.\n",
    "        y_train (np.ndarray): Etiquetas de entrenamiento.\n",
    "        y_test (np.ndarray): Etiquetas de prueba.\n",
    "        params (dict): Hiperparámetros para KNeighborsClassifier.\n",
    "\n",
    "    Returns:\n",
    "        modelo: Modelo entrenado.\n",
    "        metrics (dict): Diccionario con métricas y matriz de confusión.\n",
    "    \"\"\"\n",
    "    # Entrenamiento\n",
    "    knn = KNeighborsClassifier(**params)\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # Predicción\n",
    "    y_pred = knn.predict(X_test)\n",
    "\n",
    "    # Métricas\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"precision\": precision_score(y_test, y_pred, average=\"macro\", zero_division=0),\n",
    "        \"recall\": recall_score(y_test, y_pred, average=\"macro\", zero_division=0),\n",
    "        \"f1_score\": f1_score(y_test, y_pred, average=\"macro\", zero_division=0),\n",
    "        \"confusion_matrix\": confusion_matrix(y_test, y_pred)\n",
    "    }\n",
    "\n",
    "    return knn, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f2b72c",
   "metadata": {},
   "source": [
    "**Bloque 3:** Visualización de resultados.\n",
    "\n",
    "- **`tabla_varianza_acumulada()`** \n",
    "Muestra una tabla con la varianza explicada y acumulada por cada componente PCA.\n",
    "\n",
    "- **`graficar_pca_combinado()`** \n",
    "Grafica la varianza acumulada y la proyección de los datos en los dos primeros componentes PCA.\n",
    "\n",
    "- **`mostrar_comparacion_metricas()`** \n",
    "Presenta una tabla comparativa de métricas entre modelos con y sin PCA.\n",
    "\n",
    "- **`mostrar_matrices_confusion()`** \n",
    "Visualiza matrices de confusión para los modelos con y sin PCA para análisis detallado.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66f6797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tabla_varianza_acumulada(varianza_explicada, varianza_acumulada):\n",
    "    \"\"\"\n",
    "    Muestra una tabla con la varianza explicada y acumulada por cada componente PCA.\n",
    "\n",
    "    Args:\n",
    "        varianza_explicada (np.ndarray): Varianza explicada individual por componente.\n",
    "        varianza_acumulada (np.ndarray): Varianza explicada acumulada.\n",
    "    \"\"\"\n",
    "    df_varianza = pd.DataFrame({\n",
    "        'Componente': range(1, len(varianza_explicada) + 1),\n",
    "        'Varianza Explicada (%)': varianza_explicada * 100,\n",
    "        'Varianza Acumulada (%)': varianza_acumulada * 100\n",
    "    })\n",
    "\n",
    "    display(df_varianza.round(2))\n",
    "\n",
    "def graficar_pca_combinado(varianza_acumulada, X_pca, y):\n",
    "    \"\"\"\n",
    "    Grafica la varianza explicada acumulada y la proyección de los dos primeros componentes PCA.\n",
    "\n",
    "    - Primer gráfico: línea con varianza acumulada para selección de componentes.\n",
    "    - Segundo gráfico: scatter plot de PC1 vs PC2 con colores según la clase.\n",
    "\n",
    "    Args:\n",
    "        varianza_acumulada (np.ndarray): Varianza acumulada para componentes PCA.\n",
    "        X_pca (np.ndarray): Datos transformados por PCA.\n",
    "        y (pd.Series o np.ndarray): Etiquetas de clase para colorear.\n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    # Gráfico de varianza acumulada\n",
    "    axs[0].plot(range(1, len(varianza_acumulada) + 1), varianza_acumulada, marker='o', linestyle='--')\n",
    "    axs[0].set_xlabel('Número de Componentes')\n",
    "    axs[0].set_ylabel('Varianza Explicada Acumulada')\n",
    "    axs[0].set_title('Varianza Explicada Acumulada por PCA')\n",
    "    axs[0].grid(True)\n",
    "\n",
    "    # Gráfico de los 2 primeros componentes PCA con etiquetas\n",
    "    sns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1], hue=y, palette='Set1', ax=axs[1])\n",
    "    axs[1].set_xlabel(\"PC1\")\n",
    "    axs[1].set_ylabel(\"PC2\")\n",
    "    axs[1].set_title(\"Proyección PCA (2 Componentes)\")\n",
    "    axs[1].legend(title='Condition')\n",
    "    axs[1].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def mostrar_comparacion_metricas(metrics_sin_pca, metrics_con_pca):\n",
    "    \"\"\"\n",
    "    Muestra una tabla comparativa con métricas de modelos entrenados sin y con PCA.\n",
    "\n",
    "    Args:\n",
    "        metrics_sin_pca (dict): Métricas del modelo sin PCA.\n",
    "        metrics_con_pca (dict): Métricas del modelo con PCA.\n",
    "    \"\"\"\n",
    "    # Excluir matriz de confusión\n",
    "    dict_sin_pca = {k: v for k, v in metrics_sin_pca.items() if k != \"confusion_matrix\"}\n",
    "    dict_con_pca = {k: v for k, v in metrics_con_pca.items() if k != \"confusion_matrix\"}\n",
    "\n",
    "    df_comparativa = pd.DataFrame({\n",
    "        \"Sin PCA\": dict_sin_pca,\n",
    "        \"Con PCA\": dict_con_pca\n",
    "    })\n",
    "\n",
    "    print(\"\\nComparación de métricas KNN:\")\n",
    "    display(df_comparativa.style.format(\"{:.4f}\"))\n",
    "\n",
    "def mostrar_matrices_confusion(metrics_sin_pca, metrics_con_pca, clases=None):\n",
    "    \"\"\"\n",
    "    Muestra matrices de confusión lado a lado para modelos sin y con PCA.\n",
    "\n",
    "    Args:\n",
    "        metrics_sin_pca (dict): Métricas que incluyen matriz de confusión del modelo sin PCA.\n",
    "        metrics_con_pca (dict): Métricas que incluyen matriz de confusión del modelo con PCA.\n",
    "        clases (list, opcional): Etiquetas para las clases a mostrar en la matriz.\n",
    "    \"\"\"\n",
    "    cm_sin = metrics_sin_pca[\"confusion_matrix\"]\n",
    "    cm_con = metrics_con_pca[\"confusion_matrix\"]\n",
    "\n",
    "    if clases is None:\n",
    "        clases = ['0', '1', '2']\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    sns.heatmap(cm_sin, annot=True, fmt='d', cmap='Blues', ax=axes[0], cbar=False,\n",
    "                xticklabels=clases, yticklabels=clases)\n",
    "    axes[0].set_title('Matriz de Confusión SIN PCA')\n",
    "    axes[0].set_xlabel('Predicción')\n",
    "    axes[0].set_ylabel('Verdadero')\n",
    "\n",
    "    sns.heatmap(cm_con, annot=True, fmt='d', cmap='Greens', ax=axes[1], cbar=False,\n",
    "                xticklabels=clases, yticklabels=clases)\n",
    "    axes[1].set_title('Matriz de Confusión CON PCA')\n",
    "    axes[1].set_xlabel('Predicción')\n",
    "    axes[1].set_ylabel('Verdadero')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d655f6",
   "metadata": {},
   "source": [
    "**Bloque 4:** Función de ejecución.\n",
    "\n",
    "- **`main()`** \n",
    "Ejecuta el flujo completo del proyecto, desde la carga de datos hasta la evaluación y visualización de resultados.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec0d192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Función principal que orquesta la carga, preprocesamiento, análisis PCA, \n",
    "    optimización de hiperparámetros, entrenamiento, evaluación y visualización \n",
    "    de modelos KNN con y sin reducción dimensional mediante PCA sobre el dataset Wine.\n",
    "    \"\"\"\n",
    "    print(\"=== Carga y preprocesamiento de datos ===\\n\")\n",
    "    X_scaled, X, y = carga_y_preprocesamiento()\n",
    "    \n",
    "    print(\"\\n=== Aplicando PCA para análisis exploratorio ===\")\n",
    "    X_pca, varianza_explicada, varianza_acumulada = aplicar_pca(X_scaled)\n",
    "    \n",
    "    print(\"\\n=== Preparando datos para modelos KNN (sin y con PCA) ===\")\n",
    "    X_train, X_test, y_train, y_test = preparar_datos_modelo(X, y, usar_pca=False)\n",
    "    X_train_pca, X_test_pca, y_train_pca, y_test_pca = preparar_datos_modelo(X, y, usar_pca=True)\n",
    "    \n",
    "    print(\"\\n=== Buscando hiperparámetros óptimos con Optuna ===\")\n",
    "    mejores_params_sin_pca = buscar_hiperparametros_optimos(X_train, y_train)\n",
    "    mejores_params_con_pca = buscar_hiperparametros_optimos(X_train_pca, y_train_pca)\n",
    "    \n",
    "    print(\"\\n=== Entrenando y evaluando los modelos ===\")\n",
    "    modelo_sin_pca, metrics_sin_pca = entrenar_y_evaluar_modelo(\n",
    "        X_train, X_test, y_train, y_test, mejores_params_sin_pca\n",
    "    )\n",
    "    modelo_con_pca, metrics_con_pca = entrenar_y_evaluar_modelo(\n",
    "        X_train_pca, X_test_pca, y_train_pca, y_test_pca, mejores_params_con_pca\n",
    "    )\n",
    "    \n",
    "    print(\"\\n=== Resultados y visualización ===\")\n",
    "    tabla_varianza_acumulada(varianza_explicada, varianza_acumulada)\n",
    "    graficar_pca_combinado(varianza_acumulada, X_pca, y)\n",
    "    \n",
    "    mostrar_comparacion_metricas(metrics_sin_pca, metrics_con_pca)\n",
    "    mostrar_matrices_confusion(metrics_sin_pca, metrics_con_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70a91bf",
   "metadata": {},
   "source": [
    "# 4. Visualización de resultados\n",
    "\n",
    "Se muestran los resultados obtenidos a partir de la ejecución de la funcion **main()**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183e03bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c61d33",
   "metadata": {},
   "source": [
    "# 5. Análisis de los resultados y reflexiones finales\n",
    "\n",
    "---\n",
    "\n",
    "### ¿Cuánta información conserva el nuevo espacio?\n",
    "\n",
    "Al aplicar el Análisis de Componentes Principales (PCA), observamos que las primeras ocho componentes principales son capaces de capturar el 92.02% de la varianza total del conjunto de datos original. Este porcentaje sugiere que, aunque se ha producido una compresión considerable de la dimensionalidad, se mantiene gran parte de la estructura estadística esencial de los datos.\n",
    "\n",
    "Específicamente, las dos primeras componentes ya explican más del 55% de la varianza, lo que indica que las dimensiones originales estaban altamente correlacionadas y que una representación más compacta era no solo posible, sino también efectiva. Este tipo de reducción facilita tanto la visualización como el análisis, sin que ello implique una pérdida significativa de información relevante para las tareas de clasificación.\n",
    "\n",
    "### ¿Se observan agrupamientos o patrones más claros?\n",
    "\n",
    "La proyección de los datos en el nuevo espacio bidimensional generado por las dos primeras componentes principales revela estructuras latentes que no eran evidentes en el espacio original. En este plano reducido, emergen tres agrupamientos claramente diferenciables, los cuales se alinean con las clases originales 0, 1 y 2.\n",
    "\n",
    "Esta separación no es trivial: el hecho de que clases diferentes se proyecten en regiones distintas del espacio PCA sugiere que existen relaciones subyacentes entre las variables originales que son eficientemente capturadas por la transformación. Más allá de ser una herramienta de reducción, PCA actúa aquí como un método exploratorio poderoso, evidenciando la estructura interna del conjunto de datos y mostrando que las clases están razonablemente bien separadas incluso sin supervisión directa.\n",
    "\n",
    "---\n",
    "\n",
    "### Análisis del rendimiento del modelo KNN\n",
    "\n",
    "> Nota: Para efectos de este trabajo, no se discutira sobre el sobreajuste o baja generalización que puedan presentar los modelos, si no que se usaran como comparación para ver como actúa con datos con y sin procesado de PCA.\n",
    "\n",
    "Se entrenaron dos versiones del modelo KNN: una con los datos originales (sin aplicar PCA) y otra sobre los datos transformados mediante PCA (usando las primeras 8 componentes). En una ejecución controlada con random_state=42, ambos modelos reportaron idénticas métricas de desempeño:\n",
    "\n",
    "| Métrica   | Sin PCA | Con PCA |\n",
    "|-----------|---------|---------|\n",
    "| Accuracy  | 0.9815  | 0.9815  |\n",
    "| Precision | 0.9792  | 0.9792  |\n",
    "| Recall    | 0.9841  | 0.9841  |\n",
    "| F1-Score  | 0.9811  | 0.9811  |\n",
    "\n",
    "\n",
    "Este comportamiento no implica que PCA sea irrelevante para el modelo, sino que en este escenario específico —con la semilla fija— el proceso de validación cruzada encontró combinaciones de entrenamiento y prueba donde ambos enfoques resultan igualmente efectivos.\n",
    "\n",
    "Sin embargo, al remover la semilla (como en el código final) y permitir la aleatoriedad natural del ShuffleSplit, se observaron variaciones sutiles en las métricas entre ejecuciones. En general, el modelo entrenado sobre los datos reducidos por PCA tiende a presentar un rendimiento ligeramente superior, especialmente en términos de precisión y F1-score, aunque las diferencias no siempre son estadísticamente significativas. Esto sugiere que la transformación PCA puede mejorar la estabilidad y generalización del modelo en distintos subconjuntos del conjunto de datos. Ejamplo de ejecución sin semilla específica:\n",
    "\n",
    "| Métrica   | Sin PCA | Con PCA |\n",
    "|-----------|---------|---------|\n",
    "| Accuracy  | 0.9630  | 0.9815  |\n",
    "| Precision | 0.9616  | 0.9792  |\n",
    "| Recall    | 0.9683  | 0.9841  |\n",
    "| F1-Score  | 0.9636  | 0.9811  |\n",
    "\n",
    "La matriz de confusión correspondiente revela una clasificación casi perfecta: un único error en el cual un dato de clase 1 fue clasificado como clase 2. El resto de las instancias fueron correctamente etiquetadas. Esta precisión sugiere que el modelo capta eficazmente las fronteras de decisión, y que los errores se limitan a observaciones fronterizas o ambiguas.\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusión\n",
    "\n",
    "Este análisis demostró que la reducción de dimensionalidad mediante Análisis de Componentes Principales (PCA) es una técnica altamente efectiva para simplificar el espacio de características sin comprometer el rendimiento predictivo del modelo.\n",
    "\n",
    "La selección de 8 componentes principales permitió conservar un 92.02% de la varianza total, lo que implica una pérdida mínima de información. Además, la visualización en el espacio de los primeros dos componentes mostró una clara separación entre clases, reflejando una estructura subyacente bien definida en los datos originales.\n",
    "\n",
    "Respecto al modelo K-Nearest Neighbors (KNN), se observó un rendimiento prácticamente idéntico con y sin PCA cuando se fijó la semilla aleatoria (random_state=42). No obstante, al permitir la aleatoriedad natural, los modelos entrenados sobre los datos reducidos por PCA mostraron un rendimiento ligeramente superior en métricas clave, lo cual sugiere que la reducción de dimensionalidad no solo facilita la visualización y simplificación del problema, sino que también puede aumentar la robustez y capacidad de generalización del modelo.\n",
    "\n",
    "Por último, el análisis de la matriz de confusión indicó un desempeño casi perfecto, con tan solo un único error de clasificación en ambos casos. Este resultado, junto con las métricas obtenidas, confirma que el uso combinado de PCA y KNN puede ser una estrategia eficiente y confiable tanto para compresión de datos como para clasificación precisa en conjuntos complejos.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
