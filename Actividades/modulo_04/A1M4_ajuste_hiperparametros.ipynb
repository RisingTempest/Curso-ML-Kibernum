{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d79ab345",
   "metadata": {},
   "source": [
    "# Actividad 1:\n",
    "# Optimización inteligente de modelos predictivos en salud: Predicción de diabetes con ajuste de hiperparámetros\n",
    "\n",
    "## Objetivo\n",
    "Desarrollar un modelo de clasificación para predecir diabetes tipo II utilizando el dataset Pima Indians, aplicando y comparando técnicas de ajuste de hiperparámetros (Grid Search, Random Search y Optimización Bayesiana) para encontrar la mejor configuración del modelo y analizar su impacto en el rendimiento.\n",
    "\n",
    "**Dataset utilizado:**  \n",
    "[Pima Indians Diabetes Dataset](https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv)\n",
    "\n",
    "**Variables:**\n",
    "- Pregnancies (Embarazos)\n",
    "- Glucose (Glucosa)\n",
    "- BloodPressure (Presión arterial)\n",
    "- SkinThickness (Espesor piel)\n",
    "- Insulin (Insulina)\n",
    "- BMI (Índice masa corporal)\n",
    "- DiabetesPedigreeFunction (Historial familiar)\n",
    "- Age (Edad)\n",
    "- Outcome (Resultado: 1 = diabético, 0 = no diabético)\n",
    "\n",
    "---\n",
    "\n",
    "### Estructura del Notebook:\n",
    "1. Metodología.\n",
    "2. Importación de librerias a utilizar.\n",
    "3. Definicion de funciones.\n",
    "4. Uso de funciones y resultados.\n",
    "5. Análisis de los resultados y reflexiones finales.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b879dc9",
   "metadata": {},
   "source": [
    "## 1. Metodología\n",
    "\n",
    "### Flujo de trabajo\n",
    "1. **Carga y exploración de datos:**\n",
    "   - Análisis de dimensiones y tipos de variables.\n",
    "   - Estadísticas descriptivas básicas.\n",
    "\n",
    "2. **Preprocesamiento:**\n",
    "   - Detección y tratamiento de valores anómalos. No se trataron mas valores anómalos como valores fuera de un rango médico debido a que se desconoce en este trabajo como son estos rangos de valores en la población específica de donde fueron obtenidos, por lo que los únicos valores anómalos tratados fueron los ceros de variables que, biológicamente, es imposible que sean cero, los cuales fueron transformados a mediana ya que es una forma \"estándar\" de tratar los datos con valores cero.\n",
    "   - Escalado de variables numéricas (StandardScaler).\n",
    "   - División estratificada del dataset (70% entrenamiento - 30% prueba).\n",
    "\n",
    "3. **Modelado y optimización:**\n",
    "   - Modelo base: Random Forest sin ajuste\n",
    "   - Técnicas de optimización:\n",
    "     - Grid Search (búsqueda exhaustiva en malla paramétrica)\n",
    "     - Random Search (muestreo aleatorio de parámetros)\n",
    "     - Optimización Bayesiana (Optuna con 50 trials)\n",
    "   - Métricas de evaluación: \n",
    "      - F1-Score: es la media armónica de la precisión y el recall, especialmente útil cuando hay un desequilibrio de clases en los datos.\n",
    "      - Precisión: mide la exactitud de las predicciones positivas del modelo. \"¿Cuantos predicciones positivas son realmente positivas?\"\n",
    "      - Recall: mide la capacidad del modelo para identificar todas las instancias positivas reales. \"¿De todas las instancias positivas, cuantas predijo correctamente?\"\n",
    "      - AUC: métrica que mide la capacidad de un modelo de clasificación para distinguir entre clases. La curva ROC traza la tasa de verdaderos positivos (Recall) contra la tasa de falsos positivos (FPR) en varios umbrales de clasificación.\n",
    "\n",
    "4. **Evaluación comparativa:**\n",
    "   - Análisis de rendimiento (métricas).\n",
    "   - Comparación de tiempos de ejecución.\n",
    "   - Visualización de resultados.\n",
    "\n",
    "### Configuración clave\n",
    "- **Modelo:** Random Forest Classifier\n",
    "- **Hiperparámetros optimizados:**\n",
    "  - n_estimators (50-200)\n",
    "  - max_depth (5-30)\n",
    "  - min_samples_split (2-20)\n",
    "  - min_samples_leaf (1-10)\n",
    "  - max_features (sqrt/log2)\n",
    "- **Manejo de desbalanceo:** `class_weight='balanced'`\n",
    "- **Métrica de optimización:** AUC-ROC\n",
    "\n",
    "### Visualización de resultados\n",
    "\n",
    "- Comparación de métricas:\n",
    "    - Gráfico de barras con F1-Score, Precisión, Recall y AUC por método.\n",
    "- Tiempos de ejecución:\n",
    "    - Gráfico de barras con escala logarítmica comparando tiempos.\n",
    "- Curvas ROC:\n",
    "    - Comparación visual del rendimiento de clasificación.\n",
    "- Importancia de características:\n",
    "    - Análisis de variables más relevantes para la predicción.\n",
    "- Resultados tabulares:\n",
    "    - DataFrame comparativo con todas las métricas y tiempos.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd90ed03",
   "metadata": {},
   "source": [
    "# 2. Importacion de librerias necesarias\n",
    "--- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c8d92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (f1_score, precision_score, recall_score, roc_auc_score, roc_curve)                          \n",
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2716cf4",
   "metadata": {},
   "source": [
    "# 3. Definición de funciones\n",
    "\n",
    "> **Nota:** Para mejor comprensión de las funciones y su utilidad, esta sección se divide en bloques, en donde cada uno responde a una parte diferente de la metodología de trabajo. \n",
    "\n",
    "> **Nota 2:** Los nombres de las columnas se definieron en base a la informacion disponible en `kaggle` sobre este data set: \n",
    "[Pima Indians Diabetes Dataset (Kaggle)](https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database), ya que en el link de github no se encontraban.\n",
    "\n",
    "---\n",
    "\n",
    "**Bloque 1:** Funciones de preprocesamiento de datos.\n",
    "\n",
    "- **`load_data()`** \n",
    "Carga el dataset, define las columnas y lo convierte en un DataFrame con **pandas**. Luego hace una exploración inicial del df determinando las dimenciones y la distribución de clases de lo que sera la variable y.\n",
    "\n",
    "- **`preprocess_data()`** \n",
    "Preprocesa el dataframe reemplazando valores ceros biológicamente incompatibles con la mediana de esa variable, escalando los datos y dividiendo el data set de el sets de entrenamiento y prueba. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26c8a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(url: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Carga un dataset de diabetes desde una URL y realiza una exploración inicial.\n",
    "\n",
    "    Args:\n",
    "        url (str): Ruta o URL del archivo CSV que contiene el dataset.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame con los datos cargados, incluyendo variables clínicas y el diagnóstico de diabetes.\n",
    "    \"\"\"\n",
    "    column_names = [ # Se definen manualmente debido a que el dataset no las contiene\n",
    "        \"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\",\n",
    "        \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\", \"Age\", \"Outcome\"\n",
    "    ]\n",
    "    df = pd.read_csv(url, names=column_names)\n",
    "    \n",
    "    print(\"=\"*50)\n",
    "    print(\"Exploración inicial del dataset\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"Dimensiones:\", df.shape)\n",
    "    print(\"\\nDistribución de clases:\")\n",
    "    print(df['Outcome'].value_counts(normalize=True)) # Outcome es lo que usaremos como y\n",
    "    \n",
    "    # Gráfico de distribución de clases de diabetes\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.countplot(x='Outcome', data=df)\n",
    "    plt.title('Distribución de Diabetes (0: No, 1: Sí)')\n",
    "    plt.xlabel('Diagnóstico de Diabetes')\n",
    "    plt.ylabel('Cantidad de Pacientes')\n",
    "    plt.savefig(\"distribucion_diabetes.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    return df\n",
    "\n",
    "def preprocess_data(df: pd.DataFrame) -> tuple:\n",
    "    \"\"\"\n",
    "    Preprocesa el dataset de diabetes mediante limpieza, escalado y división para entrenamiento.\n",
    "\n",
    "    Este proceso incluye:\n",
    "    - Identificación de valores cero biológicamente inviables en ciertas variables.\n",
    "    - Reemplazo de ceros por la mediana en dichas variables.\n",
    "    - Escalado de características numéricas mediante `StandardScaler`.\n",
    "    - División estratificada del conjunto de datos en entrenamiento y prueba.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame con los datos originales del estudio de diabetes.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Una tupla que contiene:\n",
    "            - X_train (np.ndarray): Datos de entrenamiento escalados.\n",
    "            - X_test (np.ndarray): Datos de prueba escalados.\n",
    "            - y_train (pd.Series): Etiquetas de entrenamiento.\n",
    "            - y_test (pd.Series): Etiquetas de prueba.\n",
    "            - scaler (StandardScaler): Objeto scaler ajustado para posibles transformaciones futuras.\n",
    "    \"\"\"\n",
    "    # 1. Análisis exploratorio integrado\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Análisis de Valores Cero\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Características que biológicamente NO pueden ser cero\n",
    "    critical_features = [\"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\"]\n",
    "    \n",
    "    # Identificar características con valores cero en critical_features\n",
    "    features_with_zero = []\n",
    "    for feature in critical_features:\n",
    "        zero_count = (df[feature] == 0).sum()\n",
    "        if zero_count > 0:\n",
    "            features_with_zero.append(feature)\n",
    "            print(f\"- {feature}: {zero_count} ceros ({zero_count/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    # 2. Tratamiento de valores cero\n",
    "    print(\"\\nTratamiento:\")\n",
    "    for feature in features_with_zero:\n",
    "        original_zero_count = (df[feature] == 0).sum()\n",
    "        median_value = df[feature].median()\n",
    "        \n",
    "        # Reemplazar ceros por la mediana\n",
    "        df[feature] = df[feature].replace(0, median_value)\n",
    "        \n",
    "        # Verificar tratamiento\n",
    "        new_zero_count = (df[feature] == 0).sum()\n",
    "        print(f\"Reemplazados {original_zero_count} ceros en {feature} con mediana={median_value:.1f}\")\n",
    "\n",
    "    # 3. Estadísticas después del tratamiento\n",
    "    print(\"\\nResumen estadístico después del tratamiento:\")\n",
    "    print(df[critical_features].describe().loc[['min', 'max']])\n",
    "    \n",
    "    # 4. Preparación de datos para modelado\n",
    "    X = df.drop(\"Outcome\", axis=1)\n",
    "    y = df[\"Outcome\"]\n",
    "    \n",
    "    # 5. Escalado\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # 6. División estratificada\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=0.3, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6dc59f",
   "metadata": {},
   "source": [
    "**Bloque 2:** Funciones de modelado.\n",
    "\n",
    "- **`train_base_model()`** \n",
    "Entrena un modelo base con parametros por defecto para futuras comparaciones de metricas, incluyendo el tiempo.\n",
    "\n",
    "- **`evaluate_model()`** \n",
    "Evalúa el rendimiento del modelo dado sobre el conjunto de datos de prueba, incluyendo las métricas a evaluar como F1-Score, precisión, recall y AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d1759d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_base_model(X_train: np.ndarray, y_train: pd.Series) -> tuple:\n",
    "    \"\"\"\n",
    "    Entrena un modelo base de Random Forest con parámetros por defecto.\n",
    "\n",
    "    El modelo incluye manejo de desbalanceo de clases mediante `class_weight='balanced'`\n",
    "    y utiliza todos los núcleos disponibles para acelerar el entrenamiento.\n",
    "\n",
    "    Args:\n",
    "        X_train (np.ndarray): Datos de entrenamiento escalados.\n",
    "        y_train (pd.Series): Etiquetas correspondientes al conjunto de entrenamiento.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Una tupla que contiene:\n",
    "            - model (RandomForestClassifier): Modelo entrenado.\n",
    "            - train_time (float): Tiempo de entrenamiento en segundos.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    model = RandomForestClassifier(\n",
    "        random_state=42,\n",
    "        class_weight='balanced',  # Manejo de desbalanceo\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    train_time = time.time() - start_time\n",
    "    return model, train_time\n",
    "\n",
    "def evaluate_model(model, X_test: np.ndarray, y_test: pd.Series) -> dict:\n",
    "    \"\"\"\n",
    "    Evalúa el rendimiento del modelo sobre el conjunto de prueba.\n",
    "\n",
    "    Calcula métricas clave como F1-Score, Precisión, Recall y AUC, \n",
    "    utilizando las predicciones del modelo entrenado.\n",
    "\n",
    "    Args:\n",
    "        model: Modelo entrenado con un método `predict` y `predict_proba`.\n",
    "        X_test (np.ndarray): Datos de prueba escalados.\n",
    "        y_test (pd.Series): Etiquetas verdaderas del conjunto de prueba.\n",
    "\n",
    "    Returns:\n",
    "        dict: Diccionario con las métricas de evaluación:\n",
    "            - \"F1-Score\": Media armónica entre precisión y recall.\n",
    "            - \"Precisión\": Proporción de verdaderos positivos entre los predichos como positivos.\n",
    "            - \"Recall\": Proporción de verdaderos positivos entre los casos realmente positivos.\n",
    "            - \"AUC\": Área bajo la curva ROC.\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    return {\n",
    "        \"F1-Score\": f1_score(y_test, y_pred),\n",
    "        \"Precisión\": precision_score(y_test, y_pred),\n",
    "        \"Recall\": recall_score(y_test, y_pred),\n",
    "        \"AUC\": roc_auc_score(y_test, y_proba)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f24e28",
   "metadata": {},
   "source": [
    "**Bloque 3:** Funciones de optimización.\n",
    "\n",
    "- **`optimize_with_gridsearch()`** \n",
    "Optimización utilizando **GridSearchCV**.\n",
    "\n",
    "- **`optimize_with_randomsearch() -> dict`:** \n",
    "Optimización utilizando **RandomizedSearchCV**.\n",
    "\n",
    "- **`optimize_with_optuna() -> dict`:** \n",
    "Optimización utilizando **Optuna**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9b8c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_with_gridsearch(X_train: np.ndarray, y_train: pd.Series) -> tuple:\n",
    "    \"\"\"\n",
    "    Optimiza un modelo Random Forest utilizando búsqueda exhaustiva de hiperparámetros (Grid Search).\n",
    "\n",
    "    Se evalúan múltiples combinaciones de parámetros mediante validación cruzada,\n",
    "    maximizando el área bajo la curva ROC (AUC).\n",
    "\n",
    "    Args:\n",
    "        X_train (np.ndarray): Datos de entrenamiento escalados.\n",
    "        y_train (pd.Series): Etiquetas del conjunto de entrenamiento.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Una tupla con:\n",
    "            - best_estimator_ (RandomForestClassifier): Mejor modelo encontrado.\n",
    "            - best_params_ (dict): Parámetros óptimos seleccionados.\n",
    "            - time_taken (float): Tiempo de ejecución en segundos.\n",
    "    \"\"\"\n",
    "    param_grid = {\n",
    "        \"n_estimators\": [50, 100, 150],\n",
    "        \"max_depth\": [5, 10, 15],\n",
    "        \"min_samples_split\": [2, 5, 10],\n",
    "        \"min_samples_leaf\": [1, 2, 4],\n",
    "        \"max_features\": ['sqrt', 'log2'],\n",
    "        \"class_weight\": ['balanced']\n",
    "    }\n",
    "    \n",
    "    start_time = time.time()\n",
    "    grid_search = GridSearchCV(\n",
    "        RandomForestClassifier(random_state=42),\n",
    "        param_grid,\n",
    "        scoring='roc_auc',  # Optimizar por AUC\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        verbose=0\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    time_taken = time.time() - start_time\n",
    "    \n",
    "    return grid_search.best_estimator_, grid_search.best_params_, time_taken\n",
    "\n",
    "def optimize_with_randomsearch(X_train: np.ndarray, y_train: pd.Series) -> tuple:\n",
    "    \"\"\"\n",
    "    Optimiza un modelo Random Forest mediante búsqueda aleatoria de hiperparámetros (Random Search).\n",
    "\n",
    "    Evalúa una cantidad limitada de combinaciones seleccionadas al azar, \n",
    "    optimizando el AUC con validación cruzada.\n",
    "\n",
    "    Args:\n",
    "        X_train (np.ndarray): Datos de entrenamiento escalados.\n",
    "        y_train (pd.Series): Etiquetas del conjunto de entrenamiento.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Una tupla con:\n",
    "            - best_estimator_ (RandomForestClassifier): Mejor modelo encontrado.\n",
    "            - best_params_ (dict): Parámetros óptimos seleccionados.\n",
    "            - time_taken (float): Tiempo de ejecución en segundos.\n",
    "    \"\"\"\n",
    "    param_dist = {\n",
    "        \"n_estimators\": randint(50, 200),\n",
    "        \"max_depth\": randint(5, 30),\n",
    "        \"min_samples_split\": randint(2, 20),\n",
    "        \"min_samples_leaf\": randint(1, 10),\n",
    "        \"max_features\": ['sqrt', 'log2'],\n",
    "        \"class_weight\": ['balanced']\n",
    "    }\n",
    "    \n",
    "    start_time = time.time()\n",
    "    random_search = RandomizedSearchCV(\n",
    "        RandomForestClassifier(random_state=42),\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=30,\n",
    "        scoring='roc_auc',\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        verbose=0,\n",
    "        random_state=42\n",
    "    )\n",
    "    random_search.fit(X_train, y_train)\n",
    "    time_taken = time.time() - start_time\n",
    "    \n",
    "    return random_search.best_estimator_, random_search.best_params_, time_taken\n",
    "\n",
    "def optimize_with_optuna(X_train: np.ndarray, y_train: pd.Series, n_trials: int = 30) -> tuple:\n",
    "    \"\"\"\n",
    "    Optimiza un modelo Random Forest utilizando búsqueda bayesiana con Optuna.\n",
    "\n",
    "    Se define una función objetivo que entrena y evalúa modelos en una validación interna\n",
    "    para evitar sobreajuste, optimizando la métrica AUC.\n",
    "\n",
    "    Args:\n",
    "        X_train (np.ndarray): Datos de entrenamiento escalados.\n",
    "        y_train (pd.Series): Etiquetas del conjunto de entrenamiento.\n",
    "        n_trials (int, optional): Número de iteraciones (trials) para la optimización. Por defecto 30.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Una tupla con:\n",
    "            - best_model (RandomForestClassifier): Mejor modelo encontrado y reentrenado.\n",
    "            - best_params (dict): Conjunto de hiperparámetros óptimos.\n",
    "            - time_taken (float): Tiempo total de ejecución en segundos.\n",
    "    \"\"\"\n",
    "    # División interna para validación (evita data leakage)\n",
    "    X_train_opt, X_val, y_train_opt, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    "    )\n",
    "    \n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 200),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 5, 30),\n",
    "            \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 20),\n",
    "            \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 10),\n",
    "            \"max_features\": trial.suggest_categorical(\"max_features\", ['sqrt', 'log2']),\n",
    "            \"class_weight\": 'balanced',\n",
    "            \"random_state\": 42,\n",
    "            \"n_jobs\": -1\n",
    "        }\n",
    "        \n",
    "        model = RandomForestClassifier(**params)\n",
    "        model.fit(X_train_opt, y_train_opt)\n",
    "        y_proba = model.predict_proba(X_val)[:, 1]\n",
    "        return roc_auc_score(y_val, y_proba)  # Optimizar AUC\n",
    "    \n",
    "    start_time = time.time()\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "    \n",
    "    # Entrenar con mejores parámetros usando todos los datos\n",
    "    best_params = study.best_params\n",
    "    best_model = RandomForestClassifier(\n",
    "        **best_params,\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    best_model.fit(X_train, y_train)\n",
    "    time_taken = time.time() - start_time\n",
    "    \n",
    "    return best_model, best_params, time_taken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6122b5",
   "metadata": {},
   "source": [
    "**Bloque 4:** Funciones de visualización.\n",
    "\n",
    "- **`plot_combined_metrics()`** \n",
    "Crea dos gráficos para comparar los resultados cuantitativos de las métricas de rendimiento y tiempo de ejecución entre el modelo base y los optimizados.\n",
    "\n",
    "- **`plot_combined_model_analysis() -> dict`:** \n",
    "Crea dos gráficos comparar los resultados cualitativos entre los modelos para evaluar ROC e importancia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452f85f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_combined_metrics(results_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Genera una visualización comparativa de métricas de rendimiento y tiempos de ejecución.\n",
    "\n",
    "    La figura contiene dos subgráficos:\n",
    "    1. Barras agrupadas con las principales métricas (F1-Score, Precisión, Recall, AUC) por método.\n",
    "    2. Tiempos de ejecución de cada método en escala logarítmica.\n",
    "\n",
    "    Args:\n",
    "        results_df (pd.DataFrame): DataFrame que contiene las métricas evaluadas y el tiempo \n",
    "                                   de ejecución por cada método de optimización. Debe incluir \n",
    "                                   columnas como 'Método', 'F1-Score', 'Precisión', 'Recall', \n",
    "                                   'AUC' y 'Tiempo (s)'.\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7))\n",
    "    \n",
    "    # --- Subgráfico 1: Métricas de rendimiento ---\n",
    "    metrics_df = results_df.drop('Tiempo (s)', axis=1)\n",
    "    metrics_df.set_index('Método', inplace=True)\n",
    "    \n",
    "    # Configuración de colores\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(metrics_df.columns)))\n",
    "    \n",
    "    # Posiciones de las barras\n",
    "    x = np.arange(len(metrics_df.index))\n",
    "    width = 0.2\n",
    "    \n",
    "    # Dibujar barras para cada métrica\n",
    "    for i, metric in enumerate(metrics_df.columns):\n",
    "        ax1.bar(x + i * width, metrics_df[metric], width, label=metric, color=colors[i])\n",
    "        # Añadir valores numéricos\n",
    "        for j, value in enumerate(metrics_df[metric]):\n",
    "            ax1.text(j + i * width, value + 0.02, f'{value:.3f}', \n",
    "                    ha='center', fontsize=9)\n",
    "\n",
    "    # Configurar ejes y leyenda\n",
    "    ax1.set_title('Comparación de Métricas por Método de Optimización', fontsize=14)\n",
    "    ax1.set_ylabel('Valor', fontsize=12)\n",
    "    ax1.set_xticks(x + width * (len(metrics_df.columns) - 1) / 2)\n",
    "    ax1.set_xticklabels(metrics_df.index, fontsize=10)\n",
    "    ax1.set_ylim(0, 1)\n",
    "    ax1.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), \n",
    "               fancybox=True, shadow=True, ncol=4, fontsize=10)\n",
    "    ax1.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # --- Subgráfico 2: Tiempos de ejecución ---\n",
    "    # Usamos escala logarítmica para mejor visualización\n",
    "    time_df = results_df[['Método', 'Tiempo (s)']].copy()\n",
    "    time_df['Tiempo (s)'] = time_df['Tiempo (s)'].apply(lambda x: max(x, 0.1))  # Evitar 0 en log\n",
    "    \n",
    "    # Gráfico de barras con colores\n",
    "    colors = plt.cm.plasma(np.linspace(0, 1, len(time_df)))\n",
    "    bars = ax2.bar(time_df['Método'], time_df['Tiempo (s)'], color=colors)\n",
    "    ax2.set_yscale('log')\n",
    "    \n",
    "    # Añadir valores\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2., height, f'{height:.1f}s', \n",
    "                 ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    # Configuración\n",
    "    ax2.set_title('Tiempo de Ejecución por Método', fontsize=14)\n",
    "    ax2.set_ylabel('Tiempo (segundos, escala log)', fontsize=12)\n",
    "    ax2.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"comparacion_cuantitativa\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_combined_model_analysis(models: dict, X_test: np.ndarray, y_test: pd.Series, \n",
    "                                model, feature_names: list):\n",
    "    \"\"\"\n",
    "    Genera una visualización con análisis comparativo de modelos y explicación del modelo final.\n",
    "\n",
    "    La figura contiene dos subgráficos:\n",
    "    1. Curvas ROC de distintos modelos para comparar su capacidad discriminativa.\n",
    "    2. Importancia de características del modelo final entrenado (basado en Random Forest).\n",
    "\n",
    "    Args:\n",
    "        models (dict): Diccionario de modelos con nombres como claves y objetos de clasificación como valores.\n",
    "        X_test (np.ndarray): Datos de prueba escalados.\n",
    "        y_test (pd.Series): Etiquetas verdaderas del conjunto de prueba.\n",
    "        model: Modelo final ya entrenado (debe contar con `feature_importances_`).\n",
    "        feature_names (list): Lista con los nombres de las características originales del dataset.\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7))\n",
    "    \n",
    "    # --- Subgráfico 1: Curvas ROC ---\n",
    "    ax1.plot([0, 1], [0, 1], 'k--', label='Clasificador aleatorio')\n",
    "    \n",
    "    # Colores para las curvas\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(models)))\n",
    "    \n",
    "    for i, (name, model_obj) in enumerate(models.items()):\n",
    "        y_proba = model_obj.predict_proba(X_test)[:, 1]\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "        auc_score = roc_auc_score(y_test, y_proba)\n",
    "        ax1.plot(fpr, tpr, label=f'{name} (AUC = {auc_score:.3f})', \n",
    "                linewidth=2.5, color=colors[i])\n",
    "    \n",
    "    # Configuración\n",
    "    ax1.set_title('Curvas ROC Comparativas', fontsize=14)\n",
    "    ax1.set_xlabel('Tasa de Falsos Positivos (FPR)', fontsize=12)\n",
    "    ax1.set_ylabel('Tasa de Verdaderos Positivos (TPR)', fontsize=12)\n",
    "    ax1.legend(loc='lower right', fontsize=10)\n",
    "    ax1.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # --- Subgráfico 2: Importancia de características ---\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    # Gráfico de barras con colores\n",
    "    colors = plt.cm.coolwarm(np.linspace(0, 1, len(importances)))\n",
    "    bars = ax2.bar(range(len(importances)), importances[indices], \n",
    "                 color=colors, align='center')\n",
    "    \n",
    "    # Configuración de ejes\n",
    "    ax2.set_title(\"Importancia de Características\", fontsize=14)\n",
    "    ax2.set_xticks(range(len(importances)))\n",
    "    ax2.set_xticklabels([feature_names[i] for i in indices], \n",
    "                      rotation=45, ha='right', fontsize=10)\n",
    "    ax2.set_xlabel('Características', fontsize=12)\n",
    "    ax2.set_ylabel('Importancia Relativa', fontsize=12)\n",
    "    \n",
    "    # Añadir valores en las barras\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2., height, \n",
    "                f'{height:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"comparacion_cualitativa\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fe306d",
   "metadata": {},
   "source": [
    "**Bloque 5:** Función de ejecución.\n",
    "- **`main()`**\n",
    "Utiliza todas las funciones definidas anteriormente para obtener datos del modelo base y de los modelos optimizados con **GridSearchCV**, **RandomizedSearchCV** y **Optuna**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcd2fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Ejecuta el flujo completo de entrenamiento, optimización y análisis de modelos para detección de diabetes.\n",
    "\n",
    "    Pasos que realiza:\n",
    "    1. Carga y exploración inicial del dataset desde una URL.\n",
    "    2. Preprocesamiento de datos: limpieza, escalado y división en conjuntos.\n",
    "    3. Entrenamiento de un modelo base con Random Forest.\n",
    "    4. Optimización de hiperparámetros con tres enfoques: Grid Search, Random Search y Optuna.\n",
    "    5. Evaluación de rendimiento con métricas como F1-Score, Precisión, Recall y AUC.\n",
    "    6. Visualización comparativa de métricas y tiempos, además de análisis de importancia de características.\n",
    "\n",
    "    Returns:\n",
    "        dict: Diccionario con resultados clave del análisis, incluyendo:\n",
    "            - 'df' (pd.DataFrame): Dataset original procesado.\n",
    "            - 'results_df' (pd.DataFrame): Tabla con métricas y tiempos por método.\n",
    "            - 'models' (dict): Modelos entrenados por nombre.\n",
    "            - 'feature_names' (list): Lista de nombres de características usadas.\n",
    "    \"\"\"\n",
    "    # 1. Carga de datos\n",
    "    URL = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "    df = load_data(URL)\n",
    "    \n",
    "    # 2. Preprocesamiento\n",
    "    X_train, X_test, y_train, y_test, scaler = preprocess_data(df)\n",
    "    feature_names = df.drop(\"Outcome\", axis=1).columns.tolist()\n",
    "    \n",
    "    # 3. Modelo base\n",
    "    print(\"\\nEntrenando modelo base...\")\n",
    "    base_model, base_time = train_base_model(X_train, y_train)\n",
    "    base_metrics = evaluate_model(base_model, X_test, y_test)\n",
    "    print(f\"Resultados modelo base:\\n{base_metrics}\")\n",
    "    \n",
    "    # 4. Optimización de hiperparámetros\n",
    "    print(\"\\nOptimizando con Grid Search...\")\n",
    "    grid_model, grid_params, grid_time = optimize_with_gridsearch(X_train, y_train)\n",
    "    grid_metrics = evaluate_model(grid_model, X_test, y_test)\n",
    "    \n",
    "    print(\"\\nOptimizando con Random Search...\")\n",
    "    random_model, random_params, random_time = optimize_with_randomsearch(X_train, y_train)\n",
    "    random_metrics = evaluate_model(random_model, X_test, y_test)\n",
    "    \n",
    "    print(\"\\nOptimizando con Optuna (Bayesiana)...\")\n",
    "    optuna_model, optuna_params, optuna_time = optimize_with_optuna(X_train, y_train)\n",
    "    optuna_metrics = evaluate_model(optuna_model, X_test, y_test)\n",
    "    \n",
    "    # 5. Comparación de resultados\n",
    "    results_df = pd.DataFrame({\n",
    "        \"Método\": [\"Base\", \"Grid Search\", \"Random Search\", \"Optuna\"],\n",
    "        \"F1-Score\": [base_metrics[\"F1-Score\"], grid_metrics[\"F1-Score\"], \n",
    "                     random_metrics[\"F1-Score\"], optuna_metrics[\"F1-Score\"]],\n",
    "        \"Precisión\": [base_metrics[\"Precisión\"], grid_metrics[\"Precisión\"], \n",
    "                      random_metrics[\"Precisión\"], optuna_metrics[\"Precisión\"]],\n",
    "        \"Recall\": [base_metrics[\"Recall\"], grid_metrics[\"Recall\"], \n",
    "                  random_metrics[\"Recall\"], optuna_metrics[\"Recall\"]],\n",
    "        \"AUC\": [base_metrics[\"AUC\"], grid_metrics[\"AUC\"], \n",
    "                random_metrics[\"AUC\"], optuna_metrics[\"AUC\"]],\n",
    "        \"Tiempo (s)\": [base_time, grid_time, random_time, optuna_time]\n",
    "    })\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Comparación de Resultados\")\n",
    "    print(\"=\"*50)\n",
    "    print(results_df)\n",
    "    \n",
    "    # 6. Visualizaciones\n",
    "    models_dict = {\n",
    "        \"Base\": base_model,\n",
    "        \"Grid Search\": grid_model,\n",
    "        \"Random Search\": random_model,\n",
    "        \"Optuna\": optuna_model\n",
    "    }\n",
    "    \n",
    "    plot_combined_metrics(results_df)\n",
    "    plot_combined_model_analysis(models_dict, X_test, y_test, optuna_model, feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e5fd8b",
   "metadata": {},
   "source": [
    "# 4. Visualización de resultados\n",
    "\n",
    "Se muestran los resultados obtenidos a partir de la ejecución de la funcion **main()**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529f41f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejectura la función main()\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e861e3",
   "metadata": {},
   "source": [
    "# Análisis de resultados y reflexiones Finales\n",
    "\n",
    "---\n",
    "\n",
    "## Hallazgos Clave\n",
    "\n",
    "1. **Trade-off Precisión vs. Recall**\n",
    "   - Los modelos optimizados mostraron un descenso leve en precisión (~4%) pero un aumento sustancial en recall (~19%) respecto al modelo base.\n",
    "   - En contextos clínicos, este balance es positivo: es preferible detectar más casos reales (aunque haya más falsos positivos) que dejar sin diagnosticar pacientes con diabetes.\n",
    "\n",
    "2. **Eficiencia Computacional**\n",
    "   - **Grid Search** fue el método más costoso en tiempo (~20 s), siendo 5 a 6 veces más lento que Random Search u Optuna.\n",
    "   - **Random Search** y **Optuna** lograron mejores resultados con menor tiempo de cómputo, destacando su escalabilidad.\n",
    "   - **Optuna** ofrece, además, retroalimentación en tiempo real, lo que mejora el proceso iterativo de optimización.\n",
    "\n",
    "3. **Variables Predictivas Más Relevantes**\n",
    "   - La glucosa (`Glucose`) fue consistentemente la variable más importante en la predicción.\n",
    "   - También destacaron el índice de masa corporal (`BMI`) y la edad (`Age`), en línea con evidencia médica sobre factores de riesgo para diabetes tipo II.\n",
    "\n",
    "---\n",
    "\n",
    "## Limitaciones y Mejoras Futuras\n",
    "\n",
    "1. **Manejo del Desbalanceo**\n",
    "   - Explorar estrategias como pesos de clase, submuestreo/oversampling o SMOTE.\n",
    "\n",
    "2. **Optimización y Modelos Avanzados**\n",
    "   - Probar algoritmos adicionales como **XGBoost** o **LightGBM**.\n",
    "   - Incorporar técnicas de **selección de características** y **validación cruzada anidada** para mayor robustez.\n",
    "\n",
    "3. **Interpretabilidad Clínica**\n",
    "   - Analizar interacciones entre variables para mejorar la explicabilidad del modelo frente a profesionales de salud.\n",
    "\n",
    "---\n",
    "\n",
    "## Relevancia en Contextos Reales\n",
    "\n",
    "1. **Aplicación Clínica**\n",
    "   - Modelos con alto recall ayudan a minimizar falsos negativos, fundamentales en el diagnóstico temprano de diabetes.\n",
    "   - El costo de un falso positivo (una prueba innecesaria) es menor que el de un diagnóstico perdido.\n",
    "\n",
    "2. **Procesamiento a Escala**\n",
    "   - Técnicas como Random Search y Optuna son más adecuadas para conjuntos de datos grandes o en sistemas distribuidos.\n",
    "   - El uso de técnicas de muestreo puede acelerar iteraciones sin perder rendimiento.\n",
    "\n",
    "3. **Despliegue y Mantenimiento**\n",
    "   - Considerar el **monitoreo continuo del desempeño** del modelo en producción.\n",
    "   - Planificar actualizaciones periódicas con datos recientes.\n",
    "   - Establecer sistemas de alerta ante cambios significativos en la distribución de datos o el entorno clínico.\n",
    "\n",
    "---\n",
    "\n",
    "> **Conclusión Final:**  \n",
    "> La optimización de hiperparámetros marca una diferencia significativa en el rendimiento de modelos de predicción clínica. En este estudio, Random Search y Optuna mejoraron el **recall en un 19%** respecto al modelo base, manteniendo tiempos computacionales razonables. Estas técnicas son clave para desarrollar sistemas predictivos útiles en el diagnóstico temprano de diabetes tipo II, donde detectar a tiempo puede marcar la diferencia entre tratamiento efectivo y complicaciones severas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
