{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1df97ea",
   "metadata": {},
   "source": [
    "# Evaluación Modular:\n",
    "# Optimización de Modelos para la Predicción de Enfermedades Crónicas\n",
    "\n",
    "## Objetivo\n",
    "Desarrollar y optimizar un modelo de aprendizaje automático capaz de predecir la probabilidad de que un paciente desarrolle una enfermedad crónica específica, utilizando técnicas avanzadas de ajuste de hiperparámetros con Optuna y Ray Tune. Se espera que el modelo optimizado proporcione predicciones precisas y generalizables, contribuyendo a la identificación temprana y prevención de enfermedades crónicas en el ámbito de la salud pública.\n",
    "\n",
    "**Dataset utilizado:**  \n",
    "[Disease Prediction Using Machine Learning](https://www.kaggle.com/datasets/kaushil268/disease-prediction-using-machine-learning/discussion)\n",
    "\n",
    "---\n",
    "\n",
    "### Estructura del Notebook:\n",
    "1. Metodología.\n",
    "2. Configuración inicial del notebook.\n",
    "3. Definicion de funciones.\n",
    "4. Uso de funciones y resultados.\n",
    "5. Análisis de los resultados y reflexiones finales.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012bb0c2",
   "metadata": {},
   "source": [
    "## 1. Metodología\n",
    "\n",
    "---\n",
    "\n",
    "### Flujo de trabajo\n",
    "1. **Carga de datos:**\n",
    "   - Carga de datos, se concatenan los archivos **Training.csv** y **Testing.csv** en una solo data.\n",
    "   - Escalado de características con `StandardScaler`.\n",
    "   - División de datos en entrenamiento y prueba (70% / 30%) con estratificación de clases.\n",
    "\n",
    "2. **Modelos creados:**\n",
    "   - **Modelo base:** RandomForestClassifier con hiperparámetros por defecto.\n",
    "   - **Modelo optimizado con Optuna:** RandomForestClassifier optimizado mediante Optuna con 20 trials.\n",
    "   - **Modelo optimizado con Ray Tune:** RandomForestClassifier optimizado mediante Ray Tune con 20 trials. Uso de CallBack para mostrar logs.\n",
    "\n",
    "3. **Evaluación de modelos:**\n",
    "   - **Métricas evaluadas:**\n",
    "      - F1 Score.\n",
    "      - Tiempo de ejecución.\n",
    "\n",
    "4. **Comparación y visualización:**\n",
    "   - Resumen del dataset.\n",
    "   - Mejores hiperparametros encontrados por Optuna y Ray Tune.\n",
    "   - Resultados del modelo base, optimizado con Optuna y optimizado con Ray Tune.\n",
    "   - Gráficos de comparación de rendimiento (F1-Score) y tiempos de ejecución.\n",
    "   - Gráficos de evolución de F1-Score en los modelos optimizados con Optuna y Ray Tune.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5986d0fe",
   "metadata": {},
   "source": [
    "# 2. Configuración inicial del notebook\n",
    "- Importación de librerias necesarias.\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b6b715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "import optuna\n",
    "import ray\n",
    "from ray import train, tune\n",
    "from ray.tune import Tuner\n",
    "from ray.tune.search.basic_variant import BasicVariantGenerator\n",
    "from ray.tune import Callback\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e2e9ce",
   "metadata": {},
   "source": [
    "# 3. Definición de funciones\n",
    "\n",
    "> **Nota:** Para mejor comprensión de las funciones y su utilidad, esta sección se divide en bloques, en donde cada uno responde a una parte diferente de la metodología de trabajo. \n",
    "\n",
    "---\n",
    "\n",
    "**Bloque 0:** Configuración del entorno\n",
    "\n",
    "- **`setup_environment()`** \n",
    "Debido a lso multiples errores y warnings que ocurren durante la ejecución, se decidió configurar el setup para mejorar la legibilidad de las salidas de codigo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbffb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_environment():\n",
    "    \"\"\"\n",
    "    Configura variables de entorno, logging y estilo gráfico.\n",
    "    Esta función se debe llamar al inicio del flujo principal.\n",
    "    \"\"\"\n",
    "\n",
    "    # ===== Desactiva servicios externos de Apache Arrow que no se usarán =====\n",
    "    os.environ['ARROW_DISABLE_S3'] = '1'       # Desactiva soporte para Amazon S3 (ahorra memoria si no se usa)\n",
    "    os.environ['ARROW_DISABLE_GCS'] = '1'      # Desactiva soporte para Google Cloud Storage\n",
    "    os.environ['ARROW_DISABLE_HDFS'] = '1'     # Desactiva soporte para Hadoop File System\n",
    "\n",
    "    # ===== Configura Ray para entornos locales (como notebooks) =====\n",
    "    os.environ['RAY_DISABLE_DASHBOARD'] = '1'  # Evita que Ray inicie su dashboard web (consume recursos)\n",
    "    os.environ['RAY_ENABLE_WINDOWS_OR_OSX_CLUSTER'] = '1'  # Permite ejecutar Ray en Windows/macOS\n",
    "    os.environ['RAY_LOG_TO_STDERR'] = '1'      # Redirige los logs de Ray a stderr (consola)\n",
    "    os.environ['RAY_DEDUP_LOGS'] = '0'         # Muestra todos los logs, incluso si están repetidos\n",
    "\n",
    "    # ===== Reduce verbosidad de logs de Apache Arrow =====\n",
    "    os.environ['ARROW_VERBOSE_THRESHOLD'] = '0'  # Reduce al mínimo los mensajes de log de Arrow\n",
    "\n",
    "    # ===== Configura el logging de Python (global) =====\n",
    "    logging.basicConfig(level=logging.ERROR)     # Solo se mostrarán errores (oculta warnings/info)\n",
    "\n",
    "    # ===== Configura el estilo visual de los gráficos =====\n",
    "    sns.set_style(\"whitegrid\")                   # Estilo de seaborn con fondo blanco y cuadrículas\n",
    "    plt.rcParams['figure.figsize'] = (12, 6)     # Tamaño por defecto de las figuras (ancho x alto)\n",
    "    plt.rcParams['font.size'] = 12               # Tamaño de fuente legible\n",
    "    plt.rcParams['figure.max_open_warning'] = 50 # Permite abrir hasta 50 figuras sin warning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2ae5fe",
   "metadata": {},
   "source": [
    "**Bloque 1:** Carga y preprocesamiento de datos\n",
    "\n",
    "- **`load_and_preprocess_data()`** \n",
    "Carga el dataset de diagnóstico de enfermedades, divide los datos en conjuntos de entrenamiento y prueba, codifica etiquetas, escala los datos y genera un resumen del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a97925d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder#, label_binarize\n",
    "def load_and_preprocess_data(data):\n",
    "    \"\"\"\n",
    "    Realiza la carga y el preprocesamiento del dataset de cáncer de mama.\n",
    "\n",
    "    Este paso incluye:\n",
    "    - División del conjunto de datos en entrenamiento y prueba (70/30, con estratificación).\n",
    "    - Escalamiento de características numéricas usando StandardScaler.\n",
    "    - Creación de un resumen informativo del dataset.\n",
    "\n",
    "    Args:\n",
    "        data (sklearn.utils.Bunch): Objeto cargado con `load_breast_cancer()` de scikit-learn.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            - X_train_scaled (np.ndarray): Datos de entrenamiento escalados.\n",
    "            - X_test_scaled (np.ndarray): Datos de prueba escalados.\n",
    "            - y_train (np.ndarray): Etiquetas de entrenamiento.\n",
    "            - y_test (np.ndarray): Etiquetas de prueba.\n",
    "            - data (Bunch): El dataset original sin modificar.\n",
    "            - info_df (pd.DataFrame): DataFrame resumen del dataset (tamaño, clases, particiones, etc.).\n",
    "    \"\"\"\n",
    "\n",
    "    # Separar características y variable objetivo\n",
    "    X = data.drop(columns=['prognosis'])\n",
    "    y = data['prognosis']\n",
    "    \n",
    "    # División train/test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Codificar etiquetas\n",
    "    le = LabelEncoder()\n",
    "    y_train_enc = le.fit_transform(y_train)\n",
    "    y_test_enc = le.transform(y_test)\n",
    "\n",
    "    # Escalamiento\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Obtener clases y distribución\n",
    "    clases = sorted(y.unique())  # Ej: ['asma', 'bronquitis', 'lupus', ...]\n",
    "    clases_str = \", \".join(str(c) for c in clases)\n",
    "\n",
    "    # Distribución de clases\n",
    "    counts = y.value_counts()  # Series con índices = clases, valores = conteo\n",
    "    distribucion_clases = \", \".join([f\"{v} ({k})\" for k, v in counts.items()])\n",
    "    \n",
    "    # Resumen\n",
    "    info_dict = {\n",
    "        \"Total muestras\": [X.shape[0]],\n",
    "        \"N° características\": [X.shape[1]],\n",
    "        \"N° clases\": [len(clases)],\n",
    "        \"Clases\": [clases_str],\n",
    "        \"Distribución clases\": [distribucion_clases],\n",
    "        \"Train size\": [X_train.shape[0]],\n",
    "        \"Test size\": [X_test.shape[0]],\n",
    "        \"Shape X_train\": [X_train_scaled.shape],\n",
    "        \"Shape X_test\": [X_test_scaled.shape]\n",
    "    }\n",
    "    info_df = pd.DataFrame(info_dict)\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled, y_train_enc, y_test_enc, data, info_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254b2302",
   "metadata": {},
   "source": [
    "**Bloque 2:** Aplicación del modelo base, y optimizados con Optuna y Ray Tune\n",
    "\n",
    "- **`train_baseline_model()`** \n",
    "Entrena y evalúa un modelo base Random Forest con hiperparámetros por defecto.\n",
    "\n",
    "- **`optimize_with_optuna()`** \n",
    "Realiza optimización de hiperparámetros para un modelo Random Forest usando Optuna.\n",
    "\n",
    "- **`optimize_with_ray_tune()`** \n",
    "Realiza optimización de hiperparámetros para un modelo Random Forest utilizando Ray Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3495fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_baseline_model(X_train, y_train, X_test, y_test, target_names):\n",
    "    \"\"\"\n",
    "    Entrena y evalúa un modelo base Random Forest con hiperparámetros por defecto.\n",
    "\n",
    "    El modelo se ajusta sobre los datos de entrenamiento y se evalúa usando F1-score\n",
    "    sobre el conjunto de prueba.\n",
    "\n",
    "    Args:\n",
    "        X_train (np.ndarray): Conjunto de entrenamiento (features) escalado.\n",
    "        y_train (np.ndarray): Etiquetas del conjunto de entrenamiento.\n",
    "        X_test (np.ndarray): Conjunto de prueba (features) escalado.\n",
    "        y_test (np.ndarray): Etiquetas del conjunto de prueba.\n",
    "        target_names (np.ndarray): Nombres de las clases objetivo (no usado directamente aquí, \n",
    "                                   pero útil para extensiones o reportes detallados).\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            - base_model (RandomForestClassifier): Modelo entrenado.\n",
    "            - base_f1 (float): F1-score en el conjunto de prueba.\n",
    "            - base_train_time (float): Tiempo de entrenamiento (segundos).\n",
    "            - y_pred_base (np.ndarray): Predicciones del modelo base en el test set.\n",
    "    \"\"\"\n",
    "    # Entrenar modelo con parámetros por defecto\n",
    "    start_time = time.time()\n",
    "    base_model = RandomForestClassifier(random_state=42)\n",
    "    base_model.fit(X_train, y_train)\n",
    "    base_train_time = time.time() - start_time\n",
    "\n",
    "    # Evaluación del modelo\n",
    "    y_pred_base = base_model.predict(X_test)\n",
    "    base_f1 = f1_score(y_test, y_pred_base, average='macro')\n",
    "\n",
    "    return base_model, base_f1, base_train_time, y_pred_base\n",
    "\n",
    "\n",
    "def optimize_with_optuna(X_train, y_train, X_test, y_test, n_trials=20):\n",
    "    \"\"\"\n",
    "    Realiza optimización de hiperparámetros para un modelo Random Forest usando Optuna.\n",
    "\n",
    "    Busca maximizar el F1-score en el conjunto de prueba, evaluando distintos \n",
    "    conjuntos de parámetros mediante validación directa. Al finalizar, se \n",
    "    entrena un modelo final con los mejores parámetros encontrados.\n",
    "\n",
    "    Args:\n",
    "        X_train (np.ndarray): Conjunto de entrenamiento (features) escalado.\n",
    "        y_train (np.ndarray): Etiquetas del conjunto de entrenamiento.\n",
    "        X_test (np.ndarray): Conjunto de prueba (features) escalado.\n",
    "        y_test (np.ndarray): Etiquetas del conjunto de prueba.\n",
    "        n_trials (int, opcional): Número de combinaciones a probar (default: 20).\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            - optuna_best_model (RandomForestClassifier): Modelo final entrenado con los mejores parámetros.\n",
    "            - optuna_f1 (float): F1-score del modelo optimizado en el test set.\n",
    "            - optuna_time (float): Tiempo total de optimización en segundos.\n",
    "            - optuna_results (pd.DataFrame): Detalles de todos los trials realizados.\n",
    "            - y_pred_optuna (np.ndarray): Predicciones del modelo optimizado.\n",
    "            - optuna_best_params (dict): Diccionario con los mejores hiperparámetros encontrados.\n",
    "            - best_trial (int): Número del mejor trial según F1-score.\n",
    "    \"\"\"\n",
    "    print(f\"\\nOptimizando modelo con Optuna ({n_trials} trials)\")\n",
    "    \n",
    "    # Función objetivo para Optuna\n",
    "    def objective(trial):\n",
    "        # Espacio de búsqueda\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 10, 200),\n",
    "            'max_depth': trial.suggest_int('max_depth', 2, 32),\n",
    "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 20)\n",
    "        }\n",
    "        \n",
    "        # Crear y entrenar modelo\n",
    "        model = RandomForestClassifier(**params, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Evaluar con F1-score\n",
    "        y_pred = model.predict(X_test)\n",
    "        return f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Ejecutar estudio de optimización\n",
    "    print(\"Iniciando búsqueda de hiperparámetros con Optuna...\", flush=True)\n",
    "    start_time = time.time()\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "    optuna_time = time.time() - start_time\n",
    "\n",
    "    # Obtener mejores parámetros\n",
    "    optuna_best_params = study.best_params\n",
    "    optuna_best_model = RandomForestClassifier(**optuna_best_params, random_state=42)\n",
    "    optuna_best_model.fit(X_train, y_train)\n",
    "    y_pred_optuna = optuna_best_model.predict(X_test)\n",
    "    optuna_f1 = f1_score(y_test, y_pred_optuna, average='macro')\n",
    "\n",
    "    # Resultados de los trials\n",
    "    optuna_results = study.trials_dataframe()\n",
    "    \n",
    "    return optuna_best_model, optuna_f1, optuna_time, optuna_results, y_pred_optuna, optuna_best_params, study.best_trial.number\n",
    "\n",
    "\n",
    "def optimize_with_ray_tune(X_train, y_train, X_test, y_test, n_trials=20):\n",
    "    \"\"\"\n",
    "    Realiza optimización de hiperparámetros para un modelo Random Forest utilizando Ray Tune.\n",
    "\n",
    "    Usa búsqueda aleatoria (BasicVariantGenerator) sobre un espacio de hiperparámetros definido.\n",
    "    Registra el F1-score de cada configuración y retorna el modelo con mejor desempeño, junto a\n",
    "    sus resultados detallados. Incluye captura y despliegue de logs personalizados durante el proceso.\n",
    "\n",
    "    Args:\n",
    "        X_train (np.ndarray): Conjunto de entrenamiento (features) escalado.\n",
    "        y_train (np.ndarray): Etiquetas del conjunto de entrenamiento.\n",
    "        X_test (np.ndarray): Conjunto de prueba (features) escalado.\n",
    "        y_test (np.ndarray): Etiquetas del conjunto de prueba.\n",
    "        n_trials (int, opcional): Número de configuraciones a evaluar (default: 20).\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            - ray_best_model (RandomForestClassifier): Modelo final entrenado con los mejores parámetros.\n",
    "            - ray_f1 (float): F1-score del modelo optimizado en el test set.\n",
    "            - ray_time (float): Tiempo total de optimización en segundos.\n",
    "            - ray_results_df (pd.DataFrame): DataFrame con el resumen de cada trial.\n",
    "            - y_pred_ray (np.ndarray): Predicciones del modelo optimizado.\n",
    "            - ray_best_params (dict): Hiperparámetros óptimos encontrados.\n",
    "    \"\"\"\n",
    "  \n",
    "    # Callback para mostrar progreso\n",
    "    class ProgressCallback(Callback):\n",
    "        def __init__(self, total_trials):\n",
    "            self.total_trials = total_trials\n",
    "            self.completed_trials = 0\n",
    "            self.header_printed = False\n",
    "\n",
    "        def on_trial_complete(self, iteration, trials, trial):\n",
    "            if not self.header_printed:\n",
    "                print(\"=\"*50)\n",
    "                print(f\"Optimizando modelo con Ray Tune ({self.total_trials} trials)\")\n",
    "                print(\"=\"*50)\n",
    "                self.header_printed = True\n",
    "\n",
    "            self.completed_trials += 1\n",
    "            f1 = trial.last_result['f1_score']\n",
    "            params = trial.config\n",
    "            timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            print(f\"[I {timestamp}] Trial {self.completed_trials} finished with value: {f1:.4f} and parameters: {params}.\", flush=True)\n",
    "\n",
    "    # Configurar Ray\n",
    "    ray.init(\n",
    "        ignore_reinit_error=True,\n",
    "        include_dashboard=False,\n",
    "        logging_level=logging.CRITICAL,\n",
    "        log_to_driver=False\n",
    "    )\n",
    "\n",
    "    # Función entrenable para Ray Tune\n",
    "    def trainable(config):\n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=config[\"n_estimators\"],\n",
    "            max_depth=config[\"max_depth\"],\n",
    "            min_samples_split=config[\"min_samples_split\"],\n",
    "            random_state=42\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        f1 = f1_score(y_test, y_pred, average='macro')\n",
    "        train.report({\"f1_score\": f1})\n",
    "\n",
    "    # Espacio de búsqueda\n",
    "    param_space = {\n",
    "        \"n_estimators\": tune.randint(10, 200),\n",
    "        \"max_depth\": tune.randint(2, 32),\n",
    "        \"min_samples_split\": tune.randint(2, 20)\n",
    "    }\n",
    "\n",
    "    # Configurar el sintonizador\n",
    "    tuner = Tuner(\n",
    "        trainable,\n",
    "        param_space=param_space,\n",
    "        tune_config=tune.TuneConfig(\n",
    "            metric=\"f1_score\",\n",
    "            mode=\"max\",\n",
    "            num_samples=n_trials,\n",
    "            search_alg=BasicVariantGenerator(),\n",
    "            max_concurrent_trials=4\n",
    "        ),\n",
    "        run_config=train.RunConfig(\n",
    "            verbose=0,\n",
    "            callbacks=[ProgressCallback(n_trials)]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Ejecutar optimización\n",
    "    print(\"Iniciando búsqueda de hiperparámetros con Ray Tune...\")\n",
    "    start_time = time.time()\n",
    "    results = tuner.fit()\n",
    "    ray_time = time.time() - start_time\n",
    "\n",
    "    # Obtener resultados\n",
    "    best_result = results.get_best_result(metric=\"f1_score\", mode=\"max\")\n",
    "    ray_best_params = best_result.config\n",
    "    ray_f1 = best_result.metrics[\"f1_score\"]\n",
    "\n",
    "    # Convertir resultados a DataFrame\n",
    "    ray_results = []\n",
    "    for i, result in enumerate(results):\n",
    "        ray_results.append({\n",
    "            \"trial\": i + 1,\n",
    "            \"params\": result.config,\n",
    "            \"f1_score\": result.metrics[\"f1_score\"]\n",
    "        })\n",
    "    ray_results_df = pd.DataFrame(ray_results)\n",
    "\n",
    "    # Cerrar Ray\n",
    "    ray.shutdown()\n",
    "\n",
    "    # Entrenar modelo final con los mejores parámetros\n",
    "    ray_best_model = RandomForestClassifier(\n",
    "        n_estimators=ray_best_params[\"n_estimators\"],\n",
    "        max_depth=ray_best_params[\"max_depth\"],\n",
    "        min_samples_split=ray_best_params[\"min_samples_split\"],\n",
    "        random_state=42\n",
    "    )\n",
    "    ray_best_model.fit(X_train, y_train)\n",
    "    y_pred_ray = ray_best_model.predict(X_test)\n",
    "\n",
    "    return ray_best_model, ray_f1, ray_time, ray_results_df, y_pred_ray, ray_best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebccba54",
   "metadata": {},
   "source": [
    "**Bloque 3:** Creacion de tablas y gráficos para comparación de modelos.\n",
    "\n",
    "- **`compare_results()`** \n",
    "Compara los resultados de tres modelos (base, Optuna y Ray Tune) y genera visualizaciones, incluyendo tablas comparativas, gráficos de rendimiento, evolución de F1-Score y matrices de confusión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2262603e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_results(base_f1, base_time, optuna_f1, optuna_time, ray_f1, ray_time,\n",
    "                   optuna_results, ray_results_df, y_test,\n",
    "                   y_pred_base, y_pred_optuna, y_pred_ray, target_names):\n",
    "    \"\"\"\n",
    "    Compara los resultados de tres modelos (base, Optuna y Ray Tune) y genera visualizaciones.\n",
    "\n",
    "    Incluye:\n",
    "    - Tabla comparativa de F1-score, tiempo de entrenamiento y número de trials.\n",
    "    - Gráfico de barras con F1-score y tiempos.\n",
    "    - Evolución del F1-score en los trials de Optuna y Ray Tune.\n",
    "    - Matrices de confusión para cada modelo.\n",
    "\n",
    "    Args:\n",
    "        base_f1 (float): F1-score del modelo base.\n",
    "        base_time (float): Tiempo de entrenamiento del modelo base.\n",
    "        optuna_f1 (float): F1-score del modelo optimizado con Optuna.\n",
    "        optuna_time (float): Tiempo total de optimización con Optuna.\n",
    "        ray_f1 (float): F1-score del modelo optimizado con Ray Tune.\n",
    "        ray_time (float): Tiempo total de optimización con Ray Tune.\n",
    "        optuna_results (pd.DataFrame): Resultados de los trials de Optuna.\n",
    "        ray_results_df (pd.DataFrame): Resultados de los trials de Ray Tune.\n",
    "        y_test (np.ndarray): Etiquetas verdaderas del conjunto de prueba.\n",
    "        y_pred_base (np.ndarray): Predicciones del modelo base.\n",
    "        y_pred_optuna (np.ndarray): Predicciones del modelo optimizado con Optuna.\n",
    "        y_pred_ray (np.ndarray): Predicciones del modelo optimizado con Ray Tune.\n",
    "        target_names (list): Nombres de las clases objetivo.\n",
    "\n",
    "    Returns:\n",
    "        None. Solo imprime y visualiza resultados.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"5. COMPARACIÓN DE RESULTADOS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Crear tabla comparativa\n",
    "    comparison_data = {\n",
    "        'Método': ['Modelo Base', 'Optuna', 'Ray Tune'],\n",
    "        'F1-score': [base_f1, optuna_f1, ray_f1],\n",
    "        'Tiempo (s)': [base_time, optuna_time, ray_time],\n",
    "        'Número de Trials': ['-', len(optuna_results), len(ray_results_df)]\n",
    "    }\n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "    # Mostrar tabla comparativa\n",
    "    print(\"\\nTabla Comparativa:\")\n",
    "    print(\"-\"*60)\n",
    "    print(comparison_df.to_string(index=False))\n",
    "    print(\"-\"*60)\n",
    "\n",
    "\n",
    "    # Gráficos\n",
    "\n",
    "    # Gráfico 1: Comparación de F1-scores\n",
    "    fig1, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    sns.barplot(x='Método', y='F1-score', data=comparison_df, ax=axes[0], \n",
    "                hue='Método', palette=\"viridis\", legend=False, dodge=False)\n",
    "    axes[0].set_title('Comparación de Rendimiento (F1-score)')\n",
    "    axes[0].set_ylim(0.9, 1.0)\n",
    "    for i, v in enumerate(comparison_df['F1-score']):\n",
    "        axes[0].text(i, v + 0.005, f\"{v:.4f}\", ha='center', fontsize=12)\n",
    "\n",
    "    # Gráfico 2: Comparación de tiempos de ejecución\n",
    "    sns.barplot(x='Método', y='Tiempo (s)', data=comparison_df, ax=axes[1], \n",
    "                hue='Método', palette=\"rocket\", legend=False, dodge=False)\n",
    "    axes[1].set_title('Comparación de Tiempo de Ejecución')\n",
    "    for i, v in enumerate(comparison_df['Tiempo (s)']):\n",
    "        axes[1].text(i, v + 0.1, f\"{v:.2f}s\", ha='center', fontsize=12)\n",
    "\n",
    "    # Guardar las figuras\n",
    "    fig1.savefig(\"comparacion_metricas.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def plot_top_features(models, feature_names, model_names, top_n=5):\n",
    "    \"\"\"\n",
    "    Genera una figura con los gráficos de barras verticales del top N de variables más importantes\n",
    "    para cada modelo (por importancia de Gini).\n",
    "\n",
    "    Args:\n",
    "        models (list): Lista de modelos RandomForest entrenados (base, Optuna, Ray).\n",
    "        feature_names (list): Lista de nombres de características.\n",
    "        model_names (list): Nombres de los modelos correspondientes.\n",
    "        top_n (int): Número de variables top a mostrar.\n",
    "\n",
    "    Returns:\n",
    "        None. Muestra y guarda la figura.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(20, 6))  # 1 fila, 3 columnas\n",
    "    fig.suptitle(\"Top 5 variables más importantes por modelo\", fontsize=16)\n",
    "\n",
    "    for i, (model, name) in enumerate(zip(models, model_names)):\n",
    "        importances = model.feature_importances_\n",
    "        top_indices = np.argsort(importances)[-top_n:][::-1]\n",
    "        top_features = [feature_names[j] for j in top_indices]\n",
    "        top_values = importances[top_indices]\n",
    "\n",
    "        sns.barplot(x=top_features, y=top_values, ax=axes[i], hue=top_features, palette=\"viridis\", legend=False)\n",
    "        axes[i].set_title(f\"{name}\", fontsize=14)\n",
    "        axes[i].set_xlabel(\"Variable\")\n",
    "        axes[i].set_ylabel(\"Importancia\")\n",
    "        axes[i].set_ylim(0, max(top_values)*1.1)  # un poco de margen arriba\n",
    "\n",
    "        # Agregar etiquetas con valores encima de las barras\n",
    "        for j, v in enumerate(top_values):\n",
    "            axes[i].text(j, v + 0.005, f\"{v:.3f}\", ha='center', fontsize=10)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.savefig(\"top_features_importancia.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290053e0",
   "metadata": {},
   "source": [
    "**Bloque 4:** Funciones de ejecución.\n",
    "\n",
    "Debido a que Ray Tune produce errores como borrar las celdas de salida previas a us ejecución, la función main fue segmentada en dos partes:\n",
    "\n",
    "- **`main()`**\n",
    "Función que ejecuta el flujo: carga de datos, entrenamiento, creación de modelo base y optimizados con Optuna y Ray Tune.\n",
    "\n",
    "- **`main_2()`**\n",
    "Función que toma los resultados obtenidos por main() y muestra los resultados obtenidos a partir de la comparación de los tres modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60330134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Ejecuta el flujo completo de entrenamiento y optimización del modelo.\n",
    "\n",
    "    Incluye:\n",
    "    - Configuración del entorno y estilos.\n",
    "    - Carga y preprocesamiento del dataset de cáncer de mama.\n",
    "    - Entrenamiento de un modelo base sin tuning.\n",
    "    - Optimización de hiperparámetros con Optuna y Ray Tune.\n",
    "    - Evaluación de desempeño (F1-score y tiempo).\n",
    "\n",
    "    Returns:\n",
    "        tuple: Variables necesarias para reportes y comparación posterior. Incluye:\n",
    "            - info_df (pd.DataFrame): Resumen del dataset.\n",
    "            - optuna_best_params (dict): Mejores parámetros de Optuna.\n",
    "            - ray_best_params (dict): Mejores parámetros de Ray Tune.\n",
    "            - base_f1 (float): F1-score del modelo base.\n",
    "            - base_time (float): Tiempo de entrenamiento del modelo base.\n",
    "            - optuna_f1 (float): F1-score con Optuna.\n",
    "            - optuna_time (float): Tiempo de optimización con Optuna.\n",
    "            - best_trial (int): ID del mejor trial de Optuna.\n",
    "            - ray_f1 (float): F1-score con Ray Tune.\n",
    "            - ray_time (float): Tiempo de optimización con Ray Tune.\n",
    "            - optuna_results (pd.DataFrame): Resultados de Optuna.\n",
    "            - ray_results (pd.DataFrame): Resultados de Ray Tune.\n",
    "            - y_test (np.ndarray): Etiquetas reales del test.\n",
    "            - y_pred_base (np.ndarray): Predicciones del modelo base.\n",
    "            - y_pred_optuna (np.ndarray): Predicciones del modelo optimizado con Optuna.\n",
    "            - y_pred_ray (np.ndarray): Predicciones del modelo optimizado con Ray Tune.\n",
    "            - target_names (np.ndarray): Nombres de las clases objetivo.\n",
    "    \"\"\"\n",
    "    # 0. Configuración inicial\n",
    "    setup_environment()\n",
    "    \n",
    "    # 1. Carga y preprocesamiento de datos\n",
    "    train = pd.read_csv('Training.csv')\n",
    "    test = pd.read_csv('Testing.csv')\n",
    "\n",
    "    # Combinar datasets (concatenar filas)\n",
    "    data = pd.concat([train, test], ignore_index=True)\n",
    "\n",
    "    # Limpiar columna 'Unnamed: 133' si existe\n",
    "    if 'Unnamed: 133' in data.columns:\n",
    "        data = data.drop(columns=['Unnamed: 133'])\n",
    "        print(\"\\nColumna 'Unnamed: 133' eliminada.\")\n",
    "\n",
    "    # Borrar duplicados\n",
    "    data = data.drop_duplicates()\n",
    "\n",
    "    X_train, X_test, y_train, y_test, data, info_df = load_and_preprocess_data(data)\n",
    "    target_names = sorted(data['prognosis'].unique())\n",
    "    \n",
    "    # 2. Modelo base (sin tuning)\n",
    "    base_model, base_f1, base_time, y_pred_base = train_baseline_model(\n",
    "        X_train, y_train, X_test, y_test, target_names\n",
    "    )\n",
    "\n",
    "    # 3. Optimización con Ray Tune (20 trials). Se ejecuta primero para evitar problemas de memoria con Optuna.\n",
    "    ray_model, ray_f1, ray_time, ray_results, y_pred_ray, ray_best_params = optimize_with_ray_tune(\n",
    "        X_train, y_train, X_test, y_test, n_trials=20\n",
    "    )\n",
    "    \n",
    "    # 4. Optimización con Optuna (20 trials)\n",
    "    optuna_model, optuna_f1, optuna_time, optuna_results, y_pred_optuna, optuna_best_params, best_trial = optimize_with_optuna(\n",
    "        X_train, y_train, X_test, y_test, n_trials=20\n",
    "    )\n",
    "\n",
    "    # Mensajes finales antes de retornar\n",
    "    print(\"\\nDatos cargados y preprocesados correctamente.\")\n",
    "    print(f\"Modelo base entrenado sin optimización en {base_time:.2f} segundos.\")\n",
    "    print(f\"Modelo optimizado con Optuna completado en {optuna_time:.2f} segundos.\")\n",
    "    print(f\"Modelo optimizado con Ray Tune completado en {ray_time:.2f} segundos.\")\n",
    "\n",
    "    return (info_df, optuna_best_params, ray_best_params, base_f1, base_time,\n",
    "           optuna_f1, optuna_time, best_trial, ray_f1, ray_time,\n",
    "           optuna_results, ray_results, y_test,\n",
    "           y_pred_base, y_pred_optuna, y_pred_ray, target_names,\n",
    "           base_model, optuna_model, ray_model, data)        \n",
    "\n",
    "def main_2(info_df, optuna_best_params, ray_best_params, base_f1, base_time,\n",
    "           optuna_f1, optuna_time, best_trial, ray_f1, ray_time,\n",
    "           optuna_results, ray_results, y_test,\n",
    "           y_pred_base, y_pred_optuna, y_pred_ray, target_names,\n",
    "           base_model, optuna_model, ray_model, data):\n",
    "    \"\"\"\n",
    "    Segunda parte del flujo: resumen de resultados, comparación y visualización.\n",
    "\n",
    "    Esta función:\n",
    "    - Muestra resumen del dataset.\n",
    "    - Imprime mejores hiperparámetros encontrados.\n",
    "    - Reporta desempeño en F1-score y tiempo de entrenamiento.\n",
    "    - Compara gráficamente los métodos (modelo base, Optuna y Ray Tune).\n",
    "    - Guarda los resultados finales en un archivo CSV.\n",
    "\n",
    "    Args:\n",
    "        info_df (pd.DataFrame): Resumen del dataset.\n",
    "        optuna_best_params (dict): Mejores parámetros de Optuna.\n",
    "        ray_best_params (dict): Mejores parámetros de Ray Tune.\n",
    "        base_f1 (float): F1-score del modelo base.\n",
    "        base_time (float): Tiempo de entrenamiento del modelo base.\n",
    "        optuna_f1 (float): F1-score del modelo optimizado con Optuna.\n",
    "        optuna_time (float): Tiempo total de optimización con Optuna.\n",
    "        best_trial (int): Trial con mejor resultado en Optuna.\n",
    "        ray_f1 (float): F1-score del modelo optimizado con Ray Tune.\n",
    "        ray_time (float): Tiempo total de optimización con Ray Tune.\n",
    "        optuna_results (pd.DataFrame): Resultados de los trials de Optuna.\n",
    "        ray_results (pd.DataFrame): Resultados de los trials de Ray Tune.\n",
    "        y_test (np.ndarray): Etiquetas reales del conjunto de prueba.\n",
    "        y_pred_base (np.ndarray): Predicciones del modelo base.\n",
    "        y_pred_optuna (np.ndarray): Predicciones del modelo Optuna.\n",
    "        y_pred_ray (np.ndarray): Predicciones del modelo Ray Tune.\n",
    "        target_names (np.ndarray): Nombres de las clases objetivo.\n",
    "\n",
    "    Returns:\n",
    "        None. Imprime, visualiza y guarda resultados.\n",
    "    \"\"\"\n",
    "    # Mostrar info del dataset en tabla\n",
    "    print(\"Resumen del dataset:\")\n",
    "    info_df = info_df.T  # Transpone el DataFrame\n",
    "    info_df.columns = [\"Valor\"]  # Renombra la única columna resultante\n",
    "    print(info_df)\n",
    "\n",
    "    # Mostrar mejores parámetros\n",
    "    print(\"\\nMejores parámetros encontrados por Optuna:\")\n",
    "    for param, value in optuna_best_params.items():\n",
    "        print(f\"- {param}: {value}\")\n",
    "\n",
    "    print(\"\\nMejores parámetros encontrados por Ray Tune:\")\n",
    "    for param, value in ray_best_params.items():\n",
    "        print(f\"- {param}: {value}\")\n",
    "\n",
    "    # Mostrar resultados de cada modelo\n",
    "    print(\"\\nResultados del modelo base:\")\n",
    "    print(f\"- F1-score: {base_f1:.4f}\")\n",
    "    print(f\"- Tiempo de entrenamiento: {base_time:.2f} segundos\")\n",
    "    \n",
    "    print(\"\\nResultados del modelo optimizado con Optuna:\")\n",
    "    print(f\"- F1-score: {optuna_f1:.4f}\")\n",
    "    print(f\"- Tiempo total de optimización: {optuna_time:.2f} segundos\")\n",
    "    print(f\"- Mejor trial: #{best_trial}\")\n",
    "\n",
    "    print(\"\\nResultados del modelo optimizado con Ray Tune:\")\n",
    "    print(f\"- F1-score: {ray_f1:.4f}\")\n",
    "    print(f\"- Tiempo total de optimización: {ray_time:.2f} segundos\")\n",
    "\n",
    "    # Comparación de hiperparámetros\n",
    "    param_comparison = pd.DataFrame({\n",
    "        'Parámetro': list(optuna_best_params.keys()),\n",
    "        'Optuna': list(optuna_best_params.values()),\n",
    "        'Ray Tune': [ray_best_params[k] for k in optuna_best_params.keys()]\n",
    "    })\n",
    "\n",
    "    print(\"\\nComparación de Hiperparámetros:\")\n",
    "    print(param_comparison.to_string(index=False))\n",
    "\n",
    "    mejor_metodo = 'Optuna' if optuna_f1 >= ray_f1 and optuna_f1 >= base_f1 else 'Ray Tune' if ray_f1 > base_f1 else 'Modelo Base'\n",
    "    print(f\"\\nMejor modelo: {mejor_metodo} (F1-score: {max(base_f1, optuna_f1, ray_f1):.4f})\")\n",
    "\n",
    "\n",
    "    # 5. Comparación de resultados (con parámetros adicionales)\n",
    "    compare_results(\n",
    "        base_f1, base_time, \n",
    "        optuna_f1, optuna_time, \n",
    "        ray_f1, ray_time,\n",
    "        optuna_results, \n",
    "        ray_results,\n",
    "        y_test,\n",
    "        y_pred_base,\n",
    "        y_pred_optuna,\n",
    "        y_pred_ray,\n",
    "        target_names\n",
    "    )\n",
    "\n",
    "    feature_names = data.columns.drop('prognosis')  # Obtener nombres de features\n",
    "    plot_top_features(\n",
    "        models=[base_model, optuna_model, ray_model],\n",
    "        feature_names=feature_names,\n",
    "        model_names=[\"Modelo Base\", \"Optuna\", \"Ray Tune\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d691ed4",
   "metadata": {},
   "source": [
    "# 4. Visualización de resultados\n",
    "\n",
    "Para evitar problemas en las celdas de salida, la ejecución de realiza en dos pasos, en dos celdas de codigo distintas.\n",
    "\n",
    "---\n",
    "\n",
    "- **`Primer paso`**\n",
    "Almacenar en una variable todos los resultados generados por los modelos a comparar.\n",
    "\n",
    "- **`Segundo paso`**\n",
    "Usar los resultados obtenidos con main() para mostrarlos junto a las comparaciones de modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97823a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primer paso\n",
    "resultados = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c4bf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segundo paso\n",
    "main_2(*resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d52d16",
   "metadata": {},
   "source": [
    "## Análisis de Resultados y Reflexiones Finales\n",
    "\n",
    "### Justificaciones: \n",
    "El dataset utilizado presentó algunos problemas que fueron solucionados según lo siguiente:\n",
    "    - El dataset venía separado en Training.csv y Testing.cvs, pero al revisarlos, el split estaba hecho en una relacion similar a 99.15-0.85, por lo que el test era muy pequeño. De esta manera se juntaron ambos .csv mediante concat.\n",
    "    - Dentro de las columnas, había una llamada **Unnamed: 133**, la cual se eliminó del dataset debido a que no presentaba valores.\n",
    "    - El dataset presentaba datos duplicados, y al hcer el analisis exploratorio, se observó que la mayoria del dataset era duplicado, por lo que se eliminaron mediante drop_duplicates(), quedando en poco mas de 300 filas.\n",
    "\n",
    "### 1. Comparación del rendimiento del modelo optimizado vs modelo base\n",
    "\n",
    "Todos los modelos evaluados —base, optimizado con Optuna y optimizado con Ray Tune— alcanzaron un **F1-score perfecto de 1.0000**, lo que sugiere que el problema puede ser relativamente sencillo o que las clases están muy bien separadas en el espacio de características. \n",
    "\n",
    "Junto a esto es importante mencionar que desde la fuente del dataset, muchas personas han reportado que los datos siempre arrojan un F1-Score de 1, independiente del modelo que usen, aun sin optimizar, por lo que hay que tomar esto en cuenta a la hora de intentar interpretar los resultados, ya que el dataset puede haber sido creado con la finalidad de crear datos de practica para codigo mas que para evaluar modelos.\n",
    "\n",
    "Sin embargo, al comparar los **tiempos de ejecución**, se observan diferencias relevantes:\n",
    "\n",
    "| Método        | F1-score | Tiempo (s) |\n",
    "|---------------|----------|------------|\n",
    "| Modelo Base   | 1.0000   | 0.09       |\n",
    "| Optuna        | 1.0000   | 2.19       |\n",
    "| Ray Tune      | 1.0000   | 12.34      |\n",
    "\n",
    "- El **modelo base** ofrece un rendimiento perfecto en **solo 0.09 segundos**, sin necesidad de optimización.\n",
    "- **Optuna** logra el mismo rendimiento en un tiempo aceptable (2.19s) y puede ser útil para ajustar el modelo a nuevos datos.\n",
    "- **Ray Tune**, aunque potente y paralelizable, requiere más tiempo (12.34s) para obtener resultados similares.\n",
    "\n",
    "> **Conclusión**: En este caso particular, el modelo base es suficiente. Sin embargo, la optimización puede ser valiosa en problemas más complejos o con ruido.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Importancia de las variables e interpretabilidad\n",
    "\n",
    "En este caso, las variables mas importantes fueron graficadas, y dentro de eso, en el modelo base y el optimizado con Ray Tune la mas importante fue (al menos en esta ejecución) **itching** o picazón, y tiene sentido, ya que es un síntoma común en muchas enfermedades, especialmente en enfermedades de la piel, alergias, infecciones, o incluso algunas enfermedades sistémicas que pueden manifestarse con síntomas dermatológicos. Por lo tanto, puede ser un predictor fuerte para distinguir enfermedades relacionadas.\n",
    "\n",
    "Por el lado del modelo optimizado con Optuna, la mas importante fue **muscle_pain** o dolor muscular, es otro síntoma muy frecuente que aparece en muchas condiciones infecciosas, inflamatorias, virales (como gripe o dengue) o autoinmunes, y puede ayudar a diferenciar ciertas enfermedades.\n",
    "\n",
    "En problemas de clasificación multiclase con muchos atributos (en este caso, 132 variables predictoras), entender la importancia de las variables es fundamental para:\n",
    "\n",
    "- Interpretar el comportamiento del modelo.\n",
    "- Identificar los atributos más influyentes en la predicción.\n",
    "- Reducir la dimensionalidad, si fuese necesario, eliminando variables irrelevantes.\n",
    "- Guiar futuras decisiones sobre recolección de datos o ingeniería de características.\n",
    "\n",
    "La importancia de una variable nos indica cuánto contribuye esa característica a la precisión del modelo. En modelos como RandomForestClassifier, se calcula con base en la mejora del criterio de división (por ejemplo, Gini o Entropía) al usar esa variable en los árboles de decisión.\n",
    "\n",
    "Aunque los modelos basados en árboles como Random Forest no son tan interpretables como modelos lineales simples, permiten estimar:\n",
    "\n",
    "- Qué variables son más relevantes para el modelo.\n",
    "- Qué características ayudan a distinguir entre múltiples clases.\n",
    "- Cómo podrían reaccionar las predicciones si ciertos atributos cambian.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Ventajas y desventajas de Optuna vs Ray Tune\n",
    "\n",
    "| Criterio              | Optuna                        | Ray Tune                       |\n",
    "|-----------------------|-------------------------------|--------------------------------|\n",
    "| Facilidad de uso      | Muy simple e intuitivo        | Más complejo de configurar     |\n",
    "| Velocidad             | Rápido                        | Más lento (por overhead)       |\n",
    "| Paralelismo           | Limitado                      | Excelente soporte              |\n",
    "| Visualización         | Básica                        | Avanzada (si se habilita)      |\n",
    "| Integración           | Ligero, fácil de integrar     | Requiere más setup             |\n",
    "\n",
    "#### Ventajas de Optuna:\n",
    "- Sencillo de implementar, ideal para notebooks y proyectos rápidos.\n",
    "- Eficiente para problemas de baja a media complejidad.\n",
    "- Espacio de búsqueda flexible y bien documentado.\n",
    "\n",
    "#### Ventajas de Ray Tune:\n",
    "- Excelente para escalamiento en entornos distribuidos o multi-GPU.\n",
    "- Soporte avanzado para callbacks, dashboards y logging.\n",
    "- Integración con frameworks como PyTorch, XGBoost, LightGBM, entre otros.\n",
    "\n",
    "> **Recomendación**: Utilizar **Optuna** para entornos locales o tareas exploratorias, y **Ray Tune** cuando se requiera optimización a gran escala o integración con recursos distribuidos.\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusión general\n",
    "\n",
    "Aunque el rendimiento no varió entre modelos en este caso, este experimento permitió:\n",
    "\n",
    "- Validar el poder predictivo del modelo base.\n",
    "- Evaluar herramientas de optimización automatizada.\n",
    "- Comprender mejor las variables más relevantes para el diagnóstico.\n",
    "- Reflexionar sobre cuándo y por qué optimizar hiperparámetros.\n",
    "\n",
    "> En contextos más complejos, desequilibrados o con datasets ruidosos, la optimización puede marcar una diferencia significativa en el rendimiento final del modelo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
