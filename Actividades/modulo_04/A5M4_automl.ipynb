{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1df97ea",
   "metadata": {},
   "source": [
    "# Actividad 5:\n",
    "# Comparación de estrategias de tuning automático para modelos de clasificación en salud\n",
    "\n",
    "## Objetivo\n",
    "Aplicar técnicas de tuning automatizado con las librerías Optuna y Ray Tune para mejorar el rendimiento de un modelo de clasificación binaria (Random Forest) sobre un conjunto de datos médicos. El alumno deberá comparar ambas herramientas y reflexionar sobre su efectividad.\n",
    "\n",
    "**Dataset utilizado:**  \n",
    "Cáncer de mama de Scikit-learn\n",
    "\n",
    "---\n",
    "\n",
    "### Estructura del Notebook:\n",
    "1. Metodología.\n",
    "2. Configuración inicial del notebook.\n",
    "3. Definicion de funciones.\n",
    "4. Uso de funciones y resultados.\n",
    "5. Análisis de los resultados y reflexiones finales.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012bb0c2",
   "metadata": {},
   "source": [
    "## 1. Metodología\n",
    "\n",
    "---\n",
    "\n",
    "### Flujo de trabajo\n",
    "1. **Carga de datos:**\n",
    "   - Escalado de características con `StandardScaler`.\n",
    "   - División de datos en entrenamiento y prueba (70% / 30%) con estratificación de clases.\n",
    "\n",
    "2. **Modelos creados:**\n",
    "   - **Modelo base:** RandomForestClassifier con hiperparámetros por defecto.\n",
    "   - **Modelo optimizado con Optuna:** RandomForestClassifier optimizado mediante Optuna con 20 trials.\n",
    "   - **Modelo optimizado con Ray Tune:** RandomForestClassifier optimizado mediante Ray Tune con 20 trials. Uso de CallBack para mostrar logs.\n",
    "\n",
    "3. **Evaluación de modelos:**\n",
    "   - **Métricas evaluadas:**\n",
    "      - F1 Score.\n",
    "      - Tiempo de ejecución.\n",
    "\n",
    "4. **Comparación y visualización:**\n",
    "   - Resumen del dataset.\n",
    "   - Mejores hiperparametros encontrados por Optuna y Ray Tune.\n",
    "   - Resultados del modelo base, optimizado con Optuna y optimizado con Ray Tune.\n",
    "   - Gráficos de comparación de rendimiento (F1-Score) y tiempos de ejecución.\n",
    "   - Gráficos de evolución de F1-Score en los modelos optimizados con Optuna y Ray Tune.\n",
    "   - Matrices de confusión del modelo base, Optuna y Ray Tune.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5986d0fe",
   "metadata": {},
   "source": [
    "# 2. Configuración inicial del notebook\n",
    "- Importación de librerias necesarias.\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b6b715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "import os\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import optuna\n",
    "import ray\n",
    "from ray import train, tune\n",
    "from ray.tune import Tuner\n",
    "from ray.tune.search.basic_variant import BasicVariantGenerator\n",
    "from ray.tune import Callback\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e2e9ce",
   "metadata": {},
   "source": [
    "# 3. Definición de funciones\n",
    "\n",
    "> **Nota:** Para mejor comprensión de las funciones y su utilidad, esta sección se divide en bloques, en donde cada uno responde a una parte diferente de la metodología de trabajo. \n",
    "\n",
    "---\n",
    "\n",
    "**Bloque 0:** Configuración del entorno\n",
    "\n",
    "- **`setup_environment()`** \n",
    "Debido a lso multiples errores y warnings que ocurren durante la ejecución, se decidió configurar el setup para mejorar la legibilidad de las salidas de codigo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbffb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_environment():\n",
    "    \"\"\"\n",
    "    Configura variables de entorno, logging y estilo gráfico.\n",
    "\n",
    "    Incluye:\n",
    "    - Desactivación de servicios no usados por Apache Arrow.\n",
    "    - Desactivación del dashboard de Ray.\n",
    "    - Activación de captura de logs en stderr.\n",
    "    - Reducción de verbosidad en los logs.\n",
    "    - Estilo gráfico para visualizaciones (seaborn y matplotlib).\n",
    "\n",
    "    Esta función se debe llamar al inicio del flujo principal.\n",
    "    \"\"\"\n",
    "    # Configuraciones avanzadas para evitar problemas con Ray\n",
    "    os.environ['ARROW_DISABLE_S3'] = '1'\n",
    "    os.environ['ARROW_DISABLE_GCS'] = '1'\n",
    "    os.environ['ARROW_DISABLE_HDFS'] = '1'\n",
    "    os.environ['RAY_DISABLE_DASHBOARD'] = '1'\n",
    "    os.environ['RAY_ENABLE_WINDOWS_OR_OSX_CLUSTER'] = '1'\n",
    "    os.environ['RAY_LOG_TO_STDERR'] = '1'  # Ahora capturaremos estos logs\n",
    "    os.environ['RAY_DEDUP_LOGS'] = '0'  # Mostrar todos los logs\n",
    "    \n",
    "    # Reducir verbosidad de Arrow\n",
    "    os.environ['ARROW_VERBOSE_THRESHOLD'] = '0'\n",
    "    \n",
    "    # Configuración de logging\n",
    "    logging.basicConfig(level=logging.ERROR)\n",
    "    \n",
    "    # Configurar estilo para gráficos\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.rcParams['figure.figsize'] = (12, 6)\n",
    "    plt.rcParams['font.size'] = 12\n",
    "    plt.rcParams['figure.max_open_warning'] = 50  # Permitir más figuras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2ae5fe",
   "metadata": {},
   "source": [
    "**Bloque 1:** Carga y preprocesamiento de datos\n",
    "\n",
    "- **`load_and_preprocess_data()`** \n",
    "Carga el dataset de cáncer de mama, aplica escalado estándar y divide los datos en conjuntos de entrenamiento y prueba estratificados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a97925d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(data):\n",
    "    \"\"\"\n",
    "    Realiza la carga y el preprocesamiento del dataset de cáncer de mama.\n",
    "\n",
    "    Este paso incluye:\n",
    "    - División del conjunto de datos en entrenamiento y prueba (70/30, con estratificación).\n",
    "    - Escalamiento de características numéricas usando StandardScaler.\n",
    "    - Creación de un resumen informativo del dataset.\n",
    "\n",
    "    Args:\n",
    "        data (sklearn.utils.Bunch): Objeto cargado con `load_breast_cancer()` de scikit-learn.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            - X_train_scaled (np.ndarray): Datos de entrenamiento escalados.\n",
    "            - X_test_scaled (np.ndarray): Datos de prueba escalados.\n",
    "            - y_train (np.ndarray): Etiquetas de entrenamiento.\n",
    "            - y_test (np.ndarray): Etiquetas de prueba.\n",
    "            - data (Bunch): El dataset original sin modificar.\n",
    "            - info_df (pd.DataFrame): DataFrame resumen del dataset (tamaño, clases, particiones, etc.).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Cargar dataset de cáncer de mama\n",
    "    # data = load_breast_cancer()\n",
    "    X = data.data\n",
    "    y = data.target\n",
    "    \n",
    "    # Dividir datos en entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Escalar características\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Crear resumen en un DataFrame\n",
    "    info_dict = {\n",
    "        \"Total muestras\": [X.shape[0]],\n",
    "        \"N° características\": [X.shape[1]],\n",
    "        \"Clases\": [\", \".join(data.target_names)],\n",
    "        \"Distribución clases\": [f\"{np.bincount(y)[0]} (malignant), {np.bincount(y)[1]} (benign)\"],\n",
    "        \"Train size\": [X_train.shape[0]],\n",
    "        \"Test size\": [X_test.shape[0]],\n",
    "        \"Shape X_train\": [X_train_scaled.shape],\n",
    "        \"Shape X_test\": [X_test_scaled.shape]\n",
    "    }\n",
    "    info_df = pd.DataFrame(info_dict)\n",
    "\n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test, data, info_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254b2302",
   "metadata": {},
   "source": [
    "**Bloque 2:** Aplicación del modelo base, y optimizados con Optuna y Ray Tune\n",
    "\n",
    "- **`train_baseline_model()`** \n",
    "Entrena y evalúa un modelo base Random Forest con hiperparámetros por defecto.\n",
    "\n",
    "- **`optimize_with_optuna()`** \n",
    "Realiza optimización de hiperparámetros para un modelo Random Forest usando Optuna.\n",
    "\n",
    "- **`optimize_with_ray_tune()`** \n",
    "Realiza optimización de hiperparámetros para un modelo Random Forest utilizando Ray Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3495fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_baseline_model(X_train, y_train, X_test, y_test, target_names):\n",
    "    \"\"\"\n",
    "    Entrena y evalúa un modelo base Random Forest con hiperparámetros por defecto.\n",
    "\n",
    "    El modelo se ajusta sobre los datos de entrenamiento y se evalúa usando F1-score\n",
    "    sobre el conjunto de prueba.\n",
    "\n",
    "    Args:\n",
    "        X_train (np.ndarray): Conjunto de entrenamiento (features) escalado.\n",
    "        y_train (np.ndarray): Etiquetas del conjunto de entrenamiento.\n",
    "        X_test (np.ndarray): Conjunto de prueba (features) escalado.\n",
    "        y_test (np.ndarray): Etiquetas del conjunto de prueba.\n",
    "        target_names (np.ndarray): Nombres de las clases objetivo (no usado directamente aquí, \n",
    "                                   pero útil para extensiones o reportes detallados).\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            - base_model (RandomForestClassifier): Modelo entrenado.\n",
    "            - base_f1 (float): F1-score en el conjunto de prueba.\n",
    "            - base_train_time (float): Tiempo de entrenamiento (segundos).\n",
    "            - y_pred_base (np.ndarray): Predicciones del modelo base en el test set.\n",
    "    \"\"\"\n",
    "    # Entrenar modelo con parámetros por defecto\n",
    "    start_time = time.time()\n",
    "    base_model = RandomForestClassifier(random_state=42)\n",
    "    base_model.fit(X_train, y_train)\n",
    "    base_train_time = time.time() - start_time\n",
    "\n",
    "    # Evaluación del modelo\n",
    "    y_pred_base = base_model.predict(X_test)\n",
    "    base_f1 = f1_score(y_test, y_pred_base)\n",
    "\n",
    "    return base_model, base_f1, base_train_time, y_pred_base\n",
    "\n",
    "\n",
    "def optimize_with_optuna(X_train, y_train, X_test, y_test, n_trials=20):\n",
    "    \"\"\"\n",
    "    Realiza optimización de hiperparámetros para un modelo Random Forest usando Optuna.\n",
    "\n",
    "    Busca maximizar el F1-score en el conjunto de prueba, evaluando distintos \n",
    "    conjuntos de parámetros mediante validación directa. Al finalizar, se \n",
    "    entrena un modelo final con los mejores parámetros encontrados.\n",
    "\n",
    "    Args:\n",
    "        X_train (np.ndarray): Conjunto de entrenamiento (features) escalado.\n",
    "        y_train (np.ndarray): Etiquetas del conjunto de entrenamiento.\n",
    "        X_test (np.ndarray): Conjunto de prueba (features) escalado.\n",
    "        y_test (np.ndarray): Etiquetas del conjunto de prueba.\n",
    "        n_trials (int, opcional): Número de combinaciones a probar (default: 20).\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            - optuna_best_model (RandomForestClassifier): Modelo final entrenado con los mejores parámetros.\n",
    "            - optuna_f1 (float): F1-score del modelo optimizado en el test set.\n",
    "            - optuna_time (float): Tiempo total de optimización en segundos.\n",
    "            - optuna_results (pd.DataFrame): Detalles de todos los trials realizados.\n",
    "            - y_pred_optuna (np.ndarray): Predicciones del modelo optimizado.\n",
    "            - optuna_best_params (dict): Diccionario con los mejores hiperparámetros encontrados.\n",
    "            - best_trial (int): Número del mejor trial según F1-score.\n",
    "    \"\"\"\n",
    "    print(f\"\\nOptimizando modelo con Optuna ({n_trials} trials)\")\n",
    "    \n",
    "    # Función objetivo para Optuna\n",
    "    def objective(trial):\n",
    "        # Espacio de búsqueda\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 10, 200),\n",
    "            'max_depth': trial.suggest_int('max_depth', 2, 32),\n",
    "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 20)\n",
    "        }\n",
    "        \n",
    "        # Crear y entrenar modelo\n",
    "        model = RandomForestClassifier(**params, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Evaluar con F1-score\n",
    "        y_pred = model.predict(X_test)\n",
    "        return f1_score(y_test, y_pred)\n",
    "\n",
    "    # Ejecutar estudio de optimización\n",
    "    print(\"Iniciando búsqueda de hiperparámetros con Optuna...\")\n",
    "    start_time = time.time()\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "    optuna_time = time.time() - start_time\n",
    "\n",
    "    # Obtener mejores parámetros\n",
    "    optuna_best_params = study.best_params\n",
    "    optuna_best_model = RandomForestClassifier(**optuna_best_params, random_state=42)\n",
    "    optuna_best_model.fit(X_train, y_train)\n",
    "    y_pred_optuna = optuna_best_model.predict(X_test)\n",
    "    optuna_f1 = f1_score(y_test, y_pred_optuna)\n",
    "\n",
    "    # Resultados de los trials\n",
    "    optuna_results = study.trials_dataframe()\n",
    "    \n",
    "    return optuna_best_model, optuna_f1, optuna_time, optuna_results, y_pred_optuna, optuna_best_params, study.best_trial.number\n",
    "\n",
    "\n",
    "def optimize_with_ray_tune(X_train, y_train, X_test, y_test, n_trials=20):\n",
    "    \"\"\"\n",
    "    Realiza optimización de hiperparámetros para un modelo Random Forest utilizando Ray Tune.\n",
    "\n",
    "    Usa búsqueda aleatoria (BasicVariantGenerator) sobre un espacio de hiperparámetros definido.\n",
    "    Registra el F1-score de cada configuración y retorna el modelo con mejor desempeño, junto a\n",
    "    sus resultados detallados. Incluye captura y despliegue de logs personalizados durante el proceso.\n",
    "\n",
    "    Args:\n",
    "        X_train (np.ndarray): Conjunto de entrenamiento (features) escalado.\n",
    "        y_train (np.ndarray): Etiquetas del conjunto de entrenamiento.\n",
    "        X_test (np.ndarray): Conjunto de prueba (features) escalado.\n",
    "        y_test (np.ndarray): Etiquetas del conjunto de prueba.\n",
    "        n_trials (int, opcional): Número de configuraciones a evaluar (default: 20).\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            - ray_best_model (RandomForestClassifier): Modelo final entrenado con los mejores parámetros.\n",
    "            - ray_f1 (float): F1-score del modelo optimizado en el test set.\n",
    "            - ray_time (float): Tiempo total de optimización en segundos.\n",
    "            - ray_results_df (pd.DataFrame): DataFrame con el resumen de cada trial.\n",
    "            - y_pred_ray (np.ndarray): Predicciones del modelo optimizado.\n",
    "            - ray_best_params (dict): Hiperparámetros óptimos encontrados.\n",
    "    \"\"\"\n",
    "  \n",
    "    # Callback para mostrar progreso\n",
    "    class ProgressCallback(Callback):\n",
    "        def __init__(self, total_trials):\n",
    "            self.total_trials = total_trials\n",
    "            self.completed_trials = 0\n",
    "            self.header_printed = False\n",
    "\n",
    "        def on_trial_complete(self, iteration, trials, trial):\n",
    "            if not self.header_printed:\n",
    "                print(\"=\"*50)\n",
    "                print(f\"Optimizando modelo con Ray Tune ({self.total_trials} trials)\")\n",
    "                print(\"=\"*50)\n",
    "                self.header_printed = True\n",
    "\n",
    "            self.completed_trials += 1\n",
    "            f1 = trial.last_result['f1_score']\n",
    "            params = trial.config\n",
    "            timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            print(f\"[I {timestamp}] Trial {self.completed_trials} finished with value: {f1:.4f} and parameters: {params}.\", flush=True)\n",
    "\n",
    "    # Configurar Ray\n",
    "    ray.init(\n",
    "        ignore_reinit_error=True,\n",
    "        include_dashboard=False,\n",
    "        logging_level=logging.CRITICAL,\n",
    "        log_to_driver=False\n",
    "    )\n",
    "\n",
    "    # Función entrenable para Ray Tune\n",
    "    def trainable(config):\n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=config[\"n_estimators\"],\n",
    "            max_depth=config[\"max_depth\"],\n",
    "            min_samples_split=config[\"min_samples_split\"],\n",
    "            random_state=42\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        train.report({\"f1_score\": f1})\n",
    "\n",
    "    # Espacio de búsqueda\n",
    "    param_space = {\n",
    "        \"n_estimators\": tune.randint(10, 200),\n",
    "        \"max_depth\": tune.randint(2, 32),\n",
    "        \"min_samples_split\": tune.randint(2, 20)\n",
    "    }\n",
    "\n",
    "    # Configurar el sintonizador\n",
    "    tuner = Tuner(\n",
    "        trainable,\n",
    "        param_space=param_space,\n",
    "        tune_config=tune.TuneConfig(\n",
    "            metric=\"f1_score\",\n",
    "            mode=\"max\",\n",
    "            num_samples=n_trials,\n",
    "            search_alg=BasicVariantGenerator(),\n",
    "            max_concurrent_trials=4\n",
    "        ),\n",
    "        run_config=train.RunConfig(\n",
    "            verbose=0,\n",
    "            callbacks=[ProgressCallback(n_trials)]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Ejecutar optimización\n",
    "    print(\"Iniciando búsqueda de hiperparámetros con Ray Tune...\")\n",
    "    start_time = time.time()\n",
    "    results = tuner.fit()\n",
    "    ray_time = time.time() - start_time\n",
    "\n",
    "    # Obtener resultados\n",
    "    best_result = results.get_best_result(metric=\"f1_score\", mode=\"max\")\n",
    "    ray_best_params = best_result.config\n",
    "    ray_f1 = best_result.metrics[\"f1_score\"]\n",
    "\n",
    "    # Convertir resultados a DataFrame\n",
    "    ray_results = []\n",
    "    for i, result in enumerate(results):\n",
    "        ray_results.append({\n",
    "            \"trial\": i + 1,\n",
    "            \"params\": result.config,\n",
    "            \"f1_score\": result.metrics[\"f1_score\"]\n",
    "        })\n",
    "    ray_results_df = pd.DataFrame(ray_results)\n",
    "\n",
    "    # Cerrar Ray\n",
    "    ray.shutdown()\n",
    "\n",
    "    # Entrenar modelo final con los mejores parámetros\n",
    "    ray_best_model = RandomForestClassifier(\n",
    "        n_estimators=ray_best_params[\"n_estimators\"],\n",
    "        max_depth=ray_best_params[\"max_depth\"],\n",
    "        min_samples_split=ray_best_params[\"min_samples_split\"],\n",
    "        random_state=42\n",
    "    )\n",
    "    ray_best_model.fit(X_train, y_train)\n",
    "    y_pred_ray = ray_best_model.predict(X_test)\n",
    "\n",
    "    return ray_best_model, ray_f1, ray_time, ray_results_df, y_pred_ray, ray_best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebccba54",
   "metadata": {},
   "source": [
    "**Bloque 3:** Creacion de tablas y gráficos para comparación de modelos.\n",
    "\n",
    "- **`compare_results()`** \n",
    "Compara los resultados de tres modelos (base, Optuna y Ray Tune) y genera visualizaciones, incluyendo tablas comparativas, gráficos de rendimiento, evolución de F1-Score y matrices de confusión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2262603e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_results(base_f1, base_time, optuna_f1, optuna_time, ray_f1, ray_time,\n",
    "                   optuna_results, ray_results_df, y_test,\n",
    "                   y_pred_base, y_pred_optuna, y_pred_ray, target_names):\n",
    "    \"\"\"\n",
    "    Compara los resultados de tres modelos (base, Optuna y Ray Tune) y genera visualizaciones.\n",
    "\n",
    "    Incluye:\n",
    "    - Tabla comparativa de F1-score, tiempo de entrenamiento y número de trials.\n",
    "    - Gráfico de barras con F1-score y tiempos.\n",
    "    - Evolución del F1-score en los trials de Optuna y Ray Tune.\n",
    "    - Matrices de confusión para cada modelo.\n",
    "\n",
    "    Args:\n",
    "        base_f1 (float): F1-score del modelo base.\n",
    "        base_time (float): Tiempo de entrenamiento del modelo base.\n",
    "        optuna_f1 (float): F1-score del modelo optimizado con Optuna.\n",
    "        optuna_time (float): Tiempo total de optimización con Optuna.\n",
    "        ray_f1 (float): F1-score del modelo optimizado con Ray Tune.\n",
    "        ray_time (float): Tiempo total de optimización con Ray Tune.\n",
    "        optuna_results (pd.DataFrame): Resultados de los trials de Optuna.\n",
    "        ray_results_df (pd.DataFrame): Resultados de los trials de Ray Tune.\n",
    "        y_test (np.ndarray): Etiquetas verdaderas del conjunto de prueba.\n",
    "        y_pred_base (np.ndarray): Predicciones del modelo base.\n",
    "        y_pred_optuna (np.ndarray): Predicciones del modelo optimizado con Optuna.\n",
    "        y_pred_ray (np.ndarray): Predicciones del modelo optimizado con Ray Tune.\n",
    "        target_names (list): Nombres de las clases objetivo.\n",
    "\n",
    "    Returns:\n",
    "        None. Solo imprime y visualiza resultados.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"5. COMPARACIÓN DE RESULTADOS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Crear tabla comparativa\n",
    "    comparison_data = {\n",
    "        'Método': ['Modelo Base', 'Optuna', 'Ray Tune'],\n",
    "        'F1-score': [base_f1, optuna_f1, ray_f1],\n",
    "        'Tiempo (s)': [base_time, optuna_time, ray_time],\n",
    "        'Número de Trials': ['-', len(optuna_results), len(ray_results_df)]\n",
    "    }\n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "    # Mostrar tabla comparativa\n",
    "    print(\"\\nTabla Comparativa:\")\n",
    "    print(\"-\"*60)\n",
    "    print(comparison_df.to_string(index=False))\n",
    "    print(\"-\"*60)\n",
    "\n",
    "\n",
    "    # Gráficos\n",
    "    \n",
    "    # Figura 1: Comparación de métricas\n",
    "    fig1, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Gráfico 1: Comparación de F1-scores\n",
    "    sns.barplot(x='Método', y='F1-score', data=comparison_df, ax=axes[0], \n",
    "                hue='Método', palette=\"viridis\", legend=False, dodge=False)\n",
    "    axes[0].set_title('Comparación de Rendimiento (F1-score)')\n",
    "    axes[0].set_ylim(0.9, 1.0)\n",
    "    for i, v in enumerate(comparison_df['F1-score']):\n",
    "        axes[0].text(i, v + 0.005, f\"{v:.4f}\", ha='center', fontsize=12)\n",
    "\n",
    "    # Gráfico 2: Comparación de tiempos de ejecución\n",
    "    sns.barplot(x='Método', y='Tiempo (s)', data=comparison_df, ax=axes[1], \n",
    "                hue='Método', palette=\"rocket\", legend=False, dodge=False)\n",
    "    axes[1].set_title('Comparación de Tiempo de Ejecución')\n",
    "    for i, v in enumerate(comparison_df['Tiempo (s)']):\n",
    "        axes[1].text(i, v + 0.1, f\"{v:.2f}s\", ha='center', fontsize=12)\n",
    "\n",
    "\n",
    "    # Figura 2: Evolución de optimizaciones\n",
    "    fig2, (ax2, ax3) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Optuna\n",
    "    ax2.plot(optuna_results['number'], optuna_results['value'], 'o-', color='teal')\n",
    "    ax2.set_title('Evolución de F1-score en Optuna')\n",
    "    ax2.set_xlabel('Trial')\n",
    "    ax2.set_ylabel('F1-score')\n",
    "    ax2.grid(True)\n",
    "    best_trial_optuna = optuna_results.loc[optuna_results['value'].idxmax(), 'number']\n",
    "    ax2.axvline(x=best_trial_optuna, color='r', linestyle='--', alpha=0.7, \n",
    "               label=f'Mejor trial: {best_trial_optuna}')\n",
    "    ax2.legend()\n",
    "    \n",
    "    # Ray Tune\n",
    "    ax3.plot(ray_results_df['trial'], ray_results_df['f1_score'], 'o-', color='purple')\n",
    "    ax3.set_title('Evolución de F1-score en Ray Tune')\n",
    "    ax3.set_xlabel('Trial')\n",
    "    ax3.set_ylabel('F1-score')\n",
    "    ax3.grid(True)\n",
    "    best_trial_ray = ray_results_df.loc[ray_results_df['f1_score'].idxmax(), 'trial']\n",
    "    ax3.axvline(x=best_trial_ray, color='r', linestyle='--', alpha=0.7,\n",
    "               label=f'Mejor trial: {best_trial_ray}')\n",
    "    ax3.legend()\n",
    "\n",
    "\n",
    "    # Figura 3: Matrices de confusión\n",
    "    fig3, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    fig3.suptitle('Matrices de Confusión Comparativas', fontsize=16)\n",
    "    \n",
    "    # Modelo Base\n",
    "    cm_base = confusion_matrix(y_test, y_pred_base)\n",
    "    sns.heatmap(cm_base, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
    "                xticklabels=target_names, \n",
    "                yticklabels=target_names)\n",
    "    axes[0].set_title('Modelo Base')\n",
    "    axes[0].set_ylabel('Real')\n",
    "    axes[0].set_xlabel('Predicho')\n",
    "    \n",
    "    # Optuna\n",
    "    cm_optuna = confusion_matrix(y_test, y_pred_optuna)\n",
    "    sns.heatmap(cm_optuna, annot=True, fmt='d', cmap='Greens', ax=axes[1],\n",
    "                xticklabels=target_names, \n",
    "                yticklabels=target_names)\n",
    "    axes[1].set_title('Optuna Optimizado')\n",
    "    axes[1].set_xlabel('Predicho')\n",
    "    axes[1].set_ylabel('')\n",
    "    \n",
    "    # Ray Tune\n",
    "    cm_ray = confusion_matrix(y_test, y_pred_ray)\n",
    "    sns.heatmap(cm_ray, annot=True, fmt='d', cmap='Purples', ax=axes[2],\n",
    "                xticklabels=target_names, \n",
    "                yticklabels=target_names)\n",
    "    axes[2].set_title('Ray Tune Optimizado')\n",
    "    axes[2].set_xlabel('Predicho')\n",
    "    axes[2].set_ylabel('')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.85)\n",
    "\n",
    "    # Guardar las figuras\n",
    "    fig1.savefig(\"comparacion_metricas.png\", dpi=300, bbox_inches='tight')\n",
    "    fig2.savefig(\"evolucion_optimizadores.png\", dpi=300, bbox_inches='tight')\n",
    "    fig3.savefig(\"matrices_confusion.png\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290053e0",
   "metadata": {},
   "source": [
    "**Bloque 4:** Funciones de ejecución.\n",
    "\n",
    "Debido a que Ray Tune produce errores como borrar las celdas de salida previas a us ejecución, la función main fue segmentada en dos partes:\n",
    "\n",
    "- **`main()`**\n",
    "Función que ejecuta el flujo: carga de datos, entrenamiento, creación de modelo base y optimizados con Optuna y Ray Tune.\n",
    "\n",
    "- **`main_2()`**\n",
    "Función que toma los resultados obtenidos por main() y muestra los resultados obtenidos a partir de la comparación de los tres modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60330134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Ejecuta el flujo completo de entrenamiento y optimización del modelo.\n",
    "\n",
    "    Incluye:\n",
    "    - Configuración del entorno y estilos.\n",
    "    - Carga y preprocesamiento del dataset de cáncer de mama.\n",
    "    - Entrenamiento de un modelo base sin tuning.\n",
    "    - Optimización de hiperparámetros con Optuna y Ray Tune.\n",
    "    - Evaluación de desempeño (F1-score y tiempo).\n",
    "\n",
    "    Returns:\n",
    "        tuple: Variables necesarias para reportes y comparación posterior. Incluye:\n",
    "            - info_df (pd.DataFrame): Resumen del dataset.\n",
    "            - optuna_best_params (dict): Mejores parámetros de Optuna.\n",
    "            - ray_best_params (dict): Mejores parámetros de Ray Tune.\n",
    "            - base_f1 (float): F1-score del modelo base.\n",
    "            - base_time (float): Tiempo de entrenamiento del modelo base.\n",
    "            - optuna_f1 (float): F1-score con Optuna.\n",
    "            - optuna_time (float): Tiempo de optimización con Optuna.\n",
    "            - best_trial (int): ID del mejor trial de Optuna.\n",
    "            - ray_f1 (float): F1-score con Ray Tune.\n",
    "            - ray_time (float): Tiempo de optimización con Ray Tune.\n",
    "            - optuna_results (pd.DataFrame): Resultados de Optuna.\n",
    "            - ray_results (pd.DataFrame): Resultados de Ray Tune.\n",
    "            - y_test (np.ndarray): Etiquetas reales del test.\n",
    "            - y_pred_base (np.ndarray): Predicciones del modelo base.\n",
    "            - y_pred_optuna (np.ndarray): Predicciones del modelo optimizado con Optuna.\n",
    "            - y_pred_ray (np.ndarray): Predicciones del modelo optimizado con Ray Tune.\n",
    "            - target_names (np.ndarray): Nombres de las clases objetivo.\n",
    "    \"\"\"\n",
    "    # 0. Configuración inicial\n",
    "    setup_environment()\n",
    "    \n",
    "    # 1. Carga y preprocesamiento de datos\n",
    "    data = load_breast_cancer()\n",
    "    X_train, X_test, y_train, y_test, data, info_df = load_and_preprocess_data(data)\n",
    "    target_names = data.target_names\n",
    "    \n",
    "    # 2. Modelo base (sin tuning)\n",
    "    base_model, base_f1, base_time, y_pred_base = train_baseline_model(\n",
    "        X_train, y_train, X_test, y_test, target_names\n",
    "    )\n",
    "\n",
    "    # 3. Optimización con Ray Tune (20 trials). Se ejecuta primero para evitar problemas de memoria con Optuna.\n",
    "    ray_model, ray_f1, ray_time, ray_results, y_pred_ray, ray_best_params = optimize_with_ray_tune(\n",
    "        X_train, y_train, X_test, y_test, n_trials=20\n",
    "    )\n",
    "    \n",
    "    # 4. Optimización con Optuna (20 trials)\n",
    "    optuna_model, optuna_f1, optuna_time, optuna_results, y_pred_optuna, optuna_best_params, best_trial = optimize_with_optuna(\n",
    "        X_train, y_train, X_test, y_test, n_trials=20\n",
    "    )\n",
    "\n",
    "    # Mensajes finales antes de retornar\n",
    "    print(\"\\nDatos cargados y preprocesados correctamente.\")\n",
    "    print(f\"Modelo base entrenado sin optimización en {base_time:.2f} segundos.\")\n",
    "    print(f\"Modelo optimizado con Optuna completado en {optuna_time:.2f} segundos.\")\n",
    "    print(f\"Modelo optimizado con Ray Tune completado en {ray_time:.2f} segundos.\")\n",
    "\n",
    "    return (info_df, optuna_best_params, ray_best_params, base_f1, base_time,\n",
    "           optuna_f1, optuna_time, best_trial, ray_f1, ray_time,\n",
    "           optuna_results, ray_results, y_test,\n",
    "           y_pred_base, y_pred_optuna, y_pred_ray, target_names)\n",
    "        \n",
    "    \n",
    "def main_2(info_df, optuna_best_params, ray_best_params, base_f1, base_time,\n",
    "           optuna_f1, optuna_time, best_trial, ray_f1, ray_time,\n",
    "           optuna_results, ray_results, y_test,\n",
    "           y_pred_base, y_pred_optuna, y_pred_ray, target_names):\n",
    "    \"\"\"\n",
    "    Segunda parte del flujo: resumen de resultados, comparación y visualización.\n",
    "\n",
    "    Esta función:\n",
    "    - Muestra resumen del dataset.\n",
    "    - Imprime mejores hiperparámetros encontrados.\n",
    "    - Reporta desempeño en F1-score y tiempo de entrenamiento.\n",
    "    - Compara gráficamente los métodos (modelo base, Optuna y Ray Tune).\n",
    "    - Guarda los resultados finales en un archivo CSV.\n",
    "\n",
    "    Args:\n",
    "        info_df (pd.DataFrame): Resumen del dataset.\n",
    "        optuna_best_params (dict): Mejores parámetros de Optuna.\n",
    "        ray_best_params (dict): Mejores parámetros de Ray Tune.\n",
    "        base_f1 (float): F1-score del modelo base.\n",
    "        base_time (float): Tiempo de entrenamiento del modelo base.\n",
    "        optuna_f1 (float): F1-score del modelo optimizado con Optuna.\n",
    "        optuna_time (float): Tiempo total de optimización con Optuna.\n",
    "        best_trial (int): Trial con mejor resultado en Optuna.\n",
    "        ray_f1 (float): F1-score del modelo optimizado con Ray Tune.\n",
    "        ray_time (float): Tiempo total de optimización con Ray Tune.\n",
    "        optuna_results (pd.DataFrame): Resultados de los trials de Optuna.\n",
    "        ray_results (pd.DataFrame): Resultados de los trials de Ray Tune.\n",
    "        y_test (np.ndarray): Etiquetas reales del conjunto de prueba.\n",
    "        y_pred_base (np.ndarray): Predicciones del modelo base.\n",
    "        y_pred_optuna (np.ndarray): Predicciones del modelo Optuna.\n",
    "        y_pred_ray (np.ndarray): Predicciones del modelo Ray Tune.\n",
    "        target_names (np.ndarray): Nombres de las clases objetivo.\n",
    "\n",
    "    Returns:\n",
    "        None. Imprime, visualiza y guarda resultados.\n",
    "    \"\"\"\n",
    "    # Mostrar info del dataset en tabla\n",
    "    print(\"Resumen del dataset:\")\n",
    "    info_df = info_df.T  # Transpone el DataFrame\n",
    "    info_df.columns = [\"Valor\"]  # Renombra la única columna resultante\n",
    "    print(info_df)\n",
    "\n",
    "    # Mostrar mejores parámetros\n",
    "    print(\"\\nMejores parámetros encontrados por Optuna:\")\n",
    "    for param, value in optuna_best_params.items():\n",
    "        print(f\"- {param}: {value}\")\n",
    "\n",
    "    print(\"\\nMejores parámetros encontrados por Ray Tune:\")\n",
    "    for param, value in ray_best_params.items():\n",
    "        print(f\"- {param}: {value}\")\n",
    "\n",
    "    # Mostrar resultados de cada modelo\n",
    "    print(\"\\nResultados del modelo base:\")\n",
    "    print(f\"- F1-score: {base_f1:.4f}\")\n",
    "    print(f\"- Tiempo de entrenamiento: {base_time:.2f} segundos\")\n",
    "    \n",
    "    print(\"\\nResultados del modelo optimizado con Optuna:\")\n",
    "    print(f\"- F1-score: {optuna_f1:.4f}\")\n",
    "    print(f\"- Tiempo total de optimización: {optuna_time:.2f} segundos\")\n",
    "    print(f\"- Mejor trial: #{best_trial}\")\n",
    "\n",
    "    print(\"\\nResultados del modelo optimizado con Ray Tune:\")\n",
    "    print(f\"- F1-score: {ray_f1:.4f}\")\n",
    "    print(f\"- Tiempo total de optimización: {ray_time:.2f} segundos\")\n",
    "\n",
    "    # Comparación de hiperparámetros\n",
    "    param_comparison = pd.DataFrame({\n",
    "        'Parámetro': list(optuna_best_params.keys()),\n",
    "        'Optuna': list(optuna_best_params.values()),\n",
    "        'Ray Tune': [ray_best_params[k] for k in optuna_best_params.keys()]\n",
    "    })\n",
    "\n",
    "    print(\"\\nComparación de Hiperparámetros:\")\n",
    "    print(param_comparison.to_string(index=False))\n",
    "\n",
    "    mejor_metodo = 'Optuna' if optuna_f1 >= ray_f1 and optuna_f1 >= base_f1 else 'Ray Tune' if ray_f1 > base_f1 else 'Modelo Base'\n",
    "    print(f\"\\nMejor modelo: {mejor_metodo} (F1-score: {max(base_f1, optuna_f1, ray_f1):.4f})\")\n",
    "\n",
    "\n",
    "    # 5. Comparación de resultados (con parámetros adicionales)\n",
    "    compare_results(\n",
    "        base_f1, base_time, \n",
    "        optuna_f1, optuna_time, \n",
    "        ray_f1, ray_time,\n",
    "        optuna_results, \n",
    "        ray_results,\n",
    "        y_test,\n",
    "        y_pred_base,\n",
    "        y_pred_optuna,\n",
    "        y_pred_ray,\n",
    "        target_names\n",
    "    )\n",
    "    \n",
    "    # # Guardar resultados finales\n",
    "    # final_results = pd.DataFrame({\n",
    "    #     'Método': ['Modelo Base', 'Optuna', 'Ray Tune'],\n",
    "    #     'F1-score': [base_f1, optuna_f1, ray_f1],\n",
    "    #     'Tiempo (s)': [base_time, optuna_time, ray_time],\n",
    "    #     'Trials': [0, 20, 20]\n",
    "    # })\n",
    "    # final_results.to_csv('resultados_finales.csv', index=False)\n",
    "    # print(\"Resultados guardados en 'resultados_finales.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d691ed4",
   "metadata": {},
   "source": [
    "# 4. Visualización de resultados\n",
    "\n",
    "Para evitar problemas en las celdas de salida, la ejecución de realiza en dos pasos, en dos celdas de codigo distintas.\n",
    "\n",
    "---\n",
    "\n",
    "- **`Primer paso`**\n",
    "Almacenar en una variable todos los resultados generados por los modelos a comparar.\n",
    "\n",
    "- **`Segundo paso`**\n",
    "Usar los resultados obtenidos con main() para mostrarlos junto a las comparaciones de modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97823a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primer paso\n",
    "resultados = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c4bf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segundo paso\n",
    "main_2(*resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d52d16",
   "metadata": {},
   "source": [
    "# 5. Análisis de reultados y reflexiones Finales\n",
    "\n",
    "- La comparación entre un modelo Random Forest base y sus versiones optimizadas mediante Optuna y Ray Tune permitió evaluar el impacto del tuning de hiperparámetros en el rendimiento predictivo sobre el dataset de cáncer de mama.\n",
    "\n",
    "- Principales conclusiones:\n",
    "\n",
    "- El modelo base, sin optimización, ya presenta un buen desempeño con un F1-score de 0.9488, confirmando que Random Forest es robusto aún con parámetros por defecto.\n",
    "\n",
    "    - La optimización con Optuna logró el mejor F1-score (0.9585) con un tiempo de cómputo razonable (3.11 segundos), mostrando una excelente relación costo-beneficio.\n",
    "\n",
    "    - Ray Tune también mejoró el rendimiento frente al modelo base (0.9537), aunque con un tiempo de ejecución significativamente mayor (40 segundos), lo que podría no ser justificable en tareas donde los recursos o el tiempo son limitados.\n",
    "\n",
    "    - Ambos métodos coincidieron en que min_samples_split = 3 era óptimo, aunque difirieron en la profundidad y número de árboles, lo que muestra cómo distintas estrategias pueden converger parcialmente.\n",
    "\n",
    "### Reflexión:\n",
    "- La optimización de hiperparámetros puede entregar mejoras importantes en modelos ya sólidos como Random Forest. Sin embargo, el tiempo de optimización y la eficiencia computacional deben considerarse al elegir la herramienta adecuada. En este caso, Optuna se presenta como la mejor opción, combinando precisión, velocidad y simplicidad."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
