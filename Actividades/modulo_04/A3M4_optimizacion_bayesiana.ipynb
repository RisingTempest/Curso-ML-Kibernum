{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bab4382",
   "metadata": {},
   "source": [
    "# Actividad 3:\n",
    "# Optimización Inteligente de Modelos Predictivos en Salud usando Técnicas Bayesianas\n",
    "\n",
    "## Objetivo\n",
    "Aplicar la Optimización Bayesiana para ajustar los hiperparámetros de un modelo de clasificación binaria (Random Forest) sobre un problema de salud pública, comparando dos enfoques populares: Scikit-Optimize (skopt) y Hyperopt, evaluando el rendimiento del modelo y la eficiencia de cada técnica.\n",
    "\n",
    "**Dataset utilizado:**  \n",
    "Cáncer de mama de Scikit-learn\n",
    "\n",
    "---\n",
    "\n",
    "### Estructura del Notebook:\n",
    "1. Metodología.\n",
    "2. Configuración inicial del notebook.\n",
    "3. Definicion de funciones.\n",
    "4. Uso de funciones y resultados.\n",
    "5. Análisis de los resultados y reflexiones finales.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71469ecd",
   "metadata": {},
   "source": [
    "## 1. Metodología\n",
    "\n",
    "---\n",
    "\n",
    "### Flujo de trabajo\n",
    "1. **Carga, preprocesado de datos y creación del modelo base:**\n",
    "   - Carga datos, los preprocesa (escalado) y crea el modelo base.\n",
    "\n",
    "2. **Aplicación de técnicas de optimización bayesiana:**\n",
    "   - Optimización bayesiana usando BayesSearchCV (Scikit-Optimize).\n",
    "   - Optimización bayesiana usando Hyperopt con validación cruzada.\n",
    "\n",
    "3. **Evaluación comparativa:**\n",
    "   - Métricas del modelo base, optimizado con BayesSearchCV e Hyperopt por separado y su comparación (F1-Score, tiempos).\n",
    "   - Comparación de métricas de ambos métodos de optimización con distinto número de iteraciones y espacios de busqueda (F1-Score, tiempos).\n",
    "   - Visualización de las comparaciones.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f68e22",
   "metadata": {},
   "source": [
    "# 2. Configuración inicial del notebook\n",
    "- Importación de librerias necesarias.\n",
    "- Configuraciones necesarias para el correcto manejo de las salidas del código.\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311bc1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Integer\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "\n",
    "# Configuración de pandas para mostrar todos los parámetros\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adf97cb",
   "metadata": {},
   "source": [
    "# 3. Definición de funciones\n",
    "\n",
    "> **Nota:** Para mejor comprensión de las funciones y su utilidad, esta sección se divide en bloques, en donde cada uno responde a una parte diferente de la metodología de trabajo. \n",
    "\n",
    "---\n",
    "\n",
    "**Bloque 1:** Funciones de preprocesamiento de datos.\n",
    "\n",
    "- **`load_data()`** \n",
    "Carga el dataset de cáncer de mama, aplica escalado estándar y lo divide en conjuntos de entrenamiento y prueba.\n",
    "\n",
    "- **`train_base_rf()`** \n",
    "Entrena un modelo RandomForestClassifier sin ajuste de hiperparámetros y devuelve métricas de evaluación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0116972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_data(data, test_size=0.3, random_state=42):\n",
    "    \"\"\"\n",
    "    Carga y prepara el dataset de cáncer de mama.\n",
    "    \n",
    "    Realiza:\n",
    "    - Carga del dataset\n",
    "    - Escalado de características con StandardScaler\n",
    "    - División estratificada train/test (70/30)\n",
    "    \n",
    "    Parámetros:\n",
    "    test_size (float): Proporción para test (default 0.3)\n",
    "    random_state (int): Semilla para reproducibilidad (default 42)\n",
    "    \n",
    "    Retorna:\n",
    "    tuple: (X_train, X_test, y_train, y_test) arrays preprocesados\n",
    "    \"\"\"\n",
    "    #data = load_breast_cancer()\n",
    "    X = data.data\n",
    "    y = data.target\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def train_base_rf(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Entrena y evalúa un RandomForest sin ajuste de hiperparámetros.\n",
    "    \n",
    "    Parámetros:\n",
    "    X_train, y_train: Datos de entrenamiento\n",
    "    X_test, y_test: Datos de prueba\n",
    "    \n",
    "    Retorna:\n",
    "    tuple: (reporte_clasificación, f1_score, tiempo_entrenamiento)\n",
    "    \"\"\"\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    start_time = time.time()\n",
    "    rf.fit(X_train, y_train)\n",
    "    train_time = time.time() - start_time\n",
    "    y_pred = rf.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    return report, f1, train_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def68591",
   "metadata": {},
   "source": [
    "**Bloque 2:** Funciones de optimización bayesiana.\n",
    "\n",
    "- **`bayes_opt_skopt()`** \n",
    "Realiza optimización bayesiana de hiperparámetros usando BayesSearchCV y retorna el mejor modelo y sus métricas.\n",
    "\n",
    "- **`bayes_opt_hyperopt()`** \n",
    "Ejecuta optimización bayesiana usando Hyperopt y fmin con validación cruzada, entrenando luego el mejor modelo encontrado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c5b771",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayes_opt_skopt(X_train, y_train, X_test, y_test, n_iter=30):\n",
    "    \"\"\"\n",
    "    Optimización bayesiana usando BayesSearchCV (Scikit-Optimize).\n",
    "    \n",
    "    Define espacio de búsqueda para:\n",
    "    - n_estimators: [50, 500]\n",
    "    - max_depth: [2, 30]\n",
    "    - min_samples_split: [2, 30]\n",
    "    \n",
    "    Parámetros:\n",
    "    X_train, y_train: Datos de entrenamiento\n",
    "    X_test, y_test: Datos de prueba\n",
    "    n_iter (int): Número de iteraciones de optimización\n",
    "    \n",
    "    Retorna:\n",
    "    tuple: (mejores_parámetros, reporte_clasificación, f1_score, tiempo_total)\n",
    "    \"\"\"\n",
    "    search_space = {\n",
    "        'n_estimators': Integer(50, 500),\n",
    "        'max_depth': Integer(2, 30),\n",
    "        'min_samples_split': Integer(2, 30)\n",
    "    }\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    opt = BayesSearchCV(\n",
    "        rf,\n",
    "        search_spaces=search_space,\n",
    "        n_iter=n_iter,\n",
    "        cv=3,\n",
    "        scoring='f1',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    start = time.time()\n",
    "    opt.fit(X_train, y_train)\n",
    "    elapsed = time.time() - start\n",
    "    best_params = opt.best_params_\n",
    "    y_pred = opt.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    return best_params, report, f1, elapsed\n",
    "\n",
    "def bayes_opt_hyperopt(X_train, y_train, X_test, y_test, max_evals=30):\n",
    "    \"\"\"\n",
    "    Optimización bayesiana usando Hyperopt con validación cruzada.\n",
    "    \n",
    "    Define espacio de búsqueda con distribuciones uniformes discretas para:\n",
    "    - n_estimators: [50, 500]\n",
    "    - max_depth: [2, 30]\n",
    "    - min_samples_split: [2, 30]\n",
    "    \n",
    "    Parámetros:\n",
    "    X_train, y_train: Datos de entrenamiento\n",
    "    X_test, y_test: Datos de prueba\n",
    "    max_evals (int): Número máximo de evaluaciones\n",
    "    \n",
    "    Retorna:\n",
    "    tuple: (mejores_parámetros, reporte_clasificación, f1_score, tiempo_total)\n",
    "    \"\"\"\n",
    "    space = {\n",
    "        'n_estimators': hp.quniform('n_estimators', 50, 500, 1),\n",
    "        'max_depth': hp.quniform('max_depth', 2, 30, 1),\n",
    "        'min_samples_split': hp.quniform('min_samples_split', 2, 30, 1)\n",
    "    }\n",
    "    \n",
    "    def objective(params):\n",
    "        params_int = {\n",
    "            'n_estimators': int(params['n_estimators']),\n",
    "            'max_depth': int(params['max_depth']),\n",
    "            'min_samples_split': int(params['min_samples_split']),\n",
    "            'random_state': 42,\n",
    "            'n_jobs': -1\n",
    "        }\n",
    "        clf = RandomForestClassifier(**params_int)\n",
    "        \n",
    "        # Usar validación cruzada para evitar sobreajuste\n",
    "        score = cross_val_score(clf, X_train, y_train, cv=3, scoring='f1').mean()\n",
    "        return {'loss': -score, 'status': STATUS_OK}\n",
    "    \n",
    "    trials = Trials()\n",
    "    start = time.time()\n",
    "    best = fmin(\n",
    "        fn=objective,\n",
    "        space=space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=max_evals,\n",
    "        trials=trials,\n",
    "        rstate=np.random.default_rng(42)\n",
    "    )\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    best_params = {\n",
    "        'n_estimators': int(best['n_estimators']),\n",
    "        'max_depth': int(best['max_depth']),\n",
    "        'min_samples_split': int(best['min_samples_split']),\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "    \n",
    "    # Entrenar modelo final con todos los datos de entrenamiento\n",
    "    final_model = RandomForestClassifier(**best_params)\n",
    "    final_model.fit(X_train, y_train)\n",
    "    y_pred = final_model.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    return best_params, report, f1, elapsed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1244a4",
   "metadata": {},
   "source": [
    "**Bloque 5:** Funciones de visualización.\n",
    "\n",
    "- **`plot_comparison()`** \n",
    "Genera un gráfico comparativo de F1-Score y tiempos de ejecución entre el modelo base, BayesSearchCV y Hyperopt.\n",
    "\n",
    "- **`plot_experiment_results()`** \n",
    "Crea cuatro gráficos que muestran el impacto de las iteraciones y los rangos en el F1-Score y el tiempo de entrenamiento.\n",
    "\n",
    "- **`create_main_results_table()`** \n",
    "Construye DataFrames con los resultados clave (f1-score, tiempo y reporte) para el modelo base y los optimizados.\n",
    "\n",
    "- **`create_experiment_tables()`** \n",
    "Genera tablas con los resultados de los experimentos de iteraciones y rangos, diferenciando entre métodos.\n",
    "\n",
    "- **`display_formatted_tables()`** \n",
    "Muestra de forma organizada y con formato legible los resultados principales y experimentales en la consola."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9512b19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparison(base_f1, skopt_f1, hyperopt_f1, base_time, skopt_time, hyperopt_time):\n",
    "    \"\"\"\n",
    "    Genera gráficos comparativos de F1-Score y tiempos de ejecución.\n",
    "    \n",
    "    Parámetros:\n",
    "    base_f1: F1-Score modelo base\n",
    "    skopt_f1: F1-Score BayesSearchCV\n",
    "    hyperopt_f1: F1-Score Hyperopt\n",
    "    base_time: Tiempo de entrenamiento modelo base\n",
    "    skopt_time: Tiempo de BayesSearchCV\n",
    "    hyperopt_time: Tiempo de Hyperopt\n",
    "    \"\"\"\n",
    "    # Gráfico de F1-Scores\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    models = ['Base', 'BayesSearchCV', 'Hyperopt']\n",
    "    f1_scores = [base_f1, skopt_f1, hyperopt_f1]\n",
    "    colors = ['skyblue', 'lightgreen', 'salmon']\n",
    "    bars = plt.bar(models, f1_scores, color=colors)\n",
    "    plt.title('Comparación de F1-Score', fontsize=14)\n",
    "    plt.ylabel('F1-Score', fontsize=12)\n",
    "    plt.ylim(0.9, 1.0)\n",
    "    \n",
    "    # Añadir valores en las barras\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.annotate(f'{height:.4f}',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3),\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom',\n",
    "                    fontsize=10)\n",
    "    \n",
    "    # Gráfico de tiempos\n",
    "    plt.subplot(1, 2, 2)\n",
    "    times = [base_time, skopt_time, hyperopt_time]\n",
    "    colors_time = ['skyblue', 'lightgreen', 'salmon']\n",
    "    bars_time = plt.bar(models, times, color=colors_time)\n",
    "    plt.title('Tiempos de Ejecución', fontsize=14)\n",
    "    plt.ylabel('Segundos', fontsize=12)\n",
    "    \n",
    "    # Añadir valores en las barras\n",
    "    for bar in bars_time:\n",
    "        height = bar.get_height()\n",
    "        plt.annotate(f'{height:.2f}s',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3),\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom',\n",
    "                    fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('comparacion_resultados.png', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "def create_main_results_table(base_report, base_f1, base_time,\n",
    "                             skopt_params, skopt_report, skopt_f1, skopt_time,\n",
    "                             hyperopt_params, hyperopt_report, hyperopt_f1, hyperopt_time):\n",
    "    \"\"\"\n",
    "    Crea DataFrames con los resultados principales de los tres modelos.\n",
    "    \n",
    "    Retorna:\n",
    "    tuple: (df_base, df_skopt, df_hyperopt, df_comparacion)\n",
    "    \"\"\"\n",
    "    # DataFrame para modelo base\n",
    "    df_base = pd.DataFrame({\n",
    "        'Modelo': ['Base'],\n",
    "        'F1-Score': [base_f1],\n",
    "        'Tiempo (s)': [base_time],\n",
    "        'Reporte': [base_report]\n",
    "    })\n",
    "    \n",
    "    # DataFrame para BayesSearchCV\n",
    "    df_skopt = pd.DataFrame({\n",
    "        'Modelo': ['BayesSearchCV'],\n",
    "        'F1-Score': [skopt_f1],\n",
    "        'Tiempo (s)': [skopt_time],\n",
    "        'Hiperparámetros': [str(skopt_params)],\n",
    "        'Reporte': [skopt_report]\n",
    "    })\n",
    "    \n",
    "    # DataFrame para Hyperopt\n",
    "    df_hyperopt = pd.DataFrame({\n",
    "        'Modelo': ['Hyperopt'],\n",
    "        'F1-Score': [hyperopt_f1],\n",
    "        'Tiempo (s)': [hyperopt_time],\n",
    "        'Hiperparámetros': [str(hyperopt_params)],\n",
    "        'Reporte': [hyperopt_report]\n",
    "    })\n",
    "    \n",
    "    # DataFrame comparativo final\n",
    "    df_comparacion = pd.DataFrame({\n",
    "        'Modelo': ['Base', 'BayesSearchCV', 'Hyperopt'],\n",
    "        'F1-Score': [base_f1, skopt_f1, hyperopt_f1],\n",
    "        'Tiempo (s)': [base_time, skopt_time, hyperopt_time],\n",
    "        'Mejora vs Base': ['-', \n",
    "                          f\"{(skopt_f1 - base_f1):.4f}\", \n",
    "                          f\"{(hyperopt_f1 - base_f1):.4f}\"]\n",
    "    })\n",
    "    \n",
    "    return df_base, df_skopt, df_hyperopt, df_comparacion\n",
    "\n",
    "def display_formatted_tables(*tables):\n",
    "    \"\"\"\n",
    "    Muestra las tablas de resultados formateadas en la consola.\n",
    "    \n",
    "    Parámetros:\n",
    "    tables: Tupla de DataFrames a mostrar\n",
    "    \"\"\"\n",
    "    titles = [\n",
    "        \"RESULTADOS MODELO BASE\",\n",
    "        \"RESULTADOS BAYESSEARCHCV\",\n",
    "        \"RESULTADOS HYPEROPT\",\n",
    "        \"COMPARACIÓN FINAL DE MODELOS\"\n",
    "    ]\n",
    "    \n",
    "    for i, df in enumerate(tables):\n",
    "        print(titles[i])\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        # Mostrar reportes completos solo para los modelos principales\n",
    "        if i < 3:           \n",
    "            # Mostrar el DataFrame sin la columna de reporte\n",
    "            df_to_show = df.drop(columns=['Reporte'])\n",
    "            if 'Hiperparámetros' in df_to_show.columns:\n",
    "                # Formatear hiperparámetros para mejor visualización\n",
    "                df_to_show['Hiperparámetros'] = df_to_show['Hiperparámetros'].apply(\n",
    "                    lambda x: '\\n' + str(x).replace(',', '\\n').replace('{', '').replace('}', ''))\n",
    "            \n",
    "            print(\"\\nMétricas Resumen:\")\n",
    "            print(df_to_show.to_string(index=False, justify='left'))\n",
    "        else:\n",
    "            print(df.to_string(index=False, justify='left'))\n",
    "        \n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929c4f4f",
   "metadata": {},
   "source": [
    "**Bloque 6:** Función de ejecución.\n",
    "\n",
    "- **`main()`**\n",
    "Función principal que ejecuta todo el flujo: carga de datos, entrenamiento, optimización, experimentos, visualizaciones y resumen final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c069dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Función principal que ejecuta todo el flujo de trabajo\"\"\"\n",
    "    # 1. Carga y preparación de datos\n",
    "    print(\"Cargando y preparando datos...\")\n",
    "    data = load_breast_cancer()\n",
    "    X_train, X_test, y_train, y_test = load_and_prepare_data(data)\n",
    "    \n",
    "    # 2. Modelo base\n",
    "    print(\"\\nEntrenando modelo base...\")\n",
    "    base_report, base_f1, base_time = train_base_rf(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    # 3. Optimización con BayesSearchCV\n",
    "    print(\"\\nOptimizando con BayesSearchCV (Scikit-Optimize)...\")\n",
    "    skopt_params, skopt_report, skopt_f1, skopt_time = bayes_opt_skopt(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    # 4. Optimización con Hyperopt\n",
    "    print(\"\\nOptimizando con Hyperopt...\")\n",
    "    hyperopt_params, hyperopt_report, hyperopt_f1, hyperopt_time = bayes_opt_hyperopt(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    # 5. Crear DataFrames principales\n",
    "    df_base, df_skopt, df_hyperopt, df_comparacion = create_main_results_table(\n",
    "        base_report, base_f1, base_time,\n",
    "        skopt_params, skopt_report, skopt_f1, skopt_time,\n",
    "        hyperopt_params, hyperopt_report, hyperopt_f1, hyperopt_time\n",
    "    )\n",
    "    \n",
    "    # 6. Mostrar todas las tablas\n",
    "    display_formatted_tables(\n",
    "        df_base, df_skopt, df_hyperopt, df_comparacion\n",
    "    )\n",
    "    \n",
    "    # 7. Gráfico comparativo básico\n",
    "    plot_comparison(base_f1, skopt_f1, hyperopt_f1, base_time, skopt_time, hyperopt_time)\n",
    "    print(\"Gráfico comparativo guardado como 'comparacion_resultados.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6214502",
   "metadata": {},
   "source": [
    "# 4. Visualización de resultados\n",
    "\n",
    "Se muestran los resultados obtenidos a partir de la ejecución de la funcion **main()**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681f0523",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503f3a7a",
   "metadata": {},
   "source": [
    "# 5. Conclusiones, recomendaciones y reflexiones finales\n",
    "\n",
    "## Conclusiones\n",
    "\n",
    "- A partir de los resultados obtenidos, se concluye que la **Optimización Bayesiana** (tanto con **Scikit-Optimize** como con **Hyperopt**) puede superar al modelo base, pero solo bajo ciertas condiciones adecuadas de configuración.\n",
    "- El modelo base, sin ajuste de hiperparámetros, ya presentaba un desempeño sólido, con un **F1-Score de aproximadamente 0.9488**.\n",
    "- En los primeros experimentos con pocas iteraciones (por ejemplo, 20) y espacios de búsqueda estrechos, los métodos de optimización no lograron mejorar consistentemente al modelo base. De hecho, en algunos casos el rendimiento fue menor.\n",
    "- Este hallazgo sugiere que la optimización bayesiana **no garantiza automáticamente** una mejora significativa, especialmente cuando se limita el número de evaluaciones o el rango de búsqueda de hiperparámetros.\n",
    "\n",
    "## Recomendaciones y reflexiones finales\n",
    "\n",
    "Durante el desarrollo de este trabajo se evidenció que el uso de técnicas avanzadas como la optimización bayesiana requiere no solo una buena comprensión de los algoritmos involucrados, sino también un **criterio técnico claro** para determinar cuándo vale la pena aplicarlas.\n",
    "\n",
    "### Recomendaciones clave\n",
    "\n",
    "- **Evaluar primero un modelo base bien construido.**  \n",
    "  En muchos casos, un modelo con hiperparámetros por defecto (como `RandomForestClassifier`) ya puede ofrecer resultados competitivos, especialmente cuando se dispone de poco tiempo o recursos computacionales limitados.\n",
    "- **Aplicar optimización solo cuando se justifique.**  \n",
    "  Si el modelo base tiene margen de mejora o el caso de uso exige un desempeño elevado (por ejemplo, en aplicaciones clínicas o de alto impacto), entonces sí se justifica el uso de técnicas más complejas como `BayesSearchCV` o `Hyperopt`.\n",
    "- **Ajustar correctamente las configuraciones.**  \n",
    "  El número de iteraciones y el tamaño del espacio de búsqueda son factores críticos. Pocas iteraciones o rangos muy limitados pueden llevar a un desempeño peor que el del modelo base.\n",
    "- **Considerar el costo computacional.**  \n",
    "  Mientras que el modelo base se entrenó en aproximadamente **0.13 segundos**, las versiones optimizadas requirieron entre **20 y 26 segundos**. En contextos donde el tiempo o los recursos importan (como en producción o en grandes volúmenes de datos), esto podría ser un factor relevante.\n",
    "- **No confundir complejidad con efectividad.**  \n",
    "  Añadir múltiples capas de optimización no garantiza mejores resultados. La clave está en una **planificación estratégica** del experimento y una evaluación cuidadosa del valor agregado por cada técnica."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
