{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5aa357f",
   "metadata": {},
   "source": [
    "# Actividad 1:\n",
    "# Comparación de técnicas avanzadas para predicción de ingresos\n",
    "\n",
    "## Objetivo\n",
    "Objetivo: Aplicar y comparar modelos avanzados de regresión y clasificación sobre un mismo problema, evaluando su rendimiento y adecuación al contexto, utilizando un enfoque práctico e interpretativo.\n",
    "\n",
    "**Dataset utilizado:**  \n",
    "**`Adult Income`**\n",
    "\n",
    "---\n",
    "\n",
    "### Estructura del Notebook:\n",
    "1. Metodología.\n",
    "2. Importación de librerias a utilizar.\n",
    "3. Definicion de funciones.\n",
    "4. Uso de funciones y resultados.\n",
    "5. Análisis de los resultados y reflexiones finales.\n",
    "\n",
    "---\n",
    "\n",
    "### Versión de librerías usadas:\n",
    "- Pandas:           2.1.3\n",
    "- NumPy:            1.26.2\n",
    "- Matplotlib:       3.8.2\n",
    "- Seaborn:          0.13.0\n",
    "- Scikit-learn:     1.7.0\n",
    "- XGBoost:          2.1.3\n",
    "- Statsmodels:      0.14.0\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaaf6196",
   "metadata": {},
   "source": [
    "## 1. Metodología\n",
    "\n",
    "### Flujo de trabajo\n",
    "\n",
    "1. **Carga y exploración de datos:**\n",
    "   - Se utilizó el dataset **Adult Income** desde `fetch_openml`.\n",
    "   - Se exploraron dimensiones, tipos de variables, y se definió la variable objetivo (`>50K` = 1, `<=50K` = 0).\n",
    "\n",
    "2. **Preprocesamiento:**\n",
    "   - Separación de variables numéricas y categóricas.\n",
    "   - Codificación de variables categóricas mediante `OneHotEncoder`.\n",
    "   - Estandarización de variables numéricas con `StandardScaler`.\n",
    "   - División estratificada del dataset en conjuntos de entrenamiento (70%) y prueba (30%) para asegurar representatividad de clases.\n",
    "\n",
    "3. **Entrenamiento de modelos:**\n",
    "   - Se entrenaron y evaluaron cinco modelos distintos:\n",
    "     - **ElasticNet** (modelo lineal penalizado).\n",
    "     - **Regresiones Cuantílicas** con `statsmodels` en tres cuantiles: 0.1, 0.5 y 0.9.\n",
    "     - **Random Forest Classifier**.\n",
    "     - **XGBoost Classifier**.\n",
    "   - Todos los modelos fueron integrados en pipelines (`Pipeline`) con los mismos pasos de preprocesamiento para asegurar una evaluación justa.\n",
    "   - La regresión cuantilica se implementó fuera de `sklearn`, por lo que se preprocesaron manualmente los datos y se evaluaron los resultados cuantiles como clasificación (≥ 0.5).\n",
    "\n",
    "4. **Evaluación y análisis:**\n",
    "   - Métricas empleadas:\n",
    "     - **Accuracy:** porcentaje de predicciones correctas.\n",
    "     - **AUC (Area Under Curve):** mide la capacidad del modelo para distinguir entre clases.\n",
    "     - **Pinball Loss:** métrica específica para regresión cuantilica que penaliza predicciones según el cuantil definido.\n",
    "   - Se evaluaron las matrices de confusión para cada modelo.\n",
    "   - Se extrajo y comparó la **importancia de variables** más influyentes en cada modelo.\n",
    "\n",
    "5. **Visualización de resultados:**\n",
    "   - Tabla resumen con métricas comparativas.\n",
    "   - Gráficos de barras comparativos para Accuracy, AUC y curvas ROC.\n",
    "   - Matrices de confusión por grupo de modelos.\n",
    "   - Gráficos de las cinco variables más importantes por modelo.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fda1c0f",
   "metadata": {},
   "source": [
    "# 2. Importacion de librerias necesarias\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717e3c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, confusion_matrix, roc_auc_score,\n",
    "    mean_pinball_loss, roc_curve, auc\n",
    ")\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Configuración visual y de entorno\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('Set2')\n",
    "pd.set_option('display.precision', 4)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48d8f47",
   "metadata": {},
   "source": [
    "# 3. Definición de funciones\n",
    "\n",
    "> **Nota:** Para mejor comprensión de las funciones y su utilidad, esta sección se divide en bloques, en donde cada uno responde a una parte diferente de la metodología de trabajo. \n",
    "\n",
    "---\n",
    "\n",
    "**Bloque 1:** Funciones de preprocesamiento de datos.\n",
    "\n",
    "- **`cargar_datos()`** \n",
    "Carga y prepara el dataset Adult Income, separando variables numéricas y categóricas. Tambien reemplaza los valores faltantes (que son aproximadamente 7.4%) por el valor mas frecuente (moda).\n",
    "\n",
    "- **`preprocesador()`** \n",
    "Crea un transformador que escala variables numéricas y codifica variables categóricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66f03fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_datos():\n",
    "    \"\"\"\n",
    "    Carga el dataset 'Adult Income' desde OpenML, transforma la variable objetivo \n",
    "    a formato binario y separa variables predictoras categóricas y numéricas.\n",
    "    Reemplaza '?' por NaN para poder imputar valores faltantes luego.\n",
    "\n",
    "    Returns:\n",
    "        X (pd.DataFrame): DataFrame con las variables independientes (features).\n",
    "        y (pd.Series): Serie con la variable objetivo binaria (1 si ingreso >50K, 0 si no).\n",
    "        cat_cols (list): Lista con los nombres de columnas categóricas.\n",
    "        num_cols (list): Lista con los nombres de columnas numéricas.\n",
    "    \"\"\"\n",
    "    print(\"[INFO] Cargando datos...\")\n",
    "    data = fetch_openml(\"adult\", version=2, as_frame=True)\n",
    "    df = data.frame.copy()\n",
    "    df['target'] = df['class'].apply(lambda x: 1 if x == '>50K' else 0)\n",
    "    df.drop(columns=['class'], inplace=True)\n",
    "\n",
    "    # Reemplazar '?' por np.nan para detectar valores faltantes\n",
    "    df.replace('?', np.nan, inplace=True)\n",
    "\n",
    "    X = df.drop(columns=['target'])\n",
    "    y = df['target']\n",
    "\n",
    "    cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    num_cols = X.select_dtypes(include='number').columns.tolist()\n",
    "\n",
    "    return X, y, cat_cols, num_cols\n",
    "\n",
    "\n",
    "def preprocesador(cat_cols, num_cols):\n",
    "    \"\"\"\n",
    "    Crea un transformador de columnas que:\n",
    "    - Imputa valores faltantes en categóricas con la categoría más frecuente\n",
    "    - Aplica escalado a variables numéricas\n",
    "    - Codifica variables categóricas con OneHotEncoder\n",
    "\n",
    "    Args:\n",
    "        cat_cols (list): Lista con nombres de variables categóricas.\n",
    "        num_cols (list): Lista con nombres de variables numéricas.\n",
    "\n",
    "    Returns:\n",
    "        ColumnTransformer: Objeto que transforma numéricas con StandardScaler y categóricas con imputación + OneHotEncoder.\n",
    "    \"\"\"\n",
    "\n",
    "    num_pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    cat_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    return ColumnTransformer([\n",
    "        ('num', num_pipeline, num_cols),\n",
    "        ('cat', cat_pipeline, cat_cols)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7667a454",
   "metadata": {},
   "source": [
    "**Bloque 2:** Entrenamiento de modelos, evaluación y cálculo de importancia de variables.\n",
    "\n",
    "- **`evaluar_modelo()`** \n",
    "Calcula métricas y matriz de confusión, guarda resultados e imprime resumen.\n",
    "\n",
    "- **`entrenar_modelos()`** \n",
    "Entrena varios modelos y devuelve sus resultados, matrices y objetos.\n",
    "\n",
    "- **`calcular_importancias()`** \n",
    "Extrae y muestra las variables más importantes de cada modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8165579",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_modelo(y_true, y_pred, nombre, results, conf_matrices):\n",
    "    \"\"\"\n",
    "    Calcula métricas de evaluación (accuracy y AUC) para un modelo y actualiza \n",
    "    los diccionarios de resultados y matrices de confusión.\n",
    "\n",
    "    Args:\n",
    "        y_true (array-like): Valores reales de la variable objetivo.\n",
    "        y_pred (array-like): Predicciones del modelo (clase binaria).\n",
    "        nombre (str): Nombre del modelo para registrar en los diccionarios.\n",
    "        results (dict): Diccionario donde se almacenan accuracy y AUC por modelo.\n",
    "        conf_matrices (dict): Diccionario donde se almacenan las matrices de confusión por modelo.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Accuracy y AUC del modelo evaluado.\n",
    "    \"\"\"\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    results[nombre] = (acc, auc)\n",
    "    conf_matrices[nombre] = cm\n",
    "    print(f\"\\n[{nombre}] Accuracy: {acc:.4f}, AUC: {auc:.4f}\")\n",
    "    return acc, auc\n",
    "\n",
    "def entrenar_modelos(X_train, y_train, X_test, y_test, preprocessor, cat_cols, num_cols):\n",
    "    \"\"\"\n",
    "    Entrena y evalúa varios modelos de clasificación y regresión cuantilica sobre el dataset de Adult Income.\n",
    "\n",
    "    Modelos incluidos:\n",
    "        - ElasticNet (lineal penalizado)\n",
    "        - Quantile Regression con statsmodels (q = 0.1, 0.5, 0.9)\n",
    "        - Random Forest\n",
    "        - XGBoost\n",
    "\n",
    "    Args:\n",
    "        X_train (pd.DataFrame): Conjunto de entrenamiento (features).\n",
    "        y_train (pd.Series): Etiquetas del conjunto de entrenamiento.\n",
    "        X_test (pd.DataFrame): Conjunto de prueba (features).\n",
    "        y_test (pd.Series): Etiquetas del conjunto de prueba.\n",
    "        preprocessor (ColumnTransformer): Objeto de preprocesamiento compartido por los modelos.\n",
    "        cat_cols (list): Lista de columnas categóricas.\n",
    "        num_cols (list): Lista de columnas numéricas.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            - results (dict): Métricas de accuracy y AUC por modelo.\n",
    "            - conf_matrices (dict): Matrices de confusión por modelo.\n",
    "            - model_store (dict): Modelos entrenados (pipeline o regresor statsmodels).\n",
    "            - all_feature_names (list): Lista con todos los nombres de variables después del preprocesamiento.\n",
    "    \"\"\"\n",
    "    results, conf_matrices, model_store = {}, {}, {}\n",
    "\n",
    "    # ElasticNet\n",
    "    print(\"[INFO] Entrenando ElasticNet...\")\n",
    "    elastic_pipe = Pipeline([\n",
    "        ('preproc', preprocessor),\n",
    "        ('model', ElasticNet(alpha=0.1, l1_ratio=0.5))\n",
    "    ])\n",
    "    elastic_pipe.fit(X_train, y_train)\n",
    "    y_pred_en = elastic_pipe.predict(X_test)\n",
    "    y_pred_en_class = (y_pred_en >= 0.5).astype(int)\n",
    "    evaluar_modelo(y_test, y_pred_en_class, \"ElasticNet\", results, conf_matrices)\n",
    "    model_store[\"ElasticNet\"] = elastic_pipe\n",
    "\n",
    "    # Quantile Regression\n",
    "    print(\"[INFO] Entrenando Regresión Cuantílica con statsmodels...\")\n",
    "    preprocessor_qr = preprocesador(cat_cols, num_cols)\n",
    "    X_train_trans = preprocessor_qr.fit_transform(X_train)\n",
    "    X_test_trans = preprocessor_qr.transform(X_test)\n",
    "\n",
    "    cat_features = preprocessor_qr.named_transformers_['cat'].get_feature_names_out(cat_cols)\n",
    "    all_feature_names = np.concatenate([num_cols, cat_features])\n",
    "    X_train_df = pd.DataFrame(X_train_trans.toarray() if hasattr(X_train_trans, 'toarray') else X_train_trans,\n",
    "                              columns=all_feature_names, index=X_train.index)\n",
    "    X_test_df = pd.DataFrame(X_test_trans.toarray() if hasattr(X_test_trans, 'toarray') else X_test_trans,\n",
    "                             columns=all_feature_names, index=X_test.index)\n",
    "\n",
    "    X_train_const = sm.add_constant(X_train_df)\n",
    "    X_test_const = sm.add_constant(X_test_df)\n",
    "\n",
    "    for q in [0.1, 0.5, 0.9]:\n",
    "        print(f\"  > Entrenando QuantileReg q={q} con statsmodels...\")\n",
    "        qr_model = sm.QuantReg(y_train, X_train_const)\n",
    "        res = qr_model.fit(q=q)\n",
    "        y_pred_q = res.predict(X_test_const)\n",
    "        y_pred_q_class = (y_pred_q >= 0.5).astype(int)\n",
    "        nombre = f\"Quantile q={q}\"\n",
    "        evaluar_modelo(y_test, y_pred_q_class, nombre, results, conf_matrices)\n",
    "        pinball = mean_pinball_loss(y_test, y_pred_q, alpha=q)\n",
    "        print(f\"[{nombre}] Pinball Loss: {pinball:.4f}\")\n",
    "        model_store[nombre] = res\n",
    "\n",
    "    # Random Forest\n",
    "    print(\"[INFO] Entrenando Random Forest...\")\n",
    "    rf_pipe = Pipeline([\n",
    "        ('preproc', preprocessor),\n",
    "        ('model', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "    ])\n",
    "    rf_pipe.fit(X_train, y_train)\n",
    "    y_pred_rf = rf_pipe.predict(X_test)\n",
    "    evaluar_modelo(y_test, y_pred_rf, \"Random Forest\", results, conf_matrices)\n",
    "    model_store['Random Forest'] = rf_pipe\n",
    "\n",
    "    # XGBoost\n",
    "    print(\"[INFO] Entrenando XGBoost...\")\n",
    "    xgb_pipe = Pipeline([\n",
    "        ('preproc', preprocessor),\n",
    "        ('model', XGBClassifier(eval_metric='logloss', random_state=42))\n",
    "    ])\n",
    "    xgb_pipe.fit(X_train, y_train)\n",
    "    y_pred_xgb = xgb_pipe.predict(X_test)\n",
    "    evaluar_modelo(y_test, y_pred_xgb, \"XGBoost\", results, conf_matrices)\n",
    "    model_store['XGBoost'] = xgb_pipe\n",
    "\n",
    "    return results, conf_matrices, model_store, all_feature_names\n",
    "\n",
    "def calcular_importancias(model_store, all_feature_names):\n",
    "    \"\"\"\n",
    "    Calcula e imprime la importancia de las variables para cada modelo.\n",
    "\n",
    "    Para modelos lineales (ElasticNet y Quantile Regression) se usa el valor absoluto de los coeficientes.\n",
    "    Para modelos basados en árboles (Random Forest y XGBoost) se usa `feature_importances_`.\n",
    "\n",
    "    Args:\n",
    "        model_store (dict): Diccionario con los modelos entrenados.\n",
    "        all_feature_names (list): Lista de nombres de todas las variables transformadas.\n",
    "\n",
    "    Returns:\n",
    "        dict: Diccionario con las 5 variables más importantes por modelo.\n",
    "    \"\"\"\n",
    "    print(\"\\n[IMPORTANCIA DE VARIABLES]\")\n",
    "    importancias = {}\n",
    "    for modelo in ['ElasticNet', 'Random Forest', 'XGBoost']:\n",
    "        pipe = model_store[modelo]\n",
    "        if hasattr(pipe.named_steps['model'], 'coef_'):\n",
    "            coefs = np.abs(pipe.named_steps['model'].coef_)\n",
    "        else:\n",
    "            coefs = pipe.named_steps['model'].feature_importances_\n",
    "        top_idx = np.argsort(coefs)[-5:][::-1]\n",
    "        importancias[modelo] = [(all_feature_names[i], coefs[i]) for i in top_idx]\n",
    "\n",
    "    for q in [0.1, 0.5, 0.9]:\n",
    "        modelo = f\"Quantile q={q}\"\n",
    "        res = model_store[modelo]\n",
    "        coefs = np.abs(res.params.values[1:])  # sin intercepto\n",
    "        top_idx = np.argsort(coefs)[-5:][::-1]\n",
    "        importancias[modelo] = [(all_feature_names[i], coefs[i]) for i in top_idx]\n",
    "\n",
    "    print(\"\\nTop 1 variable por modelo:\")\n",
    "    for modelo, top_feats in importancias.items():\n",
    "        print(f\"{modelo:<15}: {top_feats[0][0]} ({top_feats[0][1]:.4f})\")\n",
    "    return importancias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224d08f8",
   "metadata": {},
   "source": [
    "**Bloque 3:** Resultados y visualizaciones.\n",
    "\n",
    "- **`mostrar_resultados()`** \n",
    "Muestra y retorna un DataFrame con las métricas de desempeño de todos los modelos.\n",
    "\n",
    "- **`graficar_importancias()`** \n",
    "Genera gráficos de barras con las importancias de las variables para cada modelo.\n",
    "\n",
    "- **`graficar_metricas()`** \n",
    "Visualiza comparaciones de accuracy y AUC de los modelos con gráficos de barras, además de una comparación de las curvas ROC.\n",
    "\n",
    "- **`graficar_confusiones()`** \n",
    "Muestra las matrices de confusión de los modelos en forma de mapas de calor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826bc430",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostrar_resultados(results):\n",
    "    \"\"\"\n",
    "    Muestra una tabla con las métricas de rendimiento (Accuracy y AUC) para cada modelo.\n",
    "\n",
    "    Args:\n",
    "        results (dict): Diccionario con los nombres de los modelos como llaves y tuplas (accuracy, AUC) como valores.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame con los resultados por modelo.\n",
    "    \"\"\"\n",
    "    print(\"\\n[RESULTADOS FINALES]\")\n",
    "    df = pd.DataFrame(results).T\n",
    "    df.columns = ['Accuracy', 'AUC']\n",
    "    print(df)\n",
    "    return df\n",
    "\n",
    "def graficar_importancias(importancias):\n",
    "    \"\"\"\n",
    "    Genera gráficos de la importancia de variables para ElasticNet, Random Forest, XGBoost \n",
    "    y para los modelos de regresión cuantilica (q=0.1, 0.5, 0.9).\n",
    "\n",
    "    Args:\n",
    "        importancias (dict): Diccionario con los nombres de los modelos como llaves \n",
    "                             y listas de tuplas (nombre_variable, importancia) como valores.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))  \n",
    "\n",
    "    # Definir colores para cada modelo\n",
    "    colores = ['green', 'orange', 'purple']\n",
    "\n",
    "    # Primera fila: ElasticNet, Random Forest, XGBoost\n",
    "    for ax, modelo, color in zip(axes[0], ['ElasticNet', 'Random Forest', 'XGBoost'], colores):\n",
    "        nombres, pesos = zip(*importancias[modelo])\n",
    "        sns.barplot(x=nombres, y=pesos, ax=ax, color=color)\n",
    "        ax.set_title(f\"{modelo} - Top 5 features\")\n",
    "        ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "    # Segunda fila: Quantile q=0.1, q=0.5, q=0.9\n",
    "    for ax, modelo in zip(axes[1], ['Quantile q=0.1', 'Quantile q=0.5', 'Quantile q=0.9']):\n",
    "        nombres, pesos = zip(*importancias[modelo])\n",
    "        sns.barplot(x=nombres, y=pesos, ax=ax, color='DarkBlue')\n",
    "        ax.set_title(f\"{modelo} - Top 5 features\")\n",
    "        ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('importancias_variables.png', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "def graficar_metricas(df, model_store, X_test, y_test, X_test_qr):\n",
    "    \"\"\"\n",
    "    Genera una figura con tres subgráficos:\n",
    "    - Gráfico de barras comparando Accuracy entre modelos.\n",
    "    - Gráfico de barras comparando AUC entre modelos.\n",
    "    - Curvas ROC para todos los modelos, incluyendo regresión cuantilica.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame con métricas de evaluación (Accuracy, AUC).\n",
    "        model_store (dict): Diccionario con los modelos entrenados.\n",
    "        X_test (pd.DataFrame): Conjunto de test sin preprocesar.\n",
    "        y_test (pd.Series): Etiquetas verdaderas del conjunto de test.\n",
    "        X_test_qr (np.ndarray): Conjunto de test transformado para regresión cuantilica (ya con constante).\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(21, 6))\n",
    "\n",
    "    # Gráfico 1: Accuracy\n",
    "    sns.barplot(x=df.index, y='Accuracy', data=df.reset_index(), ax=axes[0], color='Red')\n",
    "    axes[0].set_title('Comparación de Accuracy')\n",
    "    axes[0].tick_params(axis='x', rotation=45)\n",
    "    axes[0].grid(axis='y')\n",
    "\n",
    "    # Gráfico 2: AUC\n",
    "    sns.barplot(x=df.index, y='AUC', data=df.reset_index(), ax=axes[1], color='Red')\n",
    "    axes[1].set_title('Comparación de AUC')\n",
    "    axes[1].tick_params(axis='x', rotation=45)\n",
    "    axes[1].grid(axis='y')\n",
    "\n",
    "    # Gráfico 3: Curvas ROC\n",
    "\n",
    "    for modelo in ['ElasticNet', 'Random Forest', 'XGBoost']:\n",
    "        pipe = model_store[modelo]\n",
    "        y_scores = pipe.predict_proba(X_test)[:, 1] if hasattr(pipe.named_steps['model'], 'predict_proba') else pipe.predict(X_test)\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_scores)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        axes[2].plot(fpr, tpr, lw=2, label=f\"{modelo} (AUC = {roc_auc:.2f})\")\n",
    "\n",
    "    # Cuantil\n",
    "    for q in [0.1, 0.5, 0.9]:\n",
    "        modelo = f\"Quantile q={q}\"\n",
    "        res = model_store[modelo]\n",
    "        y_scores = res.predict(X_test_qr)\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_scores)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        axes[2].plot(fpr, tpr, linestyle='--', lw=1.5, label=f\"{modelo} (AUC = {roc_auc:.2f})\")\n",
    "\n",
    "    axes[2].plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "    axes[2].set_title('Curvas ROC')\n",
    "    axes[2].set_xlabel('False Positive Rate')\n",
    "    axes[2].set_ylabel('True Positive Rate')\n",
    "    axes[2].legend(loc='lower right')\n",
    "    axes[2].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('metricas_modelos.png', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "def graficar_confusiones(conf_matrices):\n",
    "    \"\"\"\n",
    "    Genera matrices de confusión para ElasticNet, Random Forest, XGBoost \n",
    "    y para los modelos de regresión cuantilica (q=0.1, 0.5, 0.9).\n",
    "\n",
    "    Args:\n",
    "        conf_matrices (dict): Diccionario con los nombres de los modelos como llaves \n",
    "                              y matrices de confusión (2x2 np.ndarray) como valores.\n",
    "                              \n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10)) \n",
    "\n",
    "    # Primera fila: ElasticNet, Random Forest, XGBoost con cmaps diferentes\n",
    "    cmaps = ['Greens', 'Oranges', 'Purples']\n",
    "    modelos = ['ElasticNet', 'Random Forest', 'XGBoost']\n",
    "\n",
    "    for ax, modelo, cmap in zip(axes[0], modelos, cmaps):\n",
    "        sns.heatmap(conf_matrices[modelo], annot=True, fmt='d', cmap=cmap, ax=ax)\n",
    "        ax.set_title(f'Matriz de Confusión - {modelo}')\n",
    "\n",
    "    # Segunda fila: regresiones cuantílicas con cmap 'Blues'\n",
    "    for ax, modelo in zip(axes[1], ['Quantile q=0.1', 'Quantile q=0.5', 'Quantile q=0.9']):\n",
    "        sns.heatmap(conf_matrices[modelo], annot=True, fmt='d', cmap='Blues', ax=ax)\n",
    "        ax.set_title(f'Matriz de Confusión - {modelo}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('matrices_confusion.png', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74184012",
   "metadata": {},
   "source": [
    "**Bloque 4:** Función de ejecución.\n",
    "\n",
    "- **`main()`**\n",
    "Utiliza todas las funciones definidas anteriormente para obtener datos de los modelos mediante Elastic Net, Regresión Cuantílica (q = 0.1, 0.5 y 0.9) y XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfd9128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Ejecuta el flujo completo de carga, preprocesamiento, entrenamiento, evaluación y visualización \n",
    "    de modelos para el dataset Adult Income.\n",
    "\n",
    "    Pasos incluidos:\n",
    "    - Carga y separación de datos en variables predictoras y objetivo.\n",
    "    - Preprocesamiento (escalado y codificación).\n",
    "    - División en conjuntos de entrenamiento y prueba.\n",
    "    - Entrenamiento de múltiples modelos (ElasticNet, regresión cuantilica, Random Forest, XGBoost).\n",
    "    - Evaluación de métricas de rendimiento y cálculo de importancia de variables.\n",
    "    - Presentación de resultados numéricos y visuales (gráficos de importancia, métricas y matrices de confusión).\n",
    "    \"\"\"\n",
    "    X, y, cat_cols, num_cols = cargar_datos()\n",
    "    preproc = preprocesador(cat_cols, num_cols)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "    results, conf_matrices, model_store, all_feature_names = entrenar_modelos(\n",
    "        X_train, y_train, X_test, y_test, preproc, cat_cols, num_cols\n",
    "    )\n",
    "    importancias = calcular_importancias(model_store, all_feature_names)\n",
    "    df_resultados = mostrar_resultados(results)\n",
    "\n",
    "    # Preparar X_test_qr (transformado + constante) para curvas ROC de regresión cuantilica\n",
    "    preprocessor_qr = preprocesador(cat_cols, num_cols)\n",
    "    X_test_trans = preprocessor_qr.fit(X_train).transform(X_test)\n",
    "    if hasattr(X_test_trans, 'toarray'):\n",
    "        X_test_trans = X_test_trans.toarray()\n",
    "    X_test_qr = sm.add_constant(X_test_trans)\n",
    "\n",
    "    graficar_importancias(importancias)\n",
    "    graficar_metricas(df_resultados, model_store, X_test, y_test, X_test_qr)  # ahora con curva ROC integrada\n",
    "    graficar_confusiones(conf_matrices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f8a051",
   "metadata": {},
   "source": [
    "# 4. Visualización de resultados\n",
    "\n",
    "Se muestran los resultados obtenidos a partir de la ejecución de la funcion **main()**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f542e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888876bc",
   "metadata": {},
   "source": [
    "## Análisis Comparativo de Modelos de Clasificación - Adult Income Dataset\n",
    "\n",
    "---\n",
    "\n",
    "### Justificaciones\n",
    "\n",
    "**Limpieza de datos:** El dataset mostró tener aproximadamente 3600 NaN, que representan alrededor del 7.4% del conjunto total. Visto que es un % significativo, se decidió imputar los datos con el mas frecuente (moda), debido a que eliminar esa cantidad de datos podría llevar a un sesgo en los resultados finales.\n",
    "\n",
    "**Uso de métodos de optimización**: Para efectos prácticos, debido a que la finalidad de este trabajo es poner a prueba distintos modelos como Elastic Net o XGBoost, para no hacer un código tan extenso y evitar que la ejecución tome mucho tiempo, se omitió la realizacion de métodos de optimización como grid search o random search para buscar los mejores hiperparámetros para cada modelos.\n",
    "\n",
    "---\n",
    "\n",
    ">**Nota:** \n",
    ">\n",
    "> Este análisis incluye la evaluación de varios modelos de aprendizaje automático sobre el dataset Adult Income, cuyo objetivo es clasificar si una persona gana más de $50.000 anuales.\n",
    ">\n",
    "> Algunos de los modelos utilizados, como ElasticNet (regresión lineal) y Regresión Cuantilica, no están diseñados específicamente para clasificación binaria. Su inclusión en este trabajo tiene un propósito comparativo y exploratorio, para analizar cómo se comportan en un contexto fuera de su aplicación ideal.\n",
    ">\n",
    "> Por ello, métricas típicas de regresión como RMSE no se aplican ni se reportan aquí. En cambio, para evaluar su desempeño en esta tarea usamos Accuracy, AUC y Pinball Loss (específica para regresión cuantilica). Esto implica que las comparaciones deben interpretarse considerando estas diferencias metodológicas.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. ¿Cuál modelo rinde mejor en qué contexto?\n",
    "\n",
    "- **XGBoost** obtuvo el mejor rendimiento general con una **accuracy de 87.76%** y **AUC de 0.805**, siendo el modelo más robusto para predecir si una persona gana más de \\$50.000.\n",
    "- **Random Forest** mostró un desempeño sólido (**accuracy 85.63%**, **AUC 0.775**), útil si se busca un equilibrio entre interpretabilidad (mediante importancia de variables o herramientas como SHAP) y precisión.\n",
    "- **ElasticNet** logró una accuracy de 77.30% pero con una baja AUC (0.53), indicando poca capacidad discriminativa pese a una precisión moderada.\n",
    "- **Regresiones cuantilicas** mostraron resultados variables:\n",
    "  - Cuantil **q=0.5 (mediana)** tuvo desempeño razonable (accuracy 78.69%, AUC 0.60), con un valor de Pinball Loss que mide el error específico para ese cuantíl, indicando qué tan bien el modelo estima esa parte de la distribución del ingreso.\n",
    "  - Cuantiles extremos (q=0.1 y q=0.9) mostraron menor estabilidad: q=0.1 predijo aleatoriamente (AUC ≈ 0.5) y un Pinball Loss bajo debido a la naturaleza del cuantíl bajo, mientras que q=0.9, aunque logró una alta AUC, tuvo baja precisión y un Pinball Loss intermedio, posiblemente por sobreajuste en un subconjunto minoritario.\n",
    "\n",
    "### **Resumen general:**\n",
    "| Criterio                      | Mejor modelo        |\n",
    "|------------------------------|---------------------|\n",
    "| Mayor precisión y AUC        | XGBoost             |\n",
    "| Interpretabilidad balanceada | Random Forest       |\n",
    "| Alternativas lineales        | Menor desempeño     |\n",
    "\n",
    "---\n",
    "\n",
    "### 2. ¿Qué variable tuvo más impacto en cada modelo?\n",
    "\n",
    "Los resultados muestran que las variables con mayor impacto varían según el modelo y el cuantíl analizado, reflejando diferentes perspectivas y sensibilidad a las características del dataset:\n",
    "\n",
    "| Modelo          | Variable más importante                |Peso (App)|\n",
    "|-----------------|----------------------------------------|----------|\n",
    "| ElasticNet      | marital-status_Married-civ-spouse      | 0.1192   |\n",
    "| Quantile q=0.1  | capital-gain                           | 0.0000   |\n",
    "| Quantile q=0.5  | education_Prof-school                  | 0.4172   |\n",
    "| Quantile q=0.9  | native-country_Hungary                 | 0.9652   |\n",
    "| Random Forest   | fnlwgt                                 | 0.1689   |\n",
    "| XGBoost         | marital-status_Married-civ-spouse      | 0.3760   |\n",
    "\n",
    "---\n",
    "\n",
    "- **Modelos lineales y regularizados (ElasticNet)** coinciden en que el **estado civil**, específicamente estar casado (\"married-civ-spouse\"), es un predictor clave para determinar ingresos altos. Esto indica que esta variable tiene un efecto lineal fuerte y consistente en la probabilidad de ganar más de \\$50K.\n",
    "\n",
    "- En la **regresión cuantílica**, la importancia de las variables cambia según el cuantíl:\n",
    "  - En el **cuantíl bajo (q=0.1)**, la variable \"capital-gain\" tiene peso nulo, sugiriendo que para los ingresos más bajos no aporta predictivamente.\n",
    "  - En el **cuantíl mediano (q=0.5)**, \"education_Prof-school\" (nivel educativo avanzado) cobra relevancia, indicando que a niveles medios de ingreso la educación tiene un impacto significativo.\n",
    "  - En el **cuantíl alto (q=0.9)**, \"native-country_Hungary\" destaca con un peso muy alto, lo que podría reflejar que para los ingresos más altos el país de origen o factores demográficos específicos juegan un papel importante, aunque podría estar influenciado por menor cantidad de casos o sesgos.\n",
    "\n",
    "- Los **modelos basados en árboles (Random Forest y XGBoost)** resaltan variables distintas:\n",
    "  - **Random Forest** destaca \"fnlwgt\" (peso final), una variable relacionada con la ponderación del encuestado en la muestra, que puede capturar características complejas del dataset.\n",
    "  - **XGBoost** vuelve a enfatizar \"marital-status_Married-civ-spouse\", mostrando la importancia continua de esta variable también en modelos no lineales y más complejos.\n",
    "\n",
    "En resumen, el **estado civil** y el **nivel educativo** aparecen como predictores recurrentes y clave en la mayoría de los modelos, mientras que otras variables, como el país de origen o características específicas de la muestra, influyen dependiendo del método y la parte de la distribución de ingresos que se modele.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. ¿Qué modelo recomendarías implementar?\n",
    "\n",
    "Recomendaría implementar **XGBoost**, ya que ofrece:\n",
    "- La mejor precisión\n",
    "- Capacidad para modelar relaciones no lineales complejas\n",
    "- Buen manejo de outliers y features categóricos\n",
    "- Compatibilidad con interpretabilidad moderna mediante técnicas como SHAP o PDP\n",
    "\n",
    "Alternativamente, si se necesita mayor **transparencia directa en las decisiones**, **Random Forest** es una opción sólida, aunque con leve pérdida de precisión.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Reflexión: ¿Por qué ElasticNet y regresión cuantilica no son preferibles aquí?\n",
    "\n",
    "### ElasticNet:\n",
    "- Es un modelo **lineal** que no captura bien las interacciones complejas entre variables presentes en este problema.\n",
    "- Aunque su accuracy es razonable, su **AUC de 0.53** indica que no distingue adecuadamente entre clases.\n",
    "\n",
    "### Regresión Cuantílica:\n",
    "- Está diseñada para predecir **distribuciones de variables continuas**, no para clasificación binaria.\n",
    "- En este contexto, genera probabilidades poco calibradas.\n",
    "- Además, es **computacionalmente costosa** cuando hay muchas variables categóricas codificadas.\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusiones finales\n",
    "\n",
    "Este análisis comparativo confirma que:\n",
    "\n",
    "- **Modelos basados en árboles**, como XGBoost y Random Forest, son ideales para tareas de clasificación en datasets como *Adult Income*.\n",
    "- La **elección del modelo** debe equilibrar precisión, interpretabilidad y recursos computacionales.\n",
    "- La exploración de variables clave permite **interpretar el comportamiento del modelo** y su posible sesgo en decisiones sensibles como predicción de ingresos.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
