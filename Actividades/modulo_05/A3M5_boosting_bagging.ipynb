{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b34241c",
   "metadata": {},
   "source": [
    "# Actividad 3:\n",
    "# Comparación de métodos de Boosting y Bagging en predicción de ingresos\n",
    "\n",
    "## Objetivo\n",
    "Aplicar y comparar algoritmos de boosting y bagging sobre datos reales, evaluando su rendimiento mediante precisión y matriz de confusión, e interpretando los resultados para fundamentar decisiones técnicas.\n",
    "\n",
    "**Datasets utilizados:**  \n",
    "`Adult Income`\n",
    "\n",
    "---\n",
    "\n",
    "### Estructura del Notebook:\n",
    "1. Metodología.\n",
    "2. Configuración del entorno.\n",
    "3. Definicion de funciones.\n",
    "4. Uso de funciones y resultados.\n",
    "5. Análisis de los resultados y reflexiones finales.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f68b6d",
   "metadata": {},
   "source": [
    "## 1. Metodología\n",
    "\n",
    "### Flujo de trabajo\n",
    "\n",
    "1. **Carga y preprocesamiento de datos y entrenamiento de modelos:**\n",
    "\n",
    "Se utilizaron 3 datasets para evaluar 3 técnicas avanzadas de regresión:  \n",
    "\n",
    "   - Se utilizó el dataset **Adult Incoome** desde `fetch_openml`.\n",
    "   - Identificación de valores faltantes (?), tipos de variables y distribución de clases.\n",
    "   - Limpieza de datos reemplazando o eliminando valores nulos según su proporción.\n",
    "   - Codificación ordinal de variables categóricas para estandarizar la entrada a todos los modelos.\n",
    "   - División estratificada del dataset en entrenamiento y prueba (80/20).\n",
    "\n",
    "2. **Evaluación y análisis:**\n",
    "   - Modelos utilizados:\n",
    "     - Boosting: AdaBoost, XGBoost, LightGBM, CatBoost.\n",
    "     - Bagging: Random Forest.\n",
    "\n",
    "   - Optimización de modelos:\n",
    "     - Uso de Optuna con 20 trials por modelo.\n",
    "     - Validación cruzada (CV=3) y accuracy como métrica objetivo.\n",
    "     - Entrenamiento de modelos en abse a los mejores parámetros.\n",
    "\n",
    "   - Métricas empleadas:\n",
    "     - accuracy_score\n",
    "     - confusion_matrix\n",
    "     - Tiempos de ejecución\n",
    "\n",
    "3. **Visualización de resultados:**\n",
    "  - Tabla resumen con métricas evaluadas para cada modelo.\n",
    "  - Gráficos de barras comparativos para mostrar la comparación de accuracy y tiempos de ejecución entre los cinco modelos.\n",
    "  - Matrices de confusión de cada modelo.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ed695f",
   "metadata": {},
   "source": [
    "# 2. Configuración del entorno\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538f352e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import optuna\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from tabulate import tabulate\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Configuración visual y de entorno\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('Set2')\n",
    "pd.set_option('display.precision', 4)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd94693e",
   "metadata": {},
   "source": [
    "# 3. Definición de funciones\n",
    "\n",
    "> **Nota:** Para mejor comprensión de las funciones y su utilidad, esta sección se divide en bloques, en donde cada uno responde a una parte diferente de la metodología de trabajo. \n",
    "\n",
    "---\n",
    "\n",
    "**Bloque 1:** Carga y preprocesamiento de datos y entrenamiento de modelos.\n",
    "\n",
    "- **`cargar_y_analizar_datos()`** \n",
    "Carga el dataset Adult Income desde OpenML, analiza su estructura y limpia valores nulos.\n",
    "\n",
    "- **`preprocesar_datos()`** \n",
    "Aplica imputación y codificación ordinal a las variables, y separa los datos en entrenamiento y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02464da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_y_analizar_datos():\n",
    "    \"\"\"\n",
    "    Carga y realiza un análisis exploratorio inicial del dataset 'Adult Income' desde OpenML.\n",
    "\n",
    "    El flujo incluye:\n",
    "    - Carga del dataset como DataFrame de pandas.\n",
    "    - Impresión de las primeras filas y resumen informativo de las columnas.\n",
    "    - Revisión del número de valores únicos por columna.\n",
    "    - Reemplazo de caracteres '?' por valores nulos (NaN).\n",
    "    - Revisión e imputación de valores faltantes:\n",
    "        - Si una columna tiene <5% de valores nulos, se eliminan las filas correspondientes.\n",
    "        - Si una columna tiene >=5% de valores nulos, se imputan con la moda de la columna.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame limpio y listo para preprocesamiento posterior.\n",
    "    \"\"\"\n",
    "    print(\"Cargando datos...\")\n",
    "    df = fetch_openml(\"adult\", version=2, as_frame=True).frame\n",
    "    print(\"\\nInformación del dataset:\")\n",
    "    print(df.info())\n",
    "\n",
    "    # Reemplazar '?' con NaN\n",
    "    df.replace('?', np.nan, inplace=True)\n",
    "\n",
    "    # Ver valores nulos\n",
    "    print(\"\\nPorcentaje de valores faltantes:\")\n",
    "    print(df.isnull().mean() * 100)\n",
    "\n",
    "    # Eliminar columnas o filas según porcentaje de nulos\n",
    "    for col in df.columns:\n",
    "        missing = df[col].isnull().mean()\n",
    "        if missing > 0:\n",
    "            if missing < 0.05:\n",
    "                df = df[df[col].notnull()]\n",
    "            else:\n",
    "                df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "    return df\n",
    "\n",
    "def preprocesar_datos(df):\n",
    "    \"\"\"\n",
    "    Preprocesa el DataFrame del dataset Adult para preparar los datos para entrenamiento de modelos de ML.\n",
    "\n",
    "    El flujo incluye:\n",
    "    - Separación entre variables predictoras (X) y variable objetivo ('class').\n",
    "    - Codificación de la variable objetivo (binaria) usando LabelEncoder.\n",
    "    - Imputación de valores faltantes en X con la moda de cada columna.\n",
    "    - Codificación ordinal de todas las variables categóricas para convertirlas a valores numéricos.\n",
    "    - Validación de que no queden columnas categóricas sin codificar.\n",
    "    - División de los datos en conjuntos de entrenamiento y prueba con estratificación.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataset limpio con variables categóricas y numéricas.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]: \n",
    "            X_train, X_test, y_train, y_test listos para entrenamiento.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    y = df['class']\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "\n",
    "    X = df.drop('class', axis=1)\n",
    "    X = X.replace('?', np.nan)\n",
    "\n",
    "    for col in X.columns:\n",
    "        if X[col].isnull().sum() > 0:\n",
    "            X[col] = X[col].fillna(X[col].mode()[0])\n",
    "\n",
    "    cat_cols = X.select_dtypes(include=['object', 'category']).columns\n",
    "    enc = OrdinalEncoder()\n",
    "    X[cat_cols] = enc.fit_transform(X[cat_cols])\n",
    "\n",
    "    assert X.select_dtypes(include=['object', 'category']).empty, \"[ALERTA] Quedan columnas no numéricas en X\"\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac175d9",
   "metadata": {},
   "source": [
    "**Bloque 2:** Optimización, entrenamiento y evaluación de modelos de Boosting y Bagging.\n",
    "\n",
    "- **`optimizar_modelo()`** \n",
    "Usa Optuna para encontrar los mejores hiperparámetros para un modelo dado.\n",
    "\n",
    "- **`entrenar_modelo()`** \n",
    "Entrena el modelo con los hiperparámetros óptimos y mide el tiempo de entrenamiento.\n",
    "\n",
    "- **`evaluar_modelo()`** \n",
    "Evalúa el modelo sobre los datos de prueba usando accuracy y matriz de confusión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b363655",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizar_modelo(nombre_modelo, X_train, y_train):\n",
    "    \"\"\"\n",
    "    Optimiza los hiperparámetros de un modelo de clasificación utilizando Optuna y validación cruzada.\n",
    "\n",
    "    Dependiendo del nombre del modelo, define un espacio de búsqueda de hiperparámetros específicos \n",
    "    y utiliza Optuna para encontrar la mejor combinación que maximice la precisión (accuracy).\n",
    "\n",
    "    Modelos soportados:\n",
    "    - AdaBoost\n",
    "    - XGBoost\n",
    "    - LightGBM\n",
    "    - CatBoost\n",
    "    - RandomForest\n",
    "\n",
    "    Args:\n",
    "        nombre_modelo (str): Nombre del modelo a optimizar. Debe ser uno de los modelos soportados.\n",
    "        X_train (np.ndarray or pd.DataFrame): Conjunto de entrenamiento (features).\n",
    "        y_train (np.ndarray or pd.Series): Conjunto de entrenamiento (target).\n",
    "\n",
    "    Returns:\n",
    "        dict: Diccionario con los mejores hiperparámetros encontrados por Optuna.\n",
    "    \"\"\"\n",
    "    def objetivo(trial):\n",
    "        if nombre_modelo == 'AdaBoost':\n",
    "            params = {\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 1.0),\n",
    "                'random_state': 42\n",
    "            }\n",
    "            modelo = AdaBoostClassifier(**params)\n",
    "\n",
    "        elif nombre_modelo == 'XGBoost':\n",
    "            params = {\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 100, 300),\n",
    "                'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "                'eval_metric': 'logloss',\n",
    "                'random_state': 42\n",
    "            }\n",
    "            modelo = XGBClassifier(**params)\n",
    "\n",
    "        elif nombre_modelo == 'LightGBM':\n",
    "            params = {\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 100, 300),\n",
    "                'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "                'random_state': 42\n",
    "            }\n",
    "            modelo = LGBMClassifier(**params, verbosity = -1)\n",
    "\n",
    "        elif nombre_modelo == 'CatBoost':\n",
    "            params = {\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 100, 300),\n",
    "                'depth': trial.suggest_int('depth', 3, 10),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "                'verbose': 0,\n",
    "                'random_state': 42\n",
    "            }\n",
    "            modelo = CatBoostClassifier(**params)\n",
    "\n",
    "        elif nombre_modelo == 'RandomForest':\n",
    "            params = {\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 100, 300),\n",
    "                'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "                'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "                'random_state': 42\n",
    "            }\n",
    "            modelo = RandomForestClassifier(**params)\n",
    "\n",
    "        score = cross_val_score(modelo, X_train, y_train, cv=3, scoring='accuracy', error_score='raise').mean()\n",
    "        return score\n",
    "\n",
    "    estudio = optuna.create_study(direction='maximize')\n",
    "    estudio.optimize(objetivo, n_trials=20, timeout=300)\n",
    "    print(f\"[INFO] Mejor conjunto de hiperparámetros para {nombre_modelo}: {estudio.best_params}\")\n",
    "    return estudio.best_params\n",
    "\n",
    "def entrenar_modelo(nombre_modelo, params, X_train, y_train):\n",
    "    \"\"\"\n",
    "    Entrena un modelo de clasificación utilizando los hiperparámetros especificados.\n",
    "\n",
    "    Se selecciona e instancia el modelo correspondiente, se ajusta con los datos de entrenamiento,\n",
    "    y se mide el tiempo total de entrenamiento.\n",
    "\n",
    "    Args:\n",
    "        nombre_modelo (str): Nombre del modelo a entrenar.\n",
    "        params (dict): Diccionario con los hiperparámetros optimizados.\n",
    "        X_train (np.ndarray or pd.DataFrame): Conjunto de entrenamiento (features).\n",
    "        y_train (np.ndarray or pd.Series): Conjunto de entrenamiento (target).\n",
    "\n",
    "    Returns:\n",
    "        Tuple[object, float]: \n",
    "            - El modelo entrenado.\n",
    "            - Tiempo de entrenamiento en segundos.\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    if nombre_modelo == 'AdaBoost':\n",
    "        modelo = AdaBoostClassifier(**params)\n",
    "    elif nombre_modelo == 'XGBoost':\n",
    "        params['eval_metric'] = 'logloss'\n",
    "        modelo = XGBClassifier(**params)\n",
    "    elif nombre_modelo == 'LightGBM':\n",
    "        modelo = LGBMClassifier(**params)\n",
    "    elif nombre_modelo == 'CatBoost':\n",
    "        modelo = CatBoostClassifier(**params, verbose=0)\n",
    "    elif nombre_modelo == 'RandomForest':\n",
    "        modelo = RandomForestClassifier(**params)\n",
    "\n",
    "    modelo.fit(X_train, y_train)\n",
    "    duracion = time.time() - start\n",
    "    return modelo, duracion\n",
    "\n",
    "def evaluar_modelo(modelo, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evalúa un modelo de clasificación en el conjunto de prueba.\n",
    "\n",
    "    Calcula el accuracy y la matriz de confusión a partir de las predicciones del modelo.\n",
    "\n",
    "    Args:\n",
    "        modelo (object): Modelo previamente entrenado con método `.predict()`.\n",
    "        X_test (np.ndarray or pd.DataFrame): Conjunto de prueba (features).\n",
    "        y_test (np.ndarray or pd.Series): Conjunto de prueba (target).\n",
    "\n",
    "    Returns:\n",
    "        Tuple[float, np.ndarray]: \n",
    "            - Accuracy del modelo en test.\n",
    "            - Matriz de confusión (2x2).\n",
    "    \"\"\"\n",
    "    y_pred = modelo.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    matriz = confusion_matrix(y_test, y_pred)\n",
    "    return acc, matriz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9af0ee4",
   "metadata": {},
   "source": [
    "**Bloque 3:** Visualización de resultados.\n",
    "\n",
    "- **`graficar_resultados()`** \n",
    "Genera gráficos comparativos de accuracy y tiempo de entrenamiento para todos los modelos.\n",
    "\n",
    "- **`graficar_matrices_confusion()`** \n",
    "Muestra matrices de confusión en formato de mapas de calor para cada modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d11aae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graficar_resultados(resultados):\n",
    "    \"\"\"\n",
    "    Genera gráficos de barras para visualizar el rendimiento de distintos modelos de clasificación.\n",
    "\n",
    "    Se generan tres gráficos:\n",
    "    - Accuracy por modelo.\n",
    "    - Tiempo de entrenamiento por modelo (en segundos).\n",
    "    - Tiempo total por modelo (optimización + entrenamiento, en segundos).\n",
    "\n",
    "    Args:\n",
    "        resultados (dict): Diccionario donde las claves son nombres de modelos y los valores son listas con:\n",
    "                           [accuracy, tiempo_entrenamiento, tiempo_optimizacion, tiempo_total].\n",
    "\n",
    "    Returns:\n",
    "        None. Muestra las figuras usando matplotlib.\n",
    "    \"\"\"\n",
    "    df_resultados = pd.DataFrame(resultados).T.reset_index()\n",
    "    df_resultados.columns = ['Modelo', 'Accuracy', 'Tiempo_Entrenamiento', 'Tiempo_Optimizacion', 'Tiempo_Total']\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(18, 5))  # Una fila, tres columnas\n",
    "\n",
    "    sns.barplot(x='Modelo', y='Accuracy', data=df_resultados, ax=axs[0], color='Orange')\n",
    "    axs[0].set_ylabel('Accuracy')\n",
    "    axs[0].set_title('Accuracy por Modelo')\n",
    "    axs[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "    sns.barplot(x='Modelo', y='Tiempo_Entrenamiento', data=df_resultados, ax=axs[1], color='Green')\n",
    "    axs[1].set_ylabel('Tiempo (s)')\n",
    "    axs[1].set_title('Tiempo de Entrenamiento')\n",
    "    axs[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "    sns.barplot(x='Modelo', y='Tiempo_Total', data=df_resultados, ax=axs[2], color='Blue')\n",
    "    axs[2].set_ylabel('Tiempo (s)')\n",
    "    axs[2].set_title('Tiempo Total (Opt + Entrenamiento)')\n",
    "    axs[2].tick_params(axis='x', rotation=45)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def graficar_matrices_confusion(matrices, nombres_modelos):\n",
    "    \"\"\"\n",
    "    Visualiza las matrices de confusión de distintos modelos como mapas de calor (heatmaps).\n",
    "\n",
    "    Dibuja hasta 5 subplots organizados en una grilla (2 filas x 3 columnas), uno para cada modelo. \n",
    "    Si hay menos de 6 modelos, se deja vacío el subplot restante para mantener la simetría.\n",
    "\n",
    "    Args:\n",
    "        matrices (list of np.ndarray): Lista de matrices de confusión, una por modelo.\n",
    "        nombres_modelos (list of str): Lista con los nombres de los modelos, en el mismo orden que las matrices.\n",
    "\n",
    "    Returns:\n",
    "        None. Muestra las figuras usando matplotlib.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(15, 10))\n",
    "    gs = GridSpec(2, 3, figure=fig)\n",
    "\n",
    "    # Primera fila: 3 gráficos\n",
    "    axs = [fig.add_subplot(gs[0, i]) for i in range(3)]\n",
    "    # Segunda fila: 2 gráficos en las dos primeras columnas\n",
    "    axs += [fig.add_subplot(gs[1, i]) for i in range(2)]\n",
    "\n",
    "    for i, (nombre, matriz) in enumerate(zip(nombres_modelos, matrices)):\n",
    "        sns.heatmap(matriz, annot=True, fmt='d', cmap='Blues', ax=axs[i])\n",
    "        axs[i].set_title(nombre)\n",
    "        axs[i].set_xlabel('Predicción')\n",
    "        axs[i].set_ylabel('Real')\n",
    "\n",
    "    # Eliminar ejes del subplot vacío (última posición)\n",
    "    fig.delaxes(fig.add_subplot(gs[1, 2]))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be29db96",
   "metadata": {},
   "source": [
    "**Bloque 4:** Función de ejecución del código.\n",
    "\n",
    "- **`main()`** \n",
    "Ejecuta todo el flujo: carga, preprocesamiento, optimización, entrenamiento, evaluación, visualización y selección del mejor modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c1f3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Función principal que ejecuta todo el flujo del proyecto de clasificación con métodos de ensamble.\n",
    "\n",
    "    Realiza las siguientes tareas:\n",
    "    1. Carga y limpieza del dataset 'Adult Income' desde OpenML.\n",
    "    2. Preprocesamiento de variables (imputación, codificación ordinal y división en train/test).\n",
    "    3. Optimización de hiperparámetros para cinco modelos: AdaBoost, XGBoost, LightGBM, CatBoost y RandomForest.\n",
    "    4. Medición del tiempo requerido para optimización y entrenamiento de cada modelo.\n",
    "    5. Entrenamiento de cada modelo con los mejores hiperparámetros encontrados.\n",
    "    6. Evaluación de cada modelo con métricas de precisión (accuracy) y matriz de confusión.\n",
    "    7. Visualización comparativa del rendimiento de los modelos en términos de accuracy, tiempo de entrenamiento, optimización y total.\n",
    "    8. Impresión de resultados finales y selección del mejor modelo para producción.\n",
    "\n",
    "    Returns:\n",
    "        None. Ejecuta todo el pipeline de principio a fin y muestra resultados por consola y gráficos.\n",
    "    \"\"\"\n",
    "    df = cargar_y_analizar_datos()\n",
    "    X_train, X_test, y_train, y_test = preprocesar_datos(df)\n",
    "\n",
    "    modelos = ['AdaBoost', 'XGBoost', 'LightGBM', 'CatBoost', 'RandomForest']\n",
    "    resultados = {}\n",
    "    matrices = []\n",
    "\n",
    "    for modelo in modelos:\n",
    "        print(f\"\\nOptimizando hiperparámetros para {modelo}...\")\n",
    "        inicio_opt = time.time()\n",
    "        params = optimizar_modelo(modelo, X_train, y_train)\n",
    "        tiempo_opt = time.time() - inicio_opt\n",
    "\n",
    "        print(f\"Entrenando modelo {modelo}...\")\n",
    "        modelo_entrenado, tiempo_ent = entrenar_modelo(modelo, params, X_train, y_train)\n",
    "\n",
    "        tiempo_total = tiempo_opt + tiempo_ent\n",
    "\n",
    "        acc, matriz = evaluar_modelo(modelo_entrenado, X_test, y_test)\n",
    "\n",
    "        resultados[modelo] = [acc, tiempo_ent, tiempo_opt, tiempo_total]\n",
    "        matrices.append(matriz)\n",
    "\n",
    "    # Prepara los datos para tabulate\n",
    "    tabla = []\n",
    "    for modelo, (acc, tiempo_ent, tiempo_opt, tiempo_total) in resultados.items():\n",
    "        tabla.append([modelo, f\"{acc:.4f}\", f\"{tiempo_ent:.2f} s\", f\"{tiempo_opt:.2f} s\", f\"{tiempo_total:.2f} s\"])\n",
    "\n",
    "    # Define los encabezados\n",
    "    headers = [\"Modelo\", \"Accuracy\", \"Tiempo Entrenamiento\", \"Tiempo Optimización\", \"Tiempo Total\"]\n",
    "\n",
    "    print(\"\\nResultados finales:\")\n",
    "    print(tabulate(tabla, headers=headers, tablefmt=\"grid\"))\n",
    "\n",
    "    graficar_resultados(resultados)\n",
    "    graficar_matrices_confusion(matrices, modelos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07694c0a",
   "metadata": {},
   "source": [
    "# 4. Visualización de resultados\n",
    "\n",
    "Se muestran los resultados obtenidos a partir de la ejecución de la funcion **main()**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b5532c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7fe5fa",
   "metadata": {},
   "source": [
    "# Análisis de resultados y reflexiones finales.\n",
    "\n",
    "---\n",
    "\n",
    ">**NOTA**: Los resultados aca expuestos y analizados fueron sacados de una ejecución x, por lo que, al momento de ejecutar nuevamente el código los resultados podrían variar, principalmente en cuál es el mejor modelo, esto debido a que como se puede apreciar, tanto XGBoost como LightGBM y CatBoost tienen valores muy similares de accuracy. La única diferencia es que Catboost tiene un peor tiempo de ejecución, teniendo en cuenta los tiempos de optimización y de entrenamiento. En el caso de la ejecución usada en este análisis, XGBoost tuvo el mejor accuracy.\n",
    "\n",
    "---\n",
    "\n",
    "## Comparación de resultados entre modelos\n",
    "\n",
    "### Comparación de accuracy:\n",
    "\n",
    "- Los modelos de Boosting (XGBoost, LightGBM, CatBoost) alcanzan accuracies muy similares, en torno a 0.868, ligeramente superiores a los métodos clásicos como AdaBoost y RandomForest.\n",
    "- Entre ellos, XGBoost es el que logró la mayor precisión, aunque por muy poco margen.\n",
    "\n",
    "### Tiempos de optimización y entrenamiento:\n",
    "\n",
    "- Aquí la diferencia es más notable: XGBoost y LightGBM fueron los mas rápidos, luego CatBoost, y finalmente los métodos tradicionales que tardan varios segundos.\n",
    "- Esto indica que XGBoost y LightGBM no solo son precisos, sino también muy eficientes en términos de tiempo.\n",
    "\n",
    "### Preprocesamiento y codificación:\n",
    "\n",
    "- Se aplicó una codificación ordinal a las variables categóricas, compatible con todos los modelos.\n",
    "- Modelos como CatBoost pueden manejar variables categóricas de forma nativa, pero se decidió codificar todas las variables para tener uniformidad y comparabilidad.\n",
    "\n",
    "### Optimización hiperparamétrica:\n",
    "\n",
    "- Se utilizó Optuna para buscar los mejores hiperparámetros, con 20 trials y validación cruzada, asegurando que los modelos estén optimizados para el dataset.\n",
    "- Esto fortalece la validez de las comparaciones.\n",
    "\n",
    "---\n",
    "\n",
    "## ¿Cuál modelo se usaría en producción?\n",
    "\n",
    "Basándonos en la combinación de alta precisión y rapidez en entrenamiento, **XGBoost** es el mejor candidato para producción en este caso.\n",
    "\n",
    "### Justificación:\n",
    "\n",
    "- Máxima precisión alcanzada: 0.8702, aunque por un margen pequeño, supera al resto de modelos.\n",
    "- Alta eficiencia: Entrenamiento rápido, apenas por detrás de LightGBM, con excelente balance entre tiempo y rendimiento.\n",
    "- Estabilidad y robustez: No presentó advertencias durante la optimización, a diferencia de LightGBM (e.g. \"No further splits with positive gain\").\n",
    "- Amplia adopción en la industria: XGBoost es altamente probado, con buena documentación, soporte y escalabilidad.\n",
    "- Flexible y configurable: Permite ajustes finos para tareas específicas y se integra fácilmente en entornos productivos.\n",
    "\n",
    "### Comparación con otros:\n",
    "\n",
    "- LightGBM es un poco peor en rendimiento, pero levemente mas rápido.\n",
    "- CatBoost es potente y maneja categóricas sin codificación previa, pero aquí su tiempo es mayor y la ganancia de accuracy no justifica la mayor latencia.\n",
    "- RandomForest y AdaBoost quedan rezagados en precisión y velocidad.\n",
    "\n",
    "---\n",
    "\n",
    "## Reflexiones finales\n",
    "\n",
    "En este trabajo se comprobó que los modelos de Boosting, especialmente XGBoost y LightGBM, ofrecen un rendimiento superior en términos de precisión y tiempo de entrenamiento frente a métodos tradicionales como AdaBoost y Random Forest. La cuidadosa optimización de hiperparámetros mediante Optuna, junto con un preprocesamiento consistente de los datos, fue fundamental para lograr resultados robustos y comparables entre modelos.\n",
    "\n",
    "Para aplicaciones en producción, es crucial considerar no solo la precisión sino también la eficiencia computacional y la escalabilidad. XGBoost destacó como la mejor opción en este caso, combinando alta exactitud con tiempos de entrenamiento muy bajos, lo que facilita su integración en pipelines reales donde la rapidez y la confiabilidad son claves. Además, este análisis resalta la importancia de adaptar el modelo al contexto y las necesidades específicas del proyecto.\n",
    "\n",
    "### Consideraciones a tomar en cuenta sobre los datos\n",
    "\n",
    "Este análisis parte del dataset Adult Income, con sus características específicas.\n",
    "- En entornos reales, también se deben evaluar:\n",
    "    - Robustez del modelo ante datos nuevos o no vistos.\n",
    "    - Facilidad de integración y despliegue.\n",
    "    - Interpretabilidad (LightGBM puede ser menos interpretable que RandomForest, pero esto puede mitigarse con técnicas como SHAP).\n",
    "    - Costos computacionales y hardware disponible."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
