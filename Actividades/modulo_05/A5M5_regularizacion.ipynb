{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a273ce4e",
   "metadata": {},
   "source": [
    "# Actividad 5:\n",
    "# Aplicación de Regularización en Modelo de Regresión\n",
    "\n",
    "## Objetivo\n",
    "Aplicar técnicas de regularización (Lasso, Ridge, Elastic Net) en un modelo re regresión y comparar su rendimiento en términos generalización y selección de características.\n",
    "\n",
    "**Datasets utilizados:**  \n",
    "`Adult Income`\n",
    "\n",
    "---\n",
    "\n",
    "### Estructura del Notebook:\n",
    "1. Metodología.\n",
    "2. Configuración del entorno.\n",
    "3. Definicion de funciones.\n",
    "4. Uso de funciones y resultados.\n",
    "5. Análisis de los resultados y reflexiones finales.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdefb25",
   "metadata": {},
   "source": [
    "## 1. Metodología\n",
    "\n",
    "### Flujo de trabajo\n",
    "\n",
    "1. **Carga y preprocesamiento de datos:**\n",
    "  - Se carga el dataset **Adult Income** y se hace una limpieza de datos, utilizando un 5% del total de datos como umbral para borrar o imputar los datos faltantes o que presenten problemas.\n",
    "\n",
    "2. **Evaluación y análisis:**\n",
    "  - Técnicas utilizadss:\n",
    "    - Lasso.\n",
    "    - Ridge.\n",
    "    - Elastic Net.\n",
    "  - Se uso además optimización con optuna para encontrar los mejores hiperparametros de cada técnica.\n",
    "\n",
    "  - Métricas empleadas:\n",
    "    - MSE\n",
    "    - RMSE\n",
    "\n",
    "3. **Visualización de resultados:**\n",
    "  - Tabla resumen de las mejores variables de cada modelo.\n",
    "  - Tabla comparativa de las tres técnicas con MSE y RMSE.\n",
    "  - Gráficos de top 10 variables por modelo con sus coeficientes.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0800f4",
   "metadata": {},
   "source": [
    "# 2. Configuración del entorno\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af5f9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import optuna\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# Silenciar logs de Optuna y warnings generales\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Estilo gráfico y opciones de pandas\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('Set2')\n",
    "pd.set_option('display.precision', 4)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2abed6",
   "metadata": {},
   "source": [
    "# 3. Definición de funciones\n",
    "\n",
    "> **Nota:** Para mejor comprensión de las funciones y su utilidad, esta sección se divide en bloques, en donde cada uno responde a una parte diferente de la metodología de trabajo. \n",
    "\n",
    "---\n",
    "\n",
    "**Bloque 1:** Carga y preprocesamiento de datos y entrenamiento de modelos.\n",
    "\n",
    "- **`carga_y_preprocesamiento()`** \n",
    "Carga y prepara el dataset Adult Income, manejando valores faltantes, codificando y escalando variables, y dividiendo en train/test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b3a000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def carga_y_preprocesamiento():\n",
    "    \"\"\"\n",
    "    Carga y preprocesa el dataset 'Adult Income' de OpenML para clasificación binaria.\n",
    "\n",
    "    Pasos realizados:\n",
    "    - Carga el dataset 'adult' versión 2.\n",
    "    - Reemplaza valores '?' por NaN para el manejo de datos faltantes.\n",
    "    - Analiza y reporta porcentaje de valores faltantes por columna.\n",
    "    - Elimina columnas con más del 5% de datos faltantes.\n",
    "    - Imputa valores faltantes en columnas numéricas con la mediana.\n",
    "    - Imputa valores faltantes en columnas categóricas con la moda.\n",
    "    - Codifica la variable objetivo 'class' a binaria: 1 si ingreso >50K, 0 en caso contrario.\n",
    "    - Divide el dataset en conjuntos de entrenamiento (70%) y prueba (30%), manteniendo la proporción de clases (stratify).\n",
    "    - Aplica preprocesamiento con pipelines:\n",
    "        * Imputación y escalado (StandardScaler) para variables numéricas.\n",
    "        * Codificación One-Hot para variables categóricas.\n",
    "    - Retorna los datos preprocesados para entrenamiento y prueba.\n",
    "\n",
    "    Returns:\n",
    "        X_train_prep (np.ndarray): Matriz preprocesada de características para entrenamiento.\n",
    "        X_test_prep (np.ndarray): Matriz preprocesada de características para prueba.\n",
    "        y_train (pd.Series): Vector objetivo binario para entrenamiento.\n",
    "        y_test (pd.Series): Vector objetivo binario para prueba.\n",
    "\n",
    "    \"\"\"\n",
    "    # Cargar dataset\n",
    "    adult = fetch_openml(\"adult\", version=2, as_frame=True)\n",
    "    df = adult.frame\n",
    "    \n",
    "    print(\"Distribución de clases original:\")\n",
    "    print(df['class'].value_counts(normalize=True))\n",
    "    \n",
    "    # Manejar valores faltantes\n",
    "    df.replace('?', np.nan, inplace=True)\n",
    "    \n",
    "    # Analizar valores faltantes\n",
    "    missing_percent = df.isna().mean().sort_values(ascending=False)\n",
    "    print(\"\\nPorcentaje de valores faltantes por columna:\")\n",
    "    print(missing_percent[missing_percent > 0])\n",
    "    \n",
    "    # Eliminar columnas con >10% de valores faltantes\n",
    "    threshold = 0.1\n",
    "    cols_to_drop = missing_percent[missing_percent > threshold].index\n",
    "    df.drop(cols_to_drop, axis=1, inplace=True)\n",
    "    \n",
    "    # Variable objetivo binaria\n",
    "    y = (df['class'] == '>50K').astype(int)\n",
    "    X = df.drop('class', axis=1)\n",
    "    \n",
    "    # Dividir en train/test (70/30)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Preprocesamiento\n",
    "    num_cols = X_train.select_dtypes(include=['int', 'float']).columns\n",
    "    cat_cols = X_train.select_dtypes(include=['object', 'category']).columns\n",
    "    \n",
    "    # Crear pipeline para variables numéricas\n",
    "    num_pipeline = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    # Codificación para variables categóricas\n",
    "    cat_pipeline = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "    ])\n",
    "\n",
    "    # ColumnTransformer combinando ambos\n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        ('num', num_pipeline, num_cols),\n",
    "        ('cat', cat_pipeline, cat_cols)\n",
    "    ])\n",
    "\n",
    "    X_train_prep = preprocessor.fit_transform(X_train)\n",
    "    X_test_prep = preprocessor.transform(X_test)\n",
    "\n",
    "    # Obtener nombres de las features tras preprocesamiento\n",
    "    # Nombres numéricos (sin cambio)\n",
    "    feature_names_num = list(num_cols)\n",
    "    # Nombres categóricos (OneHotEncoder)\n",
    "    cat_encoder = preprocessor.named_transformers_['cat']['encoder']\n",
    "    feature_names_cat = list(cat_encoder.get_feature_names_out(cat_cols))\n",
    "    # Concatenar nombres\n",
    "    feature_names = feature_names_num + feature_names_cat\n",
    "    \n",
    "    print(f\"\\nDimensiones después de preprocesamiento:\")\n",
    "    print(f\"Train: {X_train_prep.shape}, Test: {X_test_prep.shape}\")\n",
    "    \n",
    "    return X_train_prep, X_test_prep, y_train, y_test, feature_names, preprocessor # se guarda preprocessor por si se usara a futuro en un entorno de producción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2be8b7a",
   "metadata": {},
   "source": [
    "**Bloque 2:** Optimización y evaluación de las tres técnicas de regularización.\n",
    "\n",
    "- **`optimizar_y_evaluar()`** \n",
    "Optimiza con optuna cada técnica (Lasso, Ridge y ElasticNet) y entrena cada modelos con los mejores hiperparametros obtenidos de optuna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36366269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizar_y_evaluar(X_train, y_train, X_test, y_test, feature_names, n_trials=10):\n",
    "\n",
    "    def objective(trial, model_name):\n",
    "        if model_name == 'Lasso':\n",
    "            alpha = trial.suggest_float('alpha', 1e-3, 1)\n",
    "            model = Lasso(alpha=alpha, max_iter=10000)\n",
    "        elif model_name == 'Ridge':\n",
    "            alpha = trial.suggest_float('alpha', 1e-3, 1)\n",
    "            model = Ridge(alpha=alpha, max_iter=10000)\n",
    "        else:  # ElasticNet\n",
    "            alpha = trial.suggest_float('alpha', 1e-3, 1)\n",
    "            l1_ratio = trial.suggest_float('l1_ratio', 0.0, 1.0)\n",
    "            model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, max_iter=10000)\n",
    "\n",
    "        score = -cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_squared_error').mean()\n",
    "        return score\n",
    "\n",
    "    resultados = {}\n",
    "\n",
    "    for modelo_nombre in ['Lasso', 'Ridge', 'ElasticNet']:\n",
    "        print(f\"\\nOptimizando {modelo_nombre}...\")\n",
    "        study = optuna.create_study(direction='minimize')\n",
    "        func_obj = lambda trial: objective(trial, modelo_nombre)\n",
    "        study.optimize(func_obj, n_trials=n_trials)\n",
    "        \n",
    "        print(f\"Mejores parámetros para {modelo_nombre}: {study.best_params}\")\n",
    "        \n",
    "        # Entrenar con mejores hiperparámetros\n",
    "        if modelo_nombre == 'Lasso':\n",
    "            model = Lasso(alpha=study.best_params['alpha'], max_iter=10000)\n",
    "        elif modelo_nombre == 'Ridge':\n",
    "            model = Ridge(alpha=study.best_params['alpha'], max_iter=10000)\n",
    "        else:\n",
    "            model = ElasticNet(alpha=study.best_params['alpha'],\n",
    "                               l1_ratio=study.best_params['l1_ratio'], max_iter=10000)\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        coefs = pd.Series(model.coef_, index=feature_names)\n",
    "        coefs_importantes = coefs.abs().sort_values(ascending=False).head(10)\n",
    "        \n",
    "        print(f\"MSE test {modelo_nombre}: {mse:.4f}\")\n",
    "        print(\"Top 10 variables importantes:\")\n",
    "        print(coefs_importantes)\n",
    "        \n",
    "        resultados[modelo_nombre] = {\n",
    "            'mse': mse,\n",
    "            'coeficientes': coefs,\n",
    "            'best_params': study.best_params\n",
    "        }\n",
    "    \n",
    "    return resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3391d9b",
   "metadata": {},
   "source": [
    "**Bloque 3:** Visualización de resultados.\n",
    "\n",
    "- **`mostrar_tabla_mse()`** \n",
    "Muestra una tabla comparativa del MSE y adicional el RMSE de cada técnica.\n",
    "\n",
    "- **`mostrar_tabla_hiperparametros()`** \n",
    "Muestra una tabla de los mejores hiperparámetros para cada modelo (alpha para Lasso y Ridge, alpha y l1_ratio para ElasticNet).\n",
    "\n",
    "- **`plot_top_10_variables()`** \n",
    "Grafica las 10 variables mas importantes por cada modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870790b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostrar_tabla_mse(resultados):\n",
    "    \"\"\"\n",
    "    Genera y muestra una tabla comparativa de MSE y RMSE para los modelos evaluados.\n",
    "    \n",
    "    Parámetros:\n",
    "        resultados (dict): Diccionario retornado por `optimizar_y_evaluar`\n",
    "    \"\"\"\n",
    "    tabla = []\n",
    "\n",
    "    for modelo, valores in resultados.items():\n",
    "        mse = valores['mse']\n",
    "        rmse = np.sqrt(mse)\n",
    "        tabla.append({'Modelo': modelo, 'MSE': mse, 'RMSE': rmse})\n",
    "\n",
    "    df_resultados = pd.DataFrame(tabla).set_index(\"Modelo\")\n",
    "    print(\"\\nResumen de errores (MSE y RMSE):\")\n",
    "    display(df_resultados.round(4))\n",
    "    \n",
    "    return df_resultados\n",
    "\n",
    "def mostrar_tabla_hiperparametros(resultados):\n",
    "    tabla = []\n",
    "    for modelo, valores in resultados.items():\n",
    "        params = valores['best_params']\n",
    "        fila = {'Modelo': modelo}\n",
    "        fila.update(params)  # Añade cada hiperparámetro como columna\n",
    "        tabla.append(fila)\n",
    "    \n",
    "    df_hiper = pd.DataFrame(tabla).set_index(\"Modelo\")\n",
    "    print(\"\\nResumen de mejores hiperparámetros:\")\n",
    "    display(df_hiper.round(6))\n",
    "    \n",
    "    return df_hiper\n",
    "\n",
    "\n",
    "def plot_top_10_variables(resultados):\n",
    "    \"\"\"\n",
    "    Genera una figura con 3 subgráficos, cada uno mostrando las 10 variables\n",
    "    más importantes (por valor absoluto del coeficiente) para Lasso, Ridge y ElasticNet.\n",
    "    \n",
    "    Parámetros:\n",
    "        resultados (dict): Diccionario retornado por `optimizar_y_evaluar`\n",
    "    \"\"\"\n",
    "    modelos = ['Lasso', 'Ridge', 'ElasticNet']\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "\n",
    "    for i, modelo in enumerate(modelos):\n",
    "        coefs = resultados[modelo]['coeficientes']\n",
    "        top10 = coefs.abs().sort_values(ascending=False).head(10)\n",
    "        top10.plot(kind='barh', ax=axes[i], color='purple', edgecolor='black')\n",
    "        axes[i].set_title(f'{modelo}: Top 10 variables')\n",
    "        axes[i].invert_yaxis()\n",
    "        axes[i].set_xlabel('Importancia (|coef|)')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72831410",
   "metadata": {},
   "source": [
    "**Bloque 4:** Función de ejecución del código.\n",
    "\n",
    "- **`main()`** \n",
    "Ejecuta todo el flujo: carga datos, optimiza, entrena y evalúa los tres modelos de técnicas de regularización, y muestra los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a21520e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    X_train_prep, X_test_prep, y_train, y_test, feature_names, preprocessor = carga_y_preprocesamiento()\n",
    "\n",
    "    resultados = optimizar_y_evaluar(X_train_prep, y_train, X_test_prep, y_test, feature_names, n_trials=20)\n",
    "\n",
    "    # Variables eliminadas por Lasso\n",
    "    coefs_lasso = resultados['Lasso']['coeficientes']\n",
    "    eliminadas_lasso = coefs_lasso[coefs_lasso == 0].index.tolist()\n",
    "    print(f\"\\nNúmero de variables eliminadas por Lasso: {len(eliminadas_lasso)}\")\n",
    "    print(pd.DataFrame({'Variable eliminada por Lasso': eliminadas_lasso}))\n",
    "\n",
    "    # Variables eliminadas por ElasticNet\n",
    "    coefs_enet = resultados['ElasticNet']['coeficientes']\n",
    "    eliminadas_enet = coefs_enet[coefs_enet == 0].index.tolist()\n",
    "    print(f\"\\nNúmero de variables eliminadas por ElasticNet: {len(eliminadas_enet)}\")\n",
    "    print(pd.DataFrame({'Variable eliminada por ElasticNet': eliminadas_enet}))\n",
    "\n",
    "    tabla_hp = mostrar_tabla_hiperparametros(resultados)\n",
    "    tabla_mse = mostrar_tabla_mse(resultados)\n",
    "\n",
    "    plot_top_10_variables(resultados)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4f60ff",
   "metadata": {},
   "source": [
    "# 4. Visualización de resultados\n",
    "\n",
    "Se muestran los resultados obtenidos a partir de la ejecución de la funcion **main()**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58718bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31998ba",
   "metadata": {},
   "source": [
    "# Análisis de Técnicas de Regularización\n",
    "\n",
    "> **Nota:** Los resultados expuestos se basan en una ejecución específica. Al re-ejecutar el código, los valores podrían variar ligeramente, ya que la optimización se realiza mediante búsquedas aleatorias (Optuna). Las diferencias pueden afectar cuál modelo obtiene el menor error o cuántas variables son eliminadas, especialmente entre Lasso y ElasticNet.\n",
    "\n",
    "## ¿Cuál de las técnicas de regularización (Lasso, Ridge o ElasticNet) fue más efectiva para este conjunto de datos?\n",
    "\n",
    "En términos de rendimiento en el conjunto de test, el modelo **Ridge** obtuvo el menor error cuadrático medio (MSE = **0.1158**), seguido por **ElasticNet** (MSE = **0.1172**) y finalmente **Lasso** (MSE = **0.1211**). Esto sugiere que:\n",
    "\n",
    "- **Ridge** fue el más efectivo, logrando el mejor desempeño general.\n",
    "- **ElasticNet** tuvo un rendimiento competitivo, combinando las fortalezas de Lasso y Ridge.\n",
    "- **Lasso**, aunque con mayor MSE, simplificó fuertemente el modelo eliminando muchas variables.\n",
    "\n",
    "| Modelo      | MSE     | RMSE   |\n",
    "|-------------|---------|--------|\n",
    "| Lasso       | 0.1211  | 0.3479 |\n",
    "| Ridge       | 0.1158  | 0.3403 |\n",
    "| ElasticNet  | 0.1172  | 0.3423 |\n",
    "\n",
    "---\n",
    "\n",
    "## ¿Qué variables fueron eliminadas por Lasso y ElasticNet, y por qué?\n",
    "\n",
    "### Lasso eliminó **98** de las 105 variables (~93.3%)\n",
    "Esto incluye principalmente:\n",
    "- Variables de `native-country` (ej.: Yugoslavia, Vietnam, Thailand).\n",
    "- Variables de `workclass` (ej.: Never-worked, Private, Local-gov).\n",
    "- Otras variables categóricas poco frecuentes o con baja correlación con el objetivo.\n",
    "\n",
    "### ElasticNet eliminó **75** variables (~71.4%)\n",
    "- Mantuvo más variables que Lasso, pero también eliminó muchas relacionadas con `native-country` y `workclass`.\n",
    "\n",
    "Esto se debe a que:\n",
    "- **Lasso** aplica una penalización L1, que fuerza a cero los coeficientes de variables menos relevantes.\n",
    "- **ElasticNet** también puede forzar coeficientes a cero, dependiendo del valor de `l1_ratio`.\n",
    "- Ambas técnicas ayudan a seleccionar un subconjunto más informativo de variables, especialmente útil en datasets con alta dimensionalidad tras one-hot encoding.\n",
    "\n",
    "> **Conclusión parcial:** Lasso y ElasticNet simplifican el modelo al eliminar variables irrelevantes, mejorando la interpretabilidad sin sacrificar demasiado rendimiento.\n",
    "\n",
    "---\n",
    "\n",
    "## ¿Cómo impactó la regularización en la complejidad del modelo y su capacidad para generalizar?\n",
    "\n",
    "### Reducción de complejidad:\n",
    "- Lasso redujo drásticamente el número de variables activas, facilitando la interpretación.\n",
    "- ElasticNet también redujo la complejidad, aunque en menor grado.\n",
    "- Ridge conservó todas las variables, pero limitó sus coeficientes para evitar sobreajuste.\n",
    "\n",
    "### Generalización:\n",
    "- La regularización ayudó a evitar el overfitting.\n",
    "- Ridge y ElasticNet lograron mejor MSE en test que Lasso, lo que indica mayor capacidad de generalización.\n",
    "\n",
    "### Interpretabilidad vs rendimiento:\n",
    "- Lasso ofrece el mejor compromiso en cuanto a interpretabilidad.\n",
    "- Ridge prioriza el rendimiento, ideal cuando la precisión es lo más importante.\n",
    "- ElasticNet se ubica en un punto intermedio, manteniendo buen rendimiento y cierta capacidad de simplificación.\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusión\n",
    "\n",
    "La regularización fue clave para manejar la alta dimensionalidad del dataset tras aplicar one-hot encoding.\n",
    "\n",
    "- **Ridge** fue el modelo con mejor rendimiento general.\n",
    "- **Lasso** destacó por su capacidad de reducir el número de variables a solo las más relevantes.\n",
    "- **ElasticNet** ofreció un equilibrio entre rendimiento y simplificación.\n",
    "\n",
    "Estas técnicas permitieron construir modelos más robustos y con mejor capacidad de generalización, siendo fundamentales en problemas con muchas variables y correlaciones entre ellas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
