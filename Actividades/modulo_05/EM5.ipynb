{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "324f10af",
   "metadata": {},
   "source": [
    "# Evaluación Modular:\n",
    "# Interpretabilidad de Scoring Crediticio\n",
    "\n",
    "## Objetivo\n",
    "Desarrollar un modelo predictivo para el scoring crediticio, evaluando su rendimiento y la capacidad de interpretación de sus decisiones. Los estudiantes implementarán un modelo de clasificación con regularización y emplearán técnicas de interpretabilidad como SHAP o LIME para explicar el comportamiento del modelo.\n",
    "\n",
    "**Datasets utilizados:**  \n",
    "`Credit`\n",
    "\n",
    "---\n",
    "\n",
    "### Estructura del Notebook:\n",
    "1. Metodología.\n",
    "2. Configuración del entorno.\n",
    "3. Definicion de funciones.\n",
    "4. Uso de funciones y resultados.\n",
    "5. Análisis de los resultados y reflexiones finales.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6361fe",
   "metadata": {},
   "source": [
    "## 1. Metodología\n",
    "\n",
    "### Flujo de trabajo\n",
    "\n",
    "1. **Carga y preprocesamiento de datos:**\n",
    "- Se trabaja con el dataset Creit. Se realiza limpieza de datos, incluyendo manejo y eliminación de outliers y escalado.\n",
    "\n",
    "2. **Entrenamiento y evaluación de modelos:**\n",
    "- Se aplican regresión Lasso y regresión Ridge. Los hiperparámetros se optimizan con Optuna usando validación cruzada.\n",
    "\n",
    "3. **Visualización e interpretación:**\n",
    "- Se comparan las métricas y coeficientes de ambos modelos con tablas resumen, ademas de gráficos de barras de importancia de variables y visualización con SHAP.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33f26b5",
   "metadata": {},
   "source": [
    "# 2. Configuración del entorno\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcacc821",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import shap\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_val_predict\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Silenciar logs de Optuna y warnings generales\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c7517a",
   "metadata": {},
   "source": [
    "# 3. Definición de funciones\n",
    "\n",
    "> **Nota:** Para mejor comprensión de las funciones y su utilidad, esta sección se divide en bloques, en donde cada uno responde a una parte diferente de la metodología de trabajo. \n",
    "\n",
    "---\n",
    "\n",
    "**Bloque 1:** Carga y preprocesamiento de datos y entrenamiento de modelos.\n",
    "\n",
    "- **`eliminar_outliers_filas()`** \n",
    "Elimina filas con valores extremos en variables críticas para evitar sesgos fuertes en el modelo.\n",
    "\n",
    "- **`aplicar_winsorize_iqr()`** \n",
    "Limita valores atípicos moderados en variables numéricas mediante winsorización basada en IQR, preservando la mayoría de los datos..\n",
    "\n",
    "- **`cargar_y_preprocesar_credit()`** \n",
    "Orquesta la carga del dataset, aplica las dos funciones anteriores y realiza un escalado de los datos para entregar un conjunto limpio y listo para modelado.\n",
    "\n",
    "---\n",
    "\n",
    "`Justificacion de la limpieza de datos:`\n",
    "\n",
    "La estrategia combinada de limpieza y escalado se fundamenta en las siguientes razones:\n",
    "\n",
    "- Eliminación de outliers extremos: Algunos valores muy alejados de la mayoría pueden distorsionar fuertemente la estimación del modelo y sesgar sus resultados. Por eso se eliminan filas con outliers críticos en variables clave, especialmente cuando estos valores son escasos pero con magnitudes muy elevadas.\n",
    "\n",
    "- Winsorización para atípicos moderados: Valores atípicos menos extremos, que podrían tener impacto pero no justificarían eliminación total, se ajustan con winsorización basada en el rango intercuartílico (IQR). Esto permite preservar la mayoría de la información, mitigando el efecto de estos valores sin perder datos.\n",
    "\n",
    "- Escalado de variables numéricas: Después de la limpieza, se aplica escalado estándar (o similar) para que todas las variables numéricas estén en una escala comparable. Esto es fundamental para modelos que dependen de magnitudes relativas o que incluyen regularización (como Lasso, Ridge o ElasticNet), ya que evita que variables con rangos amplios dominen el proceso de entrenamiento. Además, el escalado mejora la estabilidad numérica y la velocidad de convergencia.\n",
    "\n",
    "- Por qué no solo escalado: El escalado por sí solo no corrige la distorsión causada por outliers extremos. Estos valores siguen estando presentes y pueden afectar negativamente la capacidad del modelo para generalizar. Por lo tanto, la limpieza previa (eliminación y winsorización) asegura que los datos escalados sean representativos y no sesgados.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f948037a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_outliers_filas(df, columnas_objetivo, umbral=2):\n",
    "    \"\"\"\n",
    "    Elimina filas donde los valores en las columnas objetivo superan el umbral especificado.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame original.\n",
    "        columnas_objetivo (list): Lista de nombres de columnas numéricas a evaluar.\n",
    "        umbral (float): Valor límite para eliminar outliers.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame sin las filas consideradas outliers extremos.\n",
    "    \"\"\"\n",
    "    mascara_valida = np.ones(len(df), dtype=bool)\n",
    "    for columna in columnas_objetivo:\n",
    "        mascara_valida &= (df[columna] < umbral)\n",
    "    return df[mascara_valida].copy()\n",
    "\n",
    "def aplicar_winsorize_iqr(df, columnas_excluidas=[]):\n",
    "    \"\"\"\n",
    "    Aplica winsorización por IQR a las columnas numéricas del DataFrame (excepto las excluidas).\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame con datos numéricos.\n",
    "        columnas_excluidas (list): Lista de columnas que no se modificarán.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame con winsorización aplicada a columnas numéricas.\n",
    "    \"\"\"\n",
    "    df_wins = df.copy()\n",
    "    columnas_numericas = df_wins.select_dtypes(include=['float64', 'int64']).columns\n",
    "    columnas_a_modificar = [col for col in columnas_numericas if col not in columnas_excluidas]\n",
    "\n",
    "    for columna in columnas_a_modificar:\n",
    "        q1 = df_wins[columna].quantile(0.25)\n",
    "        q3 = df_wins[columna].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        limite_inferior = q1 - 1.5 * iqr\n",
    "        limite_superior = q3 + 1.5 * iqr\n",
    "        df_wins[columna] = df_wins[columna].clip(lower=limite_inferior, upper=limite_superior)\n",
    "\n",
    "    return df_wins\n",
    "\n",
    "def cargar_y_preprocesar_credit():\n",
    "    \"\"\"\n",
    "    Carga y preprocesa el dataset 'credit' de OpenML para clasificación binaria.\n",
    "\n",
    "    Pasos realizados:\n",
    "    - Carga del dataset 'credit'.\n",
    "    - Elimina outliers extremos por fila en columnas específicas.\n",
    "    - Aplica winsorización IQR al resto de columnas numéricas.\n",
    "    - Separa variables predictoras y objetivo ('SeriousDlqin2yrs').\n",
    "    - Convierte la variable objetivo a tipo entero.\n",
    "\n",
    "    Returns:\n",
    "        X (pd.DataFrame): Variables predictoras preprocesadas.\n",
    "        y (pd.Series): Variable objetivo binaria.\n",
    "    \"\"\"\n",
    "    dataset = fetch_openml('credit', version=1, as_frame=True)\n",
    "    df = dataset.frame\n",
    "\n",
    "    columnas_outliers = ['NumberOfTimes90DaysLate', 'NumberOfTime60-89DaysPastDueNotWorse']\n",
    "    df_filtrado = eliminar_outliers_filas(df, columnas_outliers, umbral=2)\n",
    "    df_winsorizado = aplicar_winsorize_iqr(df_filtrado, columnas_excluidas=columnas_outliers)\n",
    "\n",
    "    X = df_winsorizado.drop(columns='SeriousDlqin2yrs')\n",
    "    y = df_winsorizado['SeriousDlqin2yrs'].astype(int)\n",
    "\n",
    "    # Escalar solo columnas numéricas\n",
    "    columnas_numericas = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "    scaler = StandardScaler()\n",
    "    X[columnas_numericas] = scaler.fit_transform(X[columnas_numericas])\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8ac737",
   "metadata": {},
   "source": [
    "**Bloque 2:** Entrenamiento y optimización de modelos.\n",
    "\n",
    "- **`entrenar_y_optimizar_modelos()`** \n",
    "Entrena y optimiza mediante optuna modelos de regresión logística con penalización Lasso, Ridge y ElasticNet.\n",
    "\n",
    "---\n",
    "\n",
    "`Justificacion para el uso de StratifiedKFold como reemplazo de train_test_split:`\n",
    "\n",
    "No se realizó una división explícita de los datos en conjunto de entrenamiento y prueba (train_test_split) porque la validación cruzada estratificada ya cumple con ese propósito de forma más completa. Técnicamente, cada iteración de StratifiedKFold realiza una partición del conjunto en una combinación de datos de entrenamiento y validación, de modo que cada observación del dataset es utilizada tanto para entrenar como para validar el modelo, pero nunca en la misma iteración.\n",
    "\n",
    "Esto proporciona una estimación del desempeño general del modelo que es menos sensible al azar que una sola división, reduciendo la varianza de la evaluación. Además:\n",
    "\n",
    "- Al no reservar explícitamente un conjunto de prueba, se aprovecha el 100% de los datos para la validación cruzada, maximizando la cantidad de datos usada para entrenar en cada pliegue.\n",
    "- En contextos donde la selección de modelos y la evaluación se realiza únicamente mediante validación cruzada, no es imprescindible separar un conjunto de test. Esta práctica es común y aceptada en tareas de exploración, análisis comparativo de modelos y optimización de hiperparámetros.\n",
    "\n",
    "Sin embargo, si el objetivo fuera reportar una métrica final para generalización fuera de muestra, especialmente en producción o publicación de resultados, se recomienda una división adicional (hold-out) como train/valid/test para evitar el \"data leakage\" indirecto por sobreajuste al proceso de validación cruzada.\n",
    "\n",
    "---\n",
    "\n",
    "`Justificacion para la elección de modelos:`\n",
    "\n",
    "Se optó por entrenar un modelo de Regresión Logística, ya que este permite aplicar de forma directa técnicas de regularización L1 (Lasso) y L2 (Ridge) mediante el parámetro penalty del estimador LogisticRegression en Scikit-learn.\n",
    "\n",
    "Esto permite mejorar la capacidad de generalización del modelo al reducir el sobreajuste (overfitting), especialmente en presencia de muchas variables o correlaciones. La regularización L1, en particular, también permite realizar una selección automática de variables, ya que puede forzar algunos coeficientes a ser exactamente cero.\n",
    "\n",
    "En cambio, Random Forest no permite aplicar regularización L1 o L2 de manera directa, dado que su funcionamiento se basa en la construcción de árboles de decisión, los cuales no involucran coeficientes que puedan ser penalizados en forma lineal. Por esta razón, la Regresión Logística fue la opción adecuada para cumplir con ambos requerimientos: entrenamiento del modelo y aplicación de técnicas de regularización.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced90a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar_y_optimizar_modelos(X, y, n_folds=5, n_trials=20):\n",
    "    \"\"\"\n",
    "    Entrena y optimiza modelos de regresión logística con Lasso, Ridge y Elastic Net usando Optuna.\n",
    "\n",
    "    Args:\n",
    "        X (pd.DataFrame): Variables predictoras.\n",
    "        y (pd.Series): Variable objetivo.\n",
    "        n_folds (int): Número de particiones para validación cruzada.\n",
    "        n_trials (int): Número de iteraciones para Optuna.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Tabla con métricas de evaluación para cada modelo.\n",
    "        dict: Diccionario con los modelos optimizados.\n",
    "    \"\"\"\n",
    "    def objetivo_optuna(trial, X, y, tipo_regularizacion):\n",
    "        \"\"\"\n",
    "        Función objetivo para la optimización con Optuna.\n",
    "\n",
    "        Args:\n",
    "            trial (optuna.Trial): Objeto de prueba de Optuna.\n",
    "            X (pd.DataFrame): Variables predictoras.\n",
    "            y (pd.Series): Variable objetivo.\n",
    "            tipo_regularizacion (str): 'l1', 'l2' o 'elasticnet'.\n",
    "\n",
    "        Returns:\n",
    "            float: AUC promedio de validación cruzada.\n",
    "        \"\"\"\n",
    "        C = trial.suggest_float('C', 1e-4, 1e4, log=True)\n",
    "        if tipo_regularizacion == 'elasticnet':\n",
    "            l1_ratio = trial.suggest_float('l1_ratio', 0.0, 1.0)\n",
    "            clasificador = LogisticRegression(\n",
    "                penalty='elasticnet', \n",
    "                C=C, \n",
    "                solver='saga',\n",
    "                l1_ratio=l1_ratio,\n",
    "                max_iter=5000,\n",
    "                random_state=42\n",
    "            )\n",
    "        else:\n",
    "            clasificador = LogisticRegression(\n",
    "                penalty=tipo_regularizacion, \n",
    "                C=C, \n",
    "                solver='saga', \n",
    "                max_iter=5000,\n",
    "                random_state=42\n",
    "            )\n",
    "\n",
    "        modelo = Pipeline([\n",
    "            ('escalador', StandardScaler()),\n",
    "            ('clasificador', clasificador)\n",
    "        ])\n",
    "\n",
    "        return cross_val_score(modelo, X, y, cv=5, scoring='roc_auc').mean()\n",
    "\n",
    "    resultados = []\n",
    "    modelos = {}\n",
    "\n",
    "    for nombre, penalizacion in [('Lasso', 'l1'), ('Ridge', 'l2'), ('ElasticNet', 'elasticnet')]:\n",
    "        estudio = optuna.create_study(direction='maximize')\n",
    "        estudio.optimize(lambda trial: objetivo_optuna(trial, X, y, penalizacion), n_trials=n_trials)\n",
    "\n",
    "        mejores_params = estudio.best_params\n",
    "        mejor_C = mejores_params['C']\n",
    "        l1_ratio = mejores_params.get('l1_ratio', None)\n",
    "\n",
    "        print(f\"Mejor C para {nombre}: {mejor_C:.5f}\", end='')\n",
    "        if l1_ratio is not None:\n",
    "            print(f\", l1_ratio={l1_ratio:.3f}\", end='')\n",
    "        print(f\" con AUC={estudio.best_value:.4f}\")\n",
    "\n",
    "        if penalizacion == 'elasticnet':\n",
    "            clasificador = LogisticRegression(\n",
    "                penalty='elasticnet',\n",
    "                C=mejor_C,\n",
    "                l1_ratio=l1_ratio,\n",
    "                solver='saga',\n",
    "                max_iter=5000,\n",
    "                random_state=42\n",
    "            )\n",
    "        else:\n",
    "            clasificador = LogisticRegression(\n",
    "                penalty=penalizacion,\n",
    "                C=mejor_C,\n",
    "                solver='saga',\n",
    "                max_iter=5000,\n",
    "                random_state=42\n",
    "            )\n",
    "\n",
    "        modelo_final = Pipeline([\n",
    "            ('escalador', StandardScaler()),\n",
    "            ('clasificador', clasificador)\n",
    "        ])\n",
    "        modelo_final.fit(X, y)\n",
    "\n",
    "        kf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "        y_pred = cross_val_predict(modelo_final, X, y, cv=kf, method='predict')\n",
    "        y_prob = cross_val_predict(modelo_final, X, y, cv=kf, method='predict_proba')[:, 1]\n",
    "\n",
    "        resultados.append({\n",
    "            'modelo': nombre,\n",
    "            'C': mejor_C,\n",
    "            'l1_ratio': l1_ratio if l1_ratio is not None else '-',\n",
    "            'accuracy': accuracy_score(y, y_pred),\n",
    "            'precision': precision_score(y, y_pred),\n",
    "            'recall': recall_score(y, y_pred),\n",
    "            'f1_score': f1_score(y, y_pred),\n",
    "            'auc': roc_auc_score(y, y_prob)\n",
    "        })\n",
    "\n",
    "        modelos[nombre] = modelo_final\n",
    "\n",
    "    return pd.DataFrame(resultados), modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25786e6e",
   "metadata": {},
   "source": [
    "**Bloque 3:** Visuañización mediante tablas y gráficos.\n",
    "\n",
    "- **`mostrar_tabla_metricas()`** \n",
    "Permite comparar directamente las métricas de rendimiento de los modelos entrenados, resaltando con un gradiente visual qué modelo sobresale en cada métrica clave.\n",
    "\n",
    "- **`mostrar_tabla_coeficientes()`** \n",
    "Entrega una tabla ordenada con los coeficientes de Lasso, Ridge y ElasticNet, permitiendo observar de manera clara qué variables tienen mayor peso y cómo varía su influencia según el tipo de regularización..\n",
    "\n",
    "- **`graficar_coeficientes_modelos()`** \n",
    "Representa gráficamente los 10 coeficientes más importantes por modelo, diferenciando la dirección (positiva o negativa) del efecto, lo que facilita la comprensión para usuarios no técnicos.\n",
    "\n",
    "- **`graficar_shap_modelos()`** \n",
    "Utiliza gráficos SHAP para explicar el impacto individual de cada variable en las predicciones, aportando transparencia y robustez interpretativa al modelo.\n",
    "\n",
    "---\n",
    "\n",
    "`Justificacion para usar estas visualizaciones:`\n",
    "\n",
    "Para complementar la evaluación cuantitativa, se incorporaron visualizaciones y tablas comparativas que permiten interpretar y comunicar mejor los resultados obtenidos. La función mostrar_tabla_metricas resume el desempeño de los modelos en distintas métricas, facilitando su comparación directa. Por otro lado, las funciones mostrar_tabla_coeficientes y graficar_coeficientes_modelos permiten identificar las variables más influyentes en cada modelo, destacando sus efectos positivos o negativos. Finalmente, se utiliza SHAP (graficar_shap_modelos) como herramienta de interpretabilidad de caja negra, proporcionando una visualización robusta y detallada del impacto de cada variable en las predicciones del modelo. Este enfoque integrado permite no solo evaluar el rendimiento, sino también comprender la lógica detrás de las decisiones de los modelos.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067ef746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostrar_tabla_metricas(resultados):\n",
    "    \"\"\"\n",
    "    Muestra la tabla de métricas de evaluación para cada modelo.\n",
    "\n",
    "    Args:\n",
    "        resultados (pd.DataFrame): Resultados con métricas por modelo.\n",
    "    \"\"\"\n",
    "    print(\"\\nTabla comparativa de métricas:\")\n",
    "    display(resultados.style.background_gradient(cmap='Blues', axis=1))\n",
    "\n",
    "def mostrar_tabla_coeficientes(modelos, X):\n",
    "    \"\"\"\n",
    "    Muestra tabla comparativa de coeficientes entre modelos, ordenada por magnitud.\n",
    "\n",
    "    Args:\n",
    "        modelos (dict): Diccionario con modelos entrenados.\n",
    "        X (pd.DataFrame): Variables predictoras.\n",
    "    \"\"\"\n",
    "    coeficientes = {}\n",
    "    for nombre, pipeline in modelos.items():\n",
    "        coef = pipeline.named_steps['clasificador'].coef_.flatten()\n",
    "        coeficientes[nombre] = coef\n",
    "\n",
    "    df_coef = pd.DataFrame(coeficientes, index=X.columns)\n",
    "    df_coef['max_magnitud'] = df_coef.abs().max(axis=1)\n",
    "    df_coef = df_coef.sort_values(by='max_magnitud', ascending=False).drop(columns='max_magnitud')\n",
    "\n",
    "    print(\"\\nTabla comparativa de coeficientes (ordenada por magnitud):\")\n",
    "    display(df_coef.style.background_gradient(cmap='coolwarm', subset=list(modelos.keys())))\n",
    "\n",
    "def graficar_coeficientes_modelos(modelos, X):\n",
    "    \"\"\"\n",
    "    Grafica los 10 coeficientes más importantes por modelo (positivo o negativo).\n",
    "\n",
    "    Args:\n",
    "        modelos (dict): Modelos entrenados.\n",
    "        X (pd.DataFrame): Variables predictoras (sin escalar).\n",
    "    \"\"\"\n",
    "    n_modelos = len(modelos)\n",
    "    fig, ejes = plt.subplots(1, n_modelos, figsize=(7 * n_modelos, 6))\n",
    "    if n_modelos == 1:\n",
    "        ejes = [ejes]  # Para evitar error si hay un solo modelo\n",
    "\n",
    "    fig.suptitle(\"Top 10 variables importantes por modelo (Coeficientes)\", fontsize=16)\n",
    "\n",
    "    for i, (nombre, pipeline) in enumerate(modelos.items()):\n",
    "        coeficientes = pipeline.named_steps['clasificador'].coef_.flatten()\n",
    "        importantes = pd.Series(coeficientes, index=X.columns)\n",
    "        importantes = importantes.reindex(importantes.abs().sort_values(ascending=False).head(10).index)\n",
    "\n",
    "        colores = ['green' if val > 0 else 'red' for val in importantes.values]\n",
    "        sns.barplot(x=importantes.values, y=importantes.index, ax=ejes[i], palette=colores)\n",
    "        ejes[i].set_title(nombre)\n",
    "        ejes[i].set_xlabel('Coeficiente')\n",
    "\n",
    "        for idx, val in enumerate(importantes.values):\n",
    "            ejes[i].text(val, idx, f'{val:.2f}', va='center', ha='left' if val > 0 else 'right', color='black')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "def graficar_shap_modelos(modelos, X):\n",
    "    \"\"\"\n",
    "    Genera gráficos SHAP summary plot para cada modelo.\n",
    "\n",
    "    Args:\n",
    "        modelos (dict): Modelos entrenados.\n",
    "        X (pd.DataFrame): Variables predictoras (sin escalar).\n",
    "    \"\"\"\n",
    "    for nombre, pipeline in modelos.items():\n",
    "        print(f\"\\nGráfico SHAP para {nombre}:\")\n",
    "        X_escalado = pipeline.named_steps['escalador'].transform(X)\n",
    "        explicador = shap.Explainer(pipeline.named_steps['clasificador'], X_escalado, feature_names=X.columns)\n",
    "        valores_shap = explicador(X_escalado)\n",
    "        shap.summary_plot(valores_shap, X_escalado, feature_names=X.columns, show=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fb6b86",
   "metadata": {},
   "source": [
    "**Bloque 4:** Función de ejecución del código.\n",
    "\n",
    "- **`main()`** \n",
    "Ejecuta todo el flujo: carga datos, limpieza, optimización, entrenamiento y evaluación los modelos Lasso y Ridge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bdfdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    X, y = cargar_y_preprocesar_credit()\n",
    "    resultados, modelos_entrenados = entrenar_y_optimizar_modelos(X, y)\n",
    "    mostrar_tabla_metricas(resultados)\n",
    "    mostrar_tabla_coeficientes(modelos_entrenados, X)\n",
    "    graficar_coeficientes_modelos(modelos_entrenados, X)\n",
    "    graficar_shap_modelos(modelos_entrenados, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac6d2ed",
   "metadata": {},
   "source": [
    "# 4. Visualización de resultados\n",
    "\n",
    "Se muestran los resultados obtenidos a partir de la ejecución de la funcion **main()**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e753d9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941d6973",
   "metadata": {},
   "source": [
    "# Análisis de los resultados, reflexiones y conclusión\n",
    "\n",
    "Los tres modelos de regresión logística penalizada —**Lasso**, **Ridge** y **ElasticNet**— han mostrado un desempeño **altamente consistente** en esta ejecución, especialmente en términos de capacidad predictiva medida a través del **AUC**. Este comportamiento es esperable, ya que todos comparten la misma estructura base y se diferencian únicamente en la forma en que aplican la penalización sobre los coeficientes.\n",
    "\n",
    "A pesar de pequeñas variaciones numéricas, las métricas de rendimiento (`accuracy`, `precision`, `recall`, `f1-score`) son prácticamente equivalentes, lo cual refuerza la idea de que el modelo es **robusto frente al tipo específico de regularización**, al menos en este conjunto de datos. Es importante recordar que estos resultados pueden **variar ligeramente entre ejecuciones**, tanto por la aleatoriedad inherente de la validación cruzada como por el proceso de optimización con Optuna.\n",
    "\n",
    "---\n",
    "\n",
    "## Variables más influyentes\n",
    "\n",
    "Independientemente del tipo de regularización, los modelos coinciden en identificar un **conjunto muy claro de variables clave**, cuya magnitud de coeficiente es consistentemente alta:\n",
    "\n",
    "- **RevolvingUtilizationOfUnsecuredLines**: Indicador de utilización del crédito disponible. Su fuerte impacto positivo sugiere que altos niveles de utilización están asociados a mayor riesgo.\n",
    "- **Número de pagos atrasados en distintas franjas (30-59, 60-89, 90+ días)**: Reflejan directamente el historial de morosidad, y naturalmente se asocian con un mayor riesgo de incumplimiento.\n",
    "- **Edad**: Con coeficiente negativo, sugiere que personas de mayor edad tienen menor probabilidad de incumplir, posiblemente por mayor estabilidad financiera.\n",
    "- **Ingresos mensuales**: También con peso negativo, indicando que a mayor ingreso, menor es el riesgo de default.\n",
    "\n",
    "Estas variables son **coherentes con el dominio del problema** y aportan interpretabilidad a las decisiones del modelo.\n",
    "\n",
    "---\n",
    "\n",
    "## ¿Deberíamos eliminar variables poco importantes?\n",
    "\n",
    "El análisis numérico y visual de los coeficientes revela que algunas variables tienen **magnitudes muy pequeñas**, típicamente inferiores a ±0.1. Sin embargo, decidir si deben eliminarse requiere matizar, ya que eliminar variables con coeficientes pequeños en modelos como Lasso o Ridge puede simplificar el modelo, hacerlo más rápido y reducir el ruido si esas variables realmente no aportan información útil. Sin embargo, esta decisión tiene riesgos: algunas variables con coeficientes bajos pueden aportar valor en combinación con otras (redundancia informativa), y en modelos regularizados no siempre un coeficiente pequeño implica irrelevancia total. Además, usar un umbral arbitrario para eliminar variables podría deteriorar el rendimiento del modelo si se eliminan variables con efectos marginales pero consistentes.\n",
    "\n",
    "En contextos como el **scoring crediticio**, donde la **explicabilidad y la trazabilidad** son esenciales, podría tener sentido **mantener esas variables si no afectan negativamente la interpretación**. Alternativamente, si el objetivo es simplificar al máximo sin sacrificar desempeño, puede considerarse eliminar aquellas con coeficientes muy bajos **después de validar su impacto mediante un experimento controlado**.\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusión\n",
    "\n",
    "Los modelos penalizados ofrecen una excelente combinación de **rendimiento, interpretabilidad y control de complejidad**. Aunque cada técnica (Lasso, Ridge, ElasticNet) tiene matices distintos en cómo manejan los coeficientes, en esta ejecución han convergido en una solución muy similar. Las variables más influyentes tienen un claro sentido desde la perspectiva del negocio crediticio, y las menos influyentes pueden evaluarse cuidadosamente antes de decidir eliminarlas.\n",
    "\n",
    "El uso complementario de herramientas como **SHAP** fortalece aún más la transparencia del modelo, ofreciendo explicaciones individualizadas que son clave para una implementación responsable y ética en entornos financieros.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
